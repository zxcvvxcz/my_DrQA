{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainloader length: 2700\n",
    "# testloader length: 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:08<00:00, 10007.92lines/s]\n",
      "100%|██████████| 87599/87599 [00:21<00:00, 4107.08lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import SQuAD1\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# data_dir = '.data'\n",
    "# data_names = ['dev-v1.1.json', 'train-v1.1.json']\n",
    "# for data_name in data_names:\n",
    "#     if not os.path.isfile(os.path.join(data_dir, data_name)):\n",
    "#         print('download')\n",
    "#         train, dev = SQuAD1()\n",
    "#         break\n",
    "trainset, devset = SQuAD1()\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# dataset shape: (paragraph, question, answer, span)\n",
    "trainset, devset = SQuAD1(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = trainset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# errors = 0\n",
    "# print('length of vocab before filtering:', len(vocab.stoi))\n",
    "# for key, value in list(vocab.stoi.items()):\n",
    "#     if re.search('\\n', key) or re.search(' ', key):\n",
    "#         errors += 1\n",
    "#         print(key)\n",
    "#         vocab.stoi.pop(key)\n",
    "#         vocab.itos.pop(value)\n",
    "#         vocab.freqs.pop(key)\n",
    "#         # vocab.freqs[key] -= 1\n",
    "#         # if vocab.freqs[key] < 1:\n",
    "#         #     vocab.freqs.pop(key)\n",
    "#\n",
    "# print(errors)\n",
    "# print('length of vocab after filtering:', len(vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainset, devset = SQuAD1(vocab=vocab)\n",
    "# model = None\n",
    "# optimizer = None\n",
    "# loss = None\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_large_text(data):\n",
    "    return data[0] <= 400\n",
    "\n",
    "def check_train_data(data):\n",
    "    # data might be wrong because of spacy tokenizer\n",
    "    p_length, q_length, idx, paragraph, question, answer, span = data\n",
    "    if span[0][0] > p_length or span[0][1] > p_length:\n",
    "        return False\n",
    "    if paragraph[span[0][0]] == answer[0][0] and paragraph[span[0][1]] == answer[0][-1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_dev_data(data):\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if len(spans) != 3 or len(answers) != 3:\n",
    "        return False\n",
    "    else:\n",
    "        for span, answer in zip(spans, answers):\n",
    "            if span[0] > p_length or span[1] > p_length:\n",
    "                return False\n",
    "            if paragraph[span[0]] != answer[0] or paragraph[span[1]] != answer[-1]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86412\n",
      "8295\n"
     ]
    }
   ],
   "source": [
    "train_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(trainset)]\n",
    "dev_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(devset)]\n",
    "\n",
    "train_data = list(filter(remove_large_text, train_data))\n",
    "dev_data = list(filter(remove_large_text, dev_data))\n",
    "\n",
    "train_data = list(filter(check_train_data, train_data))\n",
    "dev_data = list(filter(check_dev_data, dev_data))\n",
    "\n",
    "\n",
    "train_data.sort() # sort by length and pad sequences with similar lengths\n",
    "dev_data.sort()\n",
    "# paragraph, question: tensor of indices of words, use itos to get word\n",
    "print(len(train_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_data[0][3])\n",
    "# for idx in train_data[0][3]:\n",
    "#     print(train.get_vocab().itos[idx], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_data(data):\n",
    "    # Generate the pad id\n",
    "    pad_id = vocab['<pad>']\n",
    "    # Find max length of the mini-batch\n",
    "    # train.get_vocab()['pad'], dev.get_vocab()['pad'] is equal to 22949\n",
    "    max_p_len = max(list(zip(*data))[0])\n",
    "    max_q_len = max(list(zip(*data))[1])\n",
    "    paragraph_list = list(zip(*data))[3]\n",
    "    question_list = list(zip(*data))[4]\n",
    "    answer_list = list(zip(*data))[5]\n",
    "    span_list = list(zip(*data))[6]\n",
    "    padded_paragraphs = torch.stack([torch.cat((paragraph,\n",
    "            torch.LongTensor([pad_id] * (max_p_len - len(paragraph))))) \\\n",
    "            for paragraph in paragraph_list])\n",
    "    padded_questions = torch.stack([torch.cat((question,\n",
    "            torch.tensor([pad_id] * (max_q_len - len(question))).long())) \\\n",
    "            for question in question_list])\n",
    "    paragraph_pad_mask = torch.zeros_like(padded_paragraphs).masked_fill(padded_paragraphs == pad_id, 1)\n",
    "    question_pad_mask = torch.zeros_like(padded_questions).masked_fill(padded_questions == pad_id, 1)\n",
    "\n",
    "    return padded_paragraphs, padded_questions, span_list, answer_list, \\\n",
    "           paragraph_pad_mask, question_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_data)\n",
    "testloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([12163, 56789]), tensor([12163, 56789]), tensor([12163, 56789])] [tensor([33, 34]), tensor([33, 34]), tensor([33, 34])]\n",
      "facing\n",
      "it\n",
      "[tensor([  881, 20129]), tensor([  881, 20129]), tensor([  881, 20129])] [tensor([44, 45]), tensor([44, 45]), tensor([44, 45])]\n",
      "upraised\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "for i, (p, q, a, s) in enumerate(devset):\n",
    "    print(a,s)\n",
    "    nps = s[0].numpy()\n",
    "    tokens = tokenizer(trainset.data[i][0])\n",
    "    print(tokens[int(nps[0])])\n",
    "    print(tokens[nps[1]])\n",
    "    # print(tokens[a[0].numpy().item()])\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "           paragraph_pad_mask, question_pad_mask) in enumerate(trainloader):\n",
    "    # print(idx, padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "    #        paragraph_pad_mask, question_pad_mask)\n",
    "    # print(padded_paragraphs.masked_fill(paragraph_pad_mask == 1, -1))\n",
    "    if idx > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(trainset.get_vocab()['pad'], dev.get_vocab()['pad'])\n",
    "# devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_vec = torchtext.vocab.GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(vocab, pre_trained_emb_vec):\n",
    "    # print(pre_trained_emb_vec.dim)\n",
    "    weights_matrix = np.zeros((len(vocab), pre_trained_emb_vec.dim))\n",
    "    words_found = 0\n",
    "    no_word = 0\n",
    "    for i, (word, _) in enumerate(vocab.freqs.most_common()):\n",
    "        try:\n",
    "            word_index = pre_trained_emb_vec.stoi[word]\n",
    "            weights_matrix[i] = pre_trained_emb_vec[word_index]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            no_word += 1 # no such word in pre_trained_embedding: zero vector\n",
    "    print('words not found:', no_word)\n",
    "    print('words found:', words_found)\n",
    "    return torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for key, value in vocab.freqs.items():\n",
    "#     if re.search(' ', key):\n",
    "#         print(key, value)\n",
    "# for i, word in enumerate(vocab.freqs.most_common()):\n",
    "#     print(word)\n",
    "#     if i > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words not found: 17435\n",
      "words found: 86591\n"
     ]
    }
   ],
   "source": [
    "word_emb_table = build_word_embedding(vocab, glove_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# glove_vec.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not using now\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser','ner',])\n",
    "#\n",
    "# def exact_match(paragraphs_indices, questions_indices, vocab):\n",
    "#     # process one paragraph batch, one question batch\n",
    "#     # print(paragraphs_indices.size())\n",
    "#     # print(questions_indices.size())\n",
    "#     #\n",
    "#     # j = 0\n",
    "#     # for (paragraph_indices, question_indices) in \\\n",
    "#     #         zip(paragraphs_indices, questions_indices):\n",
    "#     #     j += 1\n",
    "#     # print('j:',j)\n",
    "#     exact_match_table = np.zeros((len(paragraphs_indices), len(paragraphs_indices[0]), 3))\n",
    "#     # print(exact_match_table.shape)\n",
    "#\n",
    "#     for i, (paragraph_indices, question_indices) in \\\n",
    "#             enumerate(zip(paragraphs_indices, questions_indices)):\n",
    "#         # print(paragraphs_indices)\n",
    "#         # print(paragraphs_indices.size())\n",
    "#         # paragraph_processed = nlp(paragraph_sentence)\n",
    "#         # question_lemmas = [lem.lemma_ for lem in question_processed]\n",
    "#         for j, paragraph_index in enumerate(paragraph_indices):\n",
    "#             paragraph_word = vocab.itos[paragraph_index]\n",
    "#             if paragraph_word == '<pad>':\n",
    "#                 # print('got pad')\n",
    "#                 continue\n",
    "#             em_tensor = torch.LongTensor([0, 0, 0])\n",
    "#             # original\n",
    "#             if paragraph_index in question_indices:\n",
    "#                 em_tensor[0] = 1\n",
    "#             # lemma\n",
    "#             if vocab.stoi[nlp(paragraph_word)[0].lemma_] in question_indices:\n",
    "#                 em_tensor[1] = 1\n",
    "#             # uncased\n",
    "#             if vocab.stoi[paragraph_word.lower()] and \\\n",
    "#                     vocab.stoi[paragraph_word.lower()] in question_indices:\n",
    "#                 em_tensor[2] = 1\n",
    "#             exact_match_table[i][j] = em_tensor\n",
    "#\n",
    "#     return torch.LongTensor(exact_match_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim, input_dim)\n",
    "        self.linear2 = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, paragraph, question, question_pad_mask):\n",
    "\n",
    "        p = self.relu(self.linear1(paragraph))\n",
    "\n",
    "        # q = self.relu(self.linear2(question))\n",
    "\n",
    "        q = self.relu(self.linear1(question))\n",
    "        q = q.permute(0, 2, 1)\n",
    "\n",
    "        dot_product = torch.bmm(p, q)\n",
    "        # print(dot_product.size())\n",
    "        # print(question_pad_mask.size())\n",
    "        question_mask_expand = question_pad_mask.unsqueeze(1).expand(dot_product.size())\n",
    "        dot_product = dot_product.masked_fill(question_mask_expand == 1, -float('inf'))\n",
    "\n",
    "        dot_product_flatten = dot_product.view(-1, question.size(1))\n",
    "\n",
    "        attn_score = F.softmax(dot_product_flatten, dim=1)\n",
    "        attn_score = attn_score.view(-1, paragraph.shape[1], question.shape[1])\n",
    "\n",
    "        aligned_embedding = torch.bmm(attn_score, question)\n",
    "        return aligned_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerBiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstms.append(nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True))\n",
    "        for i in range(1, nlayers):\n",
    "            self.lstms.append(nn.LSTM(hidden_size * 2, hidden_size,\n",
    "                                      batch_first=True, bidirectional=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.dropout(x)\n",
    "        lstm_output, (_, _) = self.lstms[0](x)\n",
    "        hidden_states = [lstm_output]\n",
    "        # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "        for i in range(1, self.nlayers):\n",
    "            # lstm_output = self.dropout(lstm_output)\n",
    "            lstm_output, (_, _) = self.lstms[i](lstm_output)\n",
    "            # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "            hidden_states.append(lstm_output)\n",
    "\n",
    "        output = torch.cat(hidden_states, dim=2)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncoding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm_output_size = hidden_size * 6\n",
    "        self.linear = nn.Linear(self.lstm_output_size, 1)\n",
    "        self.lstm = MultiLayerBiLSTM(input_size, hidden_size, nlayers, dropout)\n",
    "        # biLSTM output size: hidden size * 6\n",
    "    def forward(self, x, question_mask):\n",
    "        try:\n",
    "            x = self.lstm(x)\n",
    "            b = x.view(-1, self.lstm_output_size)\n",
    "            b = self.linear(b) # attention score\n",
    "            b = b.view(question_mask.shape[0], -1)\n",
    "            # print(x.size(), question_mask.size())\n",
    "            b = b.masked_fill(question_mask == 1, -float('inf')) # masking\n",
    "            b = F.softmax(b, dim=1)\n",
    "\n",
    "            b = b.unsqueeze(1)\n",
    "            # print(x.size(), x_lstm.size())\n",
    "            encoding = torch.bmm(b, x)\n",
    "            encoding = encoding.squeeze(1)\n",
    "            return encoding\n",
    "        except:\n",
    "            print('question mask size:', question_mask.size())\n",
    "            print('x size:', x.size())\n",
    "            print('b size:', b.size())\n",
    "            print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionLayer(nn.Module):\n",
    "    def __init__(self, p_size, q_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(q_size, p_size)\n",
    "\n",
    "    def forward(self, paragraph, question, paragraph_mask):\n",
    "        Wq = self.linear(question)\n",
    "        Wq = Wq.unsqueeze(2)\n",
    "        pWq = paragraph.bmm(Wq)\n",
    "        pWq = pWq.squeeze(2)\n",
    "        pWq = pWq.masked_fill(paragraph_mask == 1, -float('inf'))\n",
    "        return pWq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fixate_embedding(grad):\n",
    "    grad[1000:] = 0\n",
    "    return grad\n",
    "\n",
    "class DocumentReader(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, nlayers, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_emb_table).to(device), freeze=False)\n",
    "        self.word_embedding_layer.weight.register_hook(fixate_embedding)\n",
    "        # print(embedding_size)\n",
    "        self.aligned_embedding_layer = AlignedQuestionEmbedding(embedding_size)\n",
    "        # self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2 + 3, hidden_size, nlayers, dropout)\n",
    "        self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.question_encoder = QuestionEncoding(embedding_size, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.prediction_layer_start = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                          hidden_size * nlayers * 2)\n",
    "        self.prediction_layer_end = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                        hidden_size * nlayers * 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, paragraph, question, paragraph_mask, question_mask):\n",
    "        # em_embedding = exact_match(paragraph, question, vocab)\n",
    "        # print(em_embedding.size())\n",
    "        p_word_embedding = self.word_embedding_layer(paragraph)\n",
    "        q_word_embedding = self.word_embedding_layer(question)\n",
    "        p_word_embedding = self.dropout(p_word_embedding)\n",
    "        q_word_embedding = self.dropout(q_word_embedding)\n",
    "        aligned_embedding = self.aligned_embedding_layer(p_word_embedding, q_word_embedding, question_mask)\n",
    "        # print(p_word_embedding.size())\n",
    "        # print(aligned_embedding.size())\n",
    "        paragraph_embeddings = torch.cat([p_word_embedding, aligned_embedding], dim=2)\n",
    "\n",
    "        # paragraph_embeddings = torch.cat([em_embedding.to(device), p_word_embedding.to(device), aligned_embedding.to(device)], dim=2)\n",
    "        paragraph_encoding = self.paragraph_lstm(paragraph_embeddings)\n",
    "        # print(question.size(), question_mask.size())\n",
    "        question_encoding = self.question_encoder(q_word_embedding, question_mask)\n",
    "\n",
    "        prediction_start = self.prediction_layer_start(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "        prediction_end = self.prediction_layer_end(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "\n",
    "        return prediction_start, prediction_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "EMB_SIZE = 300\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "#\n",
    "# writer = SummaryWriter('runs/myDrQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# dataiter_next = dataiter.next()\n",
    "# print(dataiter_next)\n",
    "# (p, q, a, s, p_mask, q_mask) = dataiter.next()\n",
    "# writer.add_graph(model, p, p_mask, q_mask)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, train_dataset):\n",
    "    '''\n",
    "    Trains the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start training ........\")\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    # put the model in training mode\n",
    "    model.train()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    try:\n",
    "        for i, (paragraphs, questions, span_list, answer_list,\n",
    "                paragraph_mask, question_mask) in enumerate(train_dataset):\n",
    "            # if i < 575:\n",
    "            #     continue\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "            # place the tensors on GPU\n",
    "            paragraphs = paragraphs.to(device)\n",
    "            paragraph_mask = paragraph_mask.to(device)\n",
    "            questions = questions.to(device)\n",
    "            question_mask = question_mask.to(device)\n",
    "            # span_list = span_list.to(device)\n",
    "\n",
    "            # forward pass, get the predictions\n",
    "            preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "            start_pred, end_pred = preds\n",
    "\n",
    "            # print('preds:', start_pred, end_pred)\n",
    "            # separate labels for start and end position\n",
    "            span_start = []\n",
    "            span_end = []\n",
    "            for span in span_list:\n",
    "                span_start.append(span[0][0].item())\n",
    "                span_end.append(span[0][1].item())\n",
    "\n",
    "            # print('span:', span_start, span_end)\n",
    "            span_start = torch.LongTensor(span_start).to(device)\n",
    "            span_end = torch.LongTensor(span_end).to(device)\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(start_pred, span_start) + F.cross_entropy(end_pred, span_end)\n",
    "\n",
    "            # backward pass, calculates the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the gradients to prevent them from accumulating\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "    except Exception as e:\n",
    "        print(f'sizes of pred:{start_pred.size()} / span:{span_start.size()}')\n",
    "        print(f'span_start: {span_start[23]}\\nspan_end: {span_end[23]}')\n",
    "        print(f'i: {i}')\n",
    "        print(f'paragraph: {paragraphs}')\n",
    "        bad_p = paragraphs.numpy()[23]\n",
    "        bad_q = questions.numpy()[23]\n",
    "        bad_p_text = [vocab.itos[pi] for pi in bad_p]\n",
    "        bad_q_text = [vocab.itos[qi] for qi in bad_q]\n",
    "        bad_p_text = ' '.join(bad_p_text)\n",
    "        bad_q_text = ' '.join(bad_q_text)\n",
    "\n",
    "        print(bad_p_text)\n",
    "        print(bad_q_text)\n",
    "        print(f'paragraph size: {paragraphs.size()}, question size: {questions.size()}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "    return train_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %time train_loss = train(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def validate(model, test_dataset):\n",
    "    '''\n",
    "    Validates the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start validation ........\")\n",
    "\n",
    "    val_loss = 0.\n",
    "    emScore = 0\n",
    "    f1Score = 0\n",
    "    # put the model in eval mode\n",
    "    model.eval()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    for i, (paragraphs, questions, span_list, answer_list,\n",
    "            paragraph_mask, question_mask) in enumerate(test_dataset):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "        # place the tensors on GPU\n",
    "        paragraphs = paragraphs.to(device)\n",
    "        paragraph_mask = paragraph_mask.to(device)\n",
    "        questions = questions.to(device)\n",
    "        question_mask = question_mask.to(device)\n",
    "        # span_list = span_list.to(device)\n",
    "\n",
    "        # forward pass, get the predictions\n",
    "        preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "        start_pred, end_pred = preds\n",
    "        # print('preds:', start_pred, end_pred)\n",
    "        log_softmax = nn.LogSoftmax(dim=1) # batchwise log softmax\n",
    "        pred_table = log_softmax(start_pred).unsqueeze(2) + log_softmax(end_pred).unsqueeze(1)\n",
    "        pred_mask1 = (torch.ones_like(pred_table) * -float('inf')).tril(diagonal=-1)# start index <= end index\n",
    "        pred_mask2 = (torch.ones_like(pred_table) * -float('inf')).triu(diagonal=16)\n",
    "        pred_table += pred_mask1 + pred_mask2\n",
    "\n",
    "        start_pred_argmax = []\n",
    "        end_pred_argmax = []\n",
    "        paragraph_length = pred_table.shape[-1]\n",
    "        for batch in pred_table:\n",
    "            arg_max = batch.argmax()\n",
    "            start_pred_argmax.append(arg_max // paragraph_length)\n",
    "            end_pred_argmax.append(arg_max % paragraph_length)\n",
    "\n",
    "        # separate labels for start and end position\n",
    "        span_start = []\n",
    "        span_end = []\n",
    "        true_answers_list = []\n",
    "        my_answers = []\n",
    "        for paragraph, spans, answers, sp, ep in \\\n",
    "                zip(paragraphs, span_list, answer_list, start_pred_argmax, end_pred_argmax):\n",
    "            span_start.append([span[0].item() for span in spans][:3])\n",
    "            span_end.append([span[1].item() for span in spans][:3])\n",
    "            true_answers_list.append([ans2txt(answer) for answer in answers])\n",
    "            if sp > ep or ep > sp + 15:\n",
    "                print(f'wrong range, sp:{sp}, ep:{ep} ')\n",
    "            my_answers.append(span2txt([sp, ep + 1], paragraph))\n",
    "        with torch.no_grad():\n",
    "            # print('span:', span_start, span_end)\n",
    "            try:\n",
    "                span_start = torch.LongTensor(span_start).to(device)\n",
    "                span_end = torch.LongTensor(span_end).to(device)\n",
    "                # calculate loss\n",
    "                loss = F.cross_entropy(start_pred, span_start.t()[0]) + F.cross_entropy(end_pred, span_end.t()[0])\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                emScore += em_batch(my_answers, true_answers_list)\n",
    "                f1Score += f1_batch(my_answers, true_answers_list)\n",
    "            except:\n",
    "                print('start pred:', start_pred)\n",
    "                print('start pred shape:', start_pred.shape)\n",
    "                print('span_list:', span_list)\n",
    "                print('span_list length:', len(span_list))\n",
    "                print('span_start:', span_start)\n",
    "                print('span_start shape:', np.asarray(span_start).shape)\n",
    "                print('span_end:', span_end)\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    return val_loss / len(test_dataset), emScore / len(test_dataset), f1Score / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "def normalize_answer(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('','',punctuation))\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def em_batch(my_answers, true_answers_list):\n",
    "    # true_answers_list: batch size * 3\n",
    "    em = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        for true_answer in true_answers:\n",
    "            if my_answer == true_answer:\n",
    "                em += 1\n",
    "                break\n",
    "    return em / BATCH_SIZE\n",
    "\n",
    "def f1_batch(my_answers, true_answers_list):\n",
    "    f1Batch = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        f1_single = 0\n",
    "        for true_answer in true_answers:\n",
    "            my_answer_split = my_answer.split()\n",
    "            true_answer_split = true_answer.split()\n",
    "            common = Counter(my_answer_split) & Counter(true_answer_split)\n",
    "            num_intersection = sum(common.values())\n",
    "            if num_intersection == 0:\n",
    "                continue\n",
    "            precision = num_intersection / len(my_answer_split)\n",
    "            recall = num_intersection / len(true_answer_split)\n",
    "            f1_single = max((2 * precision * recall) / (precision + recall), f1_single)\n",
    "        f1Batch += f1_single\n",
    "        # if f1_single < 0.9:\n",
    "        #     print('my answer split:', my_answer_split)\n",
    "        #     print('true answer split:', true_answer_split)\n",
    "    return f1Batch / BATCH_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def span2txt(span, paragraph):\n",
    "    # print(span[0].item())\n",
    "    my_answer = paragraph[int(span[0].item()) : int(span[1].item()) + 1]\n",
    "    return ans2txt(my_answer)\n",
    "def ans2txt(answer):\n",
    "    words = []\n",
    "    for a_index in answer:\n",
    "        words.append(vocab.itos[a_index.item()])\n",
    "    return normalize_answer(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_val_loss = 100\n",
    "path = 'best.pt'\n",
    "if os.path.isfile(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "else:\n",
    "    epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring epoch 1\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008485078811645508\n",
      "Starting batch: 500, time: 97.02754926681519\n",
      "Starting batch: 1000, time: 195.56931352615356\n",
      "Starting batch: 1500, time: 294.260066986084\n",
      "Starting batch: 2000, time: 397.3694369792938\n",
      "Starting batch: 2500, time: 498.55445170402527\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002002716064453125\n",
      "train_loss: 5.993310835307636, val_loss: 5.506319822714879\n",
      "em_score: 20.46875, f1_score: 40.81565426587914\n",
      "End epoch 1, elapsed time: 552.6614120006561\n",
      "Staring epoch 2\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008000373840332031\n",
      "Starting batch: 500, time: 96.64706230163574\n",
      "Starting batch: 1000, time: 194.12632298469543\n",
      "Starting batch: 1500, time: 289.8697714805603\n",
      "Starting batch: 2000, time: 388.927561044693\n",
      "Starting batch: 2500, time: 484.50423550605774\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019452571868896484\n",
      "train_loss: 5.253432774888017, val_loss: 5.022389000195723\n",
      "em_score: 23.365384615384617, f1_score: 45.688471430554806\n",
      "End epoch 2, elapsed time: 537.5123853683472\n",
      "Staring epoch 3\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007997989654541016\n",
      "Starting batch: 500, time: 94.79383182525635\n",
      "Starting batch: 1000, time: 193.61627340316772\n",
      "Starting batch: 1500, time: 291.2610945701599\n",
      "Starting batch: 2000, time: 389.1468243598938\n",
      "Starting batch: 2500, time: 488.37210965156555\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0020334720611572266\n",
      "train_loss: 4.8251647530816655, val_loss: 4.765363375957196\n",
      "em_score: 24.723557692307693, f1_score: 48.329140101868234\n",
      "End epoch 3, elapsed time: 543.8856728076935\n",
      "Staring epoch 4\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00599980354309082\n",
      "Starting batch: 500, time: 96.839439868927\n",
      "Starting batch: 1000, time: 193.5522313117981\n",
      "Starting batch: 1500, time: 291.2763533592224\n",
      "Starting batch: 2000, time: 389.50283002853394\n",
      "Starting batch: 2500, time: 485.80655312538147\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009679794311523438\n",
      "train_loss: 4.55492016140155, val_loss: 4.6145573570178104\n",
      "em_score: 25.78125, f1_score: 49.866200074538554\n",
      "End epoch 4, elapsed time: 541.1905560493469\n",
      "Staring epoch 5\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0059986114501953125\n",
      "Starting batch: 500, time: 96.3628499507904\n",
      "Starting batch: 1000, time: 194.27645111083984\n",
      "Starting batch: 1500, time: 296.15492057800293\n",
      "Starting batch: 2000, time: 396.07233691215515\n",
      "Starting batch: 2500, time: 504.1643888950348\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0020008087158203125\n",
      "train_loss: 4.349103929995608, val_loss: 4.503938969282004\n",
      "em_score: 26.802884615384613, f1_score: 50.6989092470338\n",
      "End epoch 5, elapsed time: 577.6291792392731\n",
      "Staring epoch 6\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.014007806777954102\n",
      "Starting batch: 500, time: 121.99389505386353\n",
      "Starting batch: 1000, time: 219.1943657398224\n",
      "Starting batch: 1500, time: 318.1969327926636\n",
      "Starting batch: 2000, time: 417.5702428817749\n",
      "Starting batch: 2500, time: 515.6610732078552\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002032041549682617\n",
      "train_loss: 4.180560132125183, val_loss: 4.510311781443082\n",
      "em_score: 25.48076923076923, f1_score: 50.267914286789825\n",
      "End epoch 6, elapsed time: 571.0417098999023\n",
      "Staring epoch 7\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.009001016616821289\n",
      "Starting batch: 500, time: 100.01601600646973\n",
      "Starting batch: 1000, time: 195.3244080543518\n",
      "Starting batch: 1500, time: 290.8950300216675\n",
      "Starting batch: 2000, time: 386.91392183303833\n",
      "Starting batch: 2500, time: 481.7275800704956\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002000093460083008\n",
      "train_loss: 4.0262259718048625, val_loss: 4.425478509756235\n",
      "em_score: 27.64423076923077, f1_score: 52.28961252598056\n",
      "End epoch 7, elapsed time: 535.2187428474426\n",
      "Staring epoch 8\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008997678756713867\n",
      "Starting batch: 500, time: 94.27975535392761\n",
      "Starting batch: 1000, time: 189.42109966278076\n",
      "Starting batch: 1500, time: 284.4043405056\n",
      "Starting batch: 2000, time: 378.5134813785553\n",
      "Starting batch: 2500, time: 476.2618634700775\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010018348693847656\n",
      "train_loss: 3.8684508591305544, val_loss: 4.394320677793943\n",
      "em_score: 27.463942307692307, f1_score: 52.53725335013565\n",
      "End epoch 8, elapsed time: 530.8551206588745\n",
      "Staring epoch 9\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.009000539779663086\n",
      "Starting batch: 500, time: 94.17205476760864\n",
      "Starting batch: 1000, time: 189.00565099716187\n",
      "Starting batch: 1500, time: 285.07946515083313\n",
      "Starting batch: 2000, time: 384.1387400627136\n",
      "Starting batch: 2500, time: 486.24662351608276\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002000093460083008\n",
      "train_loss: 3.715606008093254, val_loss: 4.383649831551772\n",
      "em_score: 26.971153846153843, f1_score: 52.53129615555896\n",
      "End epoch 9, elapsed time: 543.6880271434784\n",
      "Staring epoch 10\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004965543746948242\n",
      "Starting batch: 500, time: 98.7096643447876\n",
      "Starting batch: 1000, time: 198.58071374893188\n",
      "Starting batch: 1500, time: 299.5886216163635\n",
      "Starting batch: 2000, time: 399.75908398628235\n",
      "Starting batch: 2500, time: 499.05068707466125\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010006427764892578\n",
      "train_loss: 3.5608266440641874, val_loss: 4.477578068696536\n",
      "em_score: 27.99278846153846, f1_score: 52.43692356260756\n",
      "End epoch 10, elapsed time: 554.9941811561584\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "epoch_start = max(epoch, 0)\n",
    "for epoch in range(epoch_start, epoch_start + 10):\n",
    "    print(f'Staring epoch {epoch}')\n",
    "    start_time = time()\n",
    "\n",
    "    train_loss = train(model, trainloader)\n",
    "    val_loss, emScore, f1Score = validate(model, testloader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    em_scores.append(emScore * 100)\n",
    "    f1_scores.append(f1Score * 100)\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            }, path)\n",
    "    end_time = time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "    print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')\n",
    "    print(f'End epoch {epoch}, elapsed time: {time_elapsed}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(train_losses)\n",
    "    writer.writerow(val_losses)\n",
    "    writer.writerow(em_scores)\n",
    "    writer.writerow(f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0020389556884765625\n",
      "train_loss: 7.377101438304134, val_loss: 6.482619115022513\n",
      "em_score: 13.365384615384615, f1_score: 29.547050992112123\n"
     ]
    }
   ],
   "source": [
    "# val_loss, emScore, f1Score = validate(model, testloader)\n",
    "# print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "# print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.plot([i for i in range(1, 11)], train_losses)\n",
    "# plt.plot([i for i in range(1, 11)], val_losses)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('CE losses')\n",
    "# plt.title('Training Result')\n",
    "# plt.legend(['Train', 'Test'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1, 11)], em_scores)\n",
    "plt.plot([i for i in range(1, 11)], f1_scores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores on SQuAD 1.1')\n",
    "plt.legend(['EM', 'F1'])\n",
    "plt.xticks([i for i in range(1, 11)])\n",
    "plt.yticks(np.arange(15, 60, 5))\n",
    "plt.savefig(f\"best{epoch - 9}-{epoch}.png\", dpi=350)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# for i, t_data in enumerate(testloader):\n",
    "#     idx = i\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (p, q, s, a, p_mask, q_mask), p 길이 점점 증가\n",
    "# p, q: tensor, batch size * length\n",
    "# s: tuple of tensors, batch size\n",
    "# a:\n",
    "dataiter = iter(trainloader)\n",
    "dataiter_next = dataiter.next()\n",
    "dataiter_next[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "for i in range(100):\n",
    "    dataiter_100 = dataiter.next()\n",
    "dataiter_100[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paragraphs, questions, span_list, answer_list, paragraph_mask, question_mask = dataiter_next\n",
    "model_ex = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)\n",
    "model_ex.train()\n",
    "paragraphs = paragraphs.to(device)\n",
    "paragraph_mask = paragraph_mask.to(device)\n",
    "questions = questions.to(device)\n",
    "question_mask = question_mask.to(device)\n",
    "# span_list = span_list.to(device)\n",
    "\n",
    "# forward pass, get the predictions\n",
    "preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "start_pred, end_pred = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start_pred.shape\n",
    "# start_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "# print(start_pred_argmax)\n",
    "# print(span_list)\n",
    "# print(span_list[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for p, s, a in zip(paragraphs, span_list, answer_list):\n",
    "    i += 1\n",
    "    if i < 3:\n",
    "        print(p)\n",
    "        print(s)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# em_score = 0\n",
    "# for i, (p, s, a) in enumerate(list(zip(paragraphs, span_list, answer_list))):\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     if i < 3:\n",
    "#         # print(p)\n",
    "#         # print(s)\n",
    "#         # print(a)\n",
    "#         em_score += em_func(p, a[0], s)\n",
    "# print(em_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
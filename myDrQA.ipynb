{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainloader length: 2700\n",
    "# testloader length: 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "import os\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:21<00:00, 4040.30lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import SQuAD1\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# data_dir = '.data'\n",
    "# data_names = ['dev-v1.1.json', 'train-v1.1.json']\n",
    "# for data_name in data_names:\n",
    "#     if not os.path.isfile(os.path.join(data_dir, data_name)):\n",
    "#         print('download')\n",
    "#         train, dev = SQuAD1()\n",
    "#         break\n",
    "# trainset, devset = SQuAD1()\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# dataset shape: (paragraph, question, answer, span)\n",
    "trainset, devset = SQuAD1(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = trainset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainset_1 = trainset[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "whitespace_string_dev = []\n",
    "whitespace_string_train = []\n",
    "for i, (p, q, a, s) in enumerate(devset.data):\n",
    "    if(len(re.findall('  ', p + q)) > 0):\n",
    "        whitespace_string_dev.append(i)\n",
    "    for answer in a:\n",
    "        if(len(re.findall('  ', answer)) > 0):\n",
    "            whitespace_string_dev.append(i)\n",
    "            break\n",
    "for i, (p, q, a, s) in enumerate(trainset.data):\n",
    "    if(len(re.findall('  ', p + q)) > 0):\n",
    "        whitespace_string_train.append(i)\n",
    "    for answer in a:\n",
    "        if(len(re.findall('  ', answer)) > 0):\n",
    "            whitespace_string_train.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235, 408, 593, 1094, 1300, 1304, 1305, 1306, 1307, 1308, 1309, 1690, 1766, 1807, 1815, 1868, 1869, 1870, 2170, 2184, 2187, 2245, 2266, 2323, 2380, 2383, 2390, 2433, 2486, 2516, 2582, 2623, 2766, 2865, 2877, 2878, 2879, 2880, 2881, 2955, 3019, 3031, 3076, 3077, 3078, 3079, 3336, 3496, 3503, 3509, 3517, 3521, 3550, 3575, 3595, 3672, 3675, 3754, 4138, 4360, 4518, 4524, 4533, 4630, 4631, 4637, 4645, 4659, 4665, 4834, 4865, 4866, 4880, 4882, 4883, 4884, 4885, 4886, 4987, 5386, 5387, 5388, 5389, 5390, 5565, 5987, 5988, 5989, 5990, 6576, 6794, 7350, 7550, 8050, 8455, 8456, 8457, 8457, 8458, 9026, 9027, 9027, 9028, 9029, 9030, 9051, 9052, 9053, 9054, 9055, 9080, 9460, 9645, 9646, 9647, 9648, 9649, 10084, 10171, 10272, 10275, 10380, 10391, 10471, 10472, 10473, 10474, 10475, 10480, 10481, 10482, 10483, 10493, 10504, 10539, 10540, 10541, 10542, 10546, 10547, 10548, 10549, 10550]\n",
      "143\n",
      "1322\n"
     ]
    }
   ],
   "source": [
    "print(whitespace_string_dev)\n",
    "print(len(whitespace_string_dev))\n",
    "print(len(whitespace_string_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([   14, 20129, 11824,     3,    29,   182,     2,  6206,     7,  7502,\n            16,  1562,  1578,    17,     3,    13,  9130,    22,  6354,     3,\n         20196,   522,  4493,  3893, 20734,     5,  4493,  3893, 19284, 40929,\n          5422,    43,    46,     4,    36,   513,  1620,     3, 11234,    19,\n             0,  6328,     6, 43325,    19,     0,     3,   109,  1605,     9,\n          2009,    11,   136,     6,   996,    11,   609,  2506,   347, 92741,\n            16,  2349,  3632,     3,   312, 43325,    17,     3,     9,  2009,\n            11,   426,   312,     0,     3,     6,     9,  2009,    11,   513,\n         19284,  4399,     4, 98271,     5,  5422,    23,   609, 11546,    27,\n         14499,   179, 11764, 39332,     3,    57,  6239,     9,  2009,    11,\n           136,  7047,  5446,    19,     0,  6328,     6,   860, 92741,     3,\n             6,  1012,  5686,  9918,     0,     3,  3573,     3,    57,  6239,\n          4488,  5446,    19, 55942,  6328,     6,   312, 92741,    44,     0,\n            41, 19633,    19,  1509,  6328,     6,  1022,  1666,     0,    19,\n         65828,  6328,     5,   400,  1290, 11546,   309, 12147,     0,     0,\n            16,  6460, 22973,    19, 52960,  6328,    17,     3, 20327,     0,\n             0,    16,  1669, 22973,    19, 32570,  6328,     6,   264, 92741,\n            17,     3,     6,   172,    11,    82,  5686, 23668,  2502,    16,\n          1669, 22973,    19, 66185,  6328,    17,     5,    14, 20129,     0,\n          1440,  4493,  3893,  1372,   322,  7320,  8437,     3,    57,   182,\n             2,   378,    22,     0, 43325,  6328,     6,   522, 92741,     7,\n          1048,   596,     3,   251,    22,  4493,  3893,     0,  5600, 36499,\n             3,    57, 19633,    19, 12608,  6328,     6,  6239,   759,  5446,\n            19,   275, 15601,  6328,     5,   881,    23,  4054,   356,    41,\n          1440,    63,  4493,  3893, 20734,    68,   676,  5436,     0,     6,\n          6196,     0,  5069,     5]),\n tensor([  121,    54, 22973,    49,     0,   844,  1209,    19,     2,   535,\n           236,    18]),\n [tensor([6460]), tensor([6460]), tensor([6460])],\n [tensor([124, 124]), tensor([151, 151]), tensor([151, 151])])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset[235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(\"The Panthers offense, which led the NFL in scoring (500 points), was loaded with talent, boasting six Pro Bowl selections. Pro Bowl quarterback Cam Newton had one of his best seasons, throwing for 3,837 yards and rushing for 636, while recording a career-high and league-leading 45 total touchdowns (35 passing, 10 rushing), a career-low 10 interceptions, and a career-best quarterback rating of 99.4. Newton's leading receivers were tight end Greg Olsen, who caught a career-high 77 passes for 1,104 yards and seven touchdowns, and wide receiver Ted Ginn, Jr., who caught 44 passes for 739 yards and 10 touchdowns; Ginn also rushed for 60 yards and returned 27 punts for 277 yards. Other key receivers included veteran Jerricho Cotchery (39 receptions for 485 yards), rookie Devin Funchess (31 receptions for 473 yards and five touchdowns), and second-year receiver Corey Brown (31 receptions for 447 yards). The Panthers backfield featured Pro Bowl running back Jonathan Stewart, who led the team with 989 rushing yards and six touchdowns in 13 games, along with Pro Bowl fullback Mike Tolbert, who rushed for 256 yards and caught 18 passes for another 154 yards. Carolina's offensive line also featured two Pro Bowl selections: center Ryan Kalil and guard Trai Turner.\",\n 'How many receptions did Cotchery  get for the 2015 season?',\n ['39', '39', '39'],\n [588, 739, 739])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset.data[235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "844"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "whitespace_tokens_dev = []\n",
    "whitespace_tokens_train = []\n",
    "blank_token = vocab.stoi[' ']\n",
    "for i, (p, q, a, _) in enumerate(devset):\n",
    "    if (blank_token in p) or (blank_token in q):\n",
    "        whitespace_tokens_dev.append(i)\n",
    "    for answer in a:\n",
    "        if blank_token in answer:\n",
    "            whitespace_tokens_dev.append(i)\n",
    "            break\n",
    "for i, (p, q, a, _) in enumerate(trainset):\n",
    "    if (blank_token in p) or (blank_token in q):\n",
    "        whitespace_tokens_train.append(i)\n",
    "    for answer in a:\n",
    "        if blank_token in answer:\n",
    "            whitespace_tokens_train.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "1530\n"
     ]
    }
   ],
   "source": [
    "print(len(whitespace_tokens_dev))\n",
    "print(len(whitespace_tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# errors = 0\n",
    "# print('length of vocab before filtering:', len(vocab.stoi))\n",
    "# for key, value in list(vocab.stoi.items()):\n",
    "#     if re.search('\\n', key) or re.search(' ', key):\n",
    "#         errors += 1\n",
    "#         print(key)\n",
    "#         vocab.stoi.pop(key)\n",
    "#         vocab.itos.pop(value)\n",
    "#         vocab.freqs.pop(key)\n",
    "#         # vocab.freqs[key] -= 1\n",
    "#         # if vocab.freqs[key] < 1:\n",
    "#         #     vocab.freqs.pop(key)\n",
    "#\n",
    "# print(errors)\n",
    "# print('length of vocab after filtering:', len(vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainset, devset = SQuAD1(vocab=vocab)\n",
    "# model = None\n",
    "# optimizer = None\n",
    "# loss = None\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_large_text(data):\n",
    "    return data[0] <= 400\n",
    "def remove_wrong_whitespace(data):\n",
    "    blank_token = vocab.stoi[' ']\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if (blank_token in paragraph) or (blank_token in question):\n",
    "        return False\n",
    "    for answer in answers:\n",
    "        if blank_token in answer:\n",
    "            return False\n",
    "    return True\n",
    "def check_train_data(data):\n",
    "    # data might be wrong because of spacy tokenizer\n",
    "    p_length, q_length, idx, paragraph, question, answer, span = data\n",
    "    if span[0][0] > p_length or span[0][1] > p_length:\n",
    "        return False\n",
    "    if paragraph[span[0][0]] == answer[0][0] and paragraph[span[0][1]] == answer[0][-1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_dev_data(data):\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if len(spans) != 3 or len(answers) != 3:\n",
    "        return False\n",
    "    else:\n",
    "        for span, answer in zip(spans, answers):\n",
    "            if span[0] > p_length or span[1] > p_length:\n",
    "                return False\n",
    "            if paragraph[span[0]] != answer[0] or paragraph[span[1]] != answer[-1]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85130\n",
      "8262\n"
     ]
    }
   ],
   "source": [
    "train_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(trainset)]\n",
    "dev_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(devset)]\n",
    "\n",
    "# train_data = list(filter(remove_large_text, train_data))\n",
    "# dev_data = list(filter(remove_large_text, dev_data))\n",
    "\n",
    "train_data = list(filter(remove_wrong_whitespace, train_data))\n",
    "dev_data = list(filter(remove_wrong_whitespace, dev_data))\n",
    "\n",
    "train_data = list(filter(check_train_data, train_data))\n",
    "dev_data = list(filter(check_dev_data, dev_data))\n",
    "\n",
    "\n",
    "train_data.sort() # sort by length and pad sequences with similar lengths\n",
    "dev_data.sort()\n",
    "# paragraph, question: tensor of indices of words, use itos to get word\n",
    "print(len(train_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_data[0][3])\n",
    "# for idx in train_data[0][3]:\n",
    "#     print(train.get_vocab().itos[idx], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_data(data):\n",
    "    # Generate the pad id\n",
    "    pad_id = vocab['<pad>']\n",
    "    # Find max length of the mini-batch\n",
    "    # train.get_vocab()['pad'], dev.get_vocab()['pad'] is equal to 22949\n",
    "    max_p_len = max(list(zip(*data))[0])\n",
    "    max_q_len = max(list(zip(*data))[1])\n",
    "    paragraph_list = list(zip(*data))[3]\n",
    "    question_list = list(zip(*data))[4]\n",
    "    answer_list = list(zip(*data))[5]\n",
    "    span_list = list(zip(*data))[6]\n",
    "    padded_paragraphs = torch.stack([torch.cat((paragraph,\n",
    "            torch.LongTensor([pad_id] * (max_p_len - len(paragraph))))) \\\n",
    "            for paragraph in paragraph_list])\n",
    "    padded_questions = torch.stack([torch.cat((question,\n",
    "            torch.tensor([pad_id] * (max_q_len - len(question))).long())) \\\n",
    "            for question in question_list])\n",
    "    paragraph_pad_mask = torch.zeros_like(padded_paragraphs).masked_fill(padded_paragraphs == pad_id, 1)\n",
    "    question_pad_mask = torch.zeros_like(padded_questions).masked_fill(padded_questions == pad_id, 1)\n",
    "\n",
    "    return padded_paragraphs, padded_questions, span_list, answer_list, \\\n",
    "           paragraph_pad_mask, question_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_data, num_workers=0)\n",
    "testloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_data, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i, (p, q, a, s) in enumerate(devset.data):\n",
    "#     print(p)\n",
    "#     print(q)\n",
    "#     print(a,s)\n",
    "#     nps = s[0].numpy()\n",
    "#     tokens = tokenizer(trainset.data[i][0])\n",
    "#     print(tokens[int(nps[0])])\n",
    "#     print(tokens[nps[1]])\n",
    "#     # print(tokens[a[0].numpy().item()])\n",
    "#     if i > 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2121,  3893,   929,    13,    32,   107,   697,   455,     8,  2612,\n",
      "            2,  6340,     4,     2,   238,  1221,   290,    16,  6206,    17,\n",
      "           19,     2,   535,   236,     5,    14,   107,  1221,  2953,    16,\n",
      "        38675,    17,  6340, 12163, 56789,  1186,     2,   238,  1221,  2953,\n",
      "           16, 49082,    17,  6340,   881, 20129,     0,     8,  7111,    40,\n",
      "          317,  2121,  3893,   712,     5,    14,   455,    13,   450,    24,\n",
      "          504,   783,     3,  2275,     3,    31, 36266,    23,  2070,     7,\n",
      "            2,   592,  2916,  1549,  3626,    31,  1649, 25470,     3,  1553,\n",
      "            5,   173,    51,    13,     2, 16882,  2121,  3893,     3,     2,\n",
      "          996,  5210,     2,    10,  4259,  4004,    10,    22,   296,  1534,\n",
      "           11, 10093,  6642,     3,    15,   104,    15,  4468, 19307,     2,\n",
      "          843,     4,  6895,   174,  2121,  3893,   455,    22,   204, 14790,\n",
      "           16,   105,    29,     2,   455,    83,    37,    52,    88,    15,\n",
      "           10,  2121,  3893,  9658,    10,    17,     3,   160,    21,     2,\n",
      "         5921,   150,  9247,  1065,     2,  1685, 14790,   929,     5])\n",
      "tensor([  270,  6206,   378,  1518,     2, 38675,    31,  2121,  3893,   929,\n",
      "           18])\n",
      "[tensor([12163, 56789]), tensor([12163, 56789]), tensor([12163, 56789])] [tensor([33, 34]), tensor([33, 34]), tensor([33, 34])]\n",
      "facing\n",
      "it\n",
      "tensor([ 2121,  3893,   929,    13,    32,   107,   697,   455,     8,  2612,\n",
      "            2,  6340,     4,     2,   238,  1221,   290,    16,  6206,    17,\n",
      "           19,     2,   535,   236,     5,    14,   107,  1221,  2953,    16,\n",
      "        38675,    17,  6340, 12163, 56789,  1186,     2,   238,  1221,  2953,\n",
      "           16, 49082,    17,  6340,   881, 20129,     0,     8,  7111,    40,\n",
      "          317,  2121,  3893,   712,     5,    14,   455,    13,   450,    24,\n",
      "          504,   783,     3,  2275,     3,    31, 36266,    23,  2070,     7,\n",
      "            2,   592,  2916,  1549,  3626,    31,  1649, 25470,     3,  1553,\n",
      "            5,   173,    51,    13,     2, 16882,  2121,  3893,     3,     2,\n",
      "          996,  5210,     2,    10,  4259,  4004,    10,    22,   296,  1534,\n",
      "           11, 10093,  6642,     3,    15,   104,    15,  4468, 19307,     2,\n",
      "          843,     4,  6895,   174,  2121,  3893,   455,    22,   204, 14790,\n",
      "           16,   105,    29,     2,   455,    83,    37,    52,    88,    15,\n",
      "           10,  2121,  3893,  9658,    10,    17,     3,   160,    21,     2,\n",
      "         5921,   150,  9247,  1065,     2,  1685, 14790,   929,     5])\n",
      "tensor([  270,  6206,   378,  1518,     2, 49082,    31,  2121,  3893,   929,\n",
      "           18])\n",
      "[tensor([  881, 20129]), tensor([  881, 20129]), tensor([  881, 20129])] [tensor([44, 45]), tensor([44, 45]), tensor([44, 45])]\n",
      "upraised\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "for i, (p, q, a, s) in enumerate(devset):\n",
    "    print(p)\n",
    "    print(q)\n",
    "    print(a,s)\n",
    "    nps = s[0].numpy()\n",
    "    tokens = tokenizer(trainset.data[i][0])\n",
    "    print(tokens[int(nps[0])])\n",
    "    print(tokens[nps[1]])\n",
    "    # print(tokens[a[0].numpy().item()])\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "           paragraph_pad_mask, question_pad_mask) in enumerate(trainloader):\n",
    "    # print(idx, padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "    #        paragraph_pad_mask, question_pad_mask)\n",
    "    # print(padded_paragraphs.masked_fill(paragraph_pad_mask == 1, -1))\n",
    "    if idx > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(trainset.get_vocab()['pad'], dev.get_vocab()['pad'])\n",
    "# devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_vec = torchtext.vocab.GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(vocab, pre_trained_emb_vec):\n",
    "    # print(pre_trained_emb_vec.dim)\n",
    "    weights_matrix = np.zeros((len(vocab), pre_trained_emb_vec.dim))\n",
    "    words_found = 0\n",
    "    no_word = 0\n",
    "    for i, (word, _) in enumerate(vocab.freqs.most_common()):\n",
    "        try:\n",
    "            # word_index = pre_trained_emb_vec.stoi[word]\n",
    "            # weights_matrix[i] = pre_trained_emb_vec[word_index]\n",
    "            weights_matrix[i] = pre_trained_emb_vec[word]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            no_word += 1 # no such word in pre_trained_embedding: zero vector\n",
    "    print('words not found:', no_word)\n",
    "    print('words found:', words_found)\n",
    "    return torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "tensor([ 8.9187e-02,  2.5792e-01,  2.6282e-01, -2.9365e-02,  4.7187e-01,\n",
      "        -1.0389e-01, -1.0013e-01,  8.1230e-02,  2.0883e-01,  2.5726e+00,\n",
      "        -6.7854e-01,  3.6121e-02,  1.3085e-01,  1.2462e-03,  1.4769e-01,\n",
      "         2.6926e-01,  3.7144e-01,  1.3501e+00, -1.1326e-01, -2.3036e-01,\n",
      "        -2.6575e-01, -1.8077e-01,  9.2455e-02, -1.6215e-01,  1.5003e-01,\n",
      "        -3.4547e-01,  7.2295e-02,  4.0659e-01,  1.0021e-02, -7.9257e-03,\n",
      "        -1.1435e-01,  1.7008e-02, -2.9789e-01,  1.9079e-01,  3.7112e-01,\n",
      "        -2.6588e-01,  1.6212e-01,  6.5469e-02, -3.1781e-01, -3.2260e-02,\n",
      "         8.1969e-02,  3.4450e-01, -1.7362e-01, -3.5745e-01,  5.4487e-02,\n",
      "         3.9941e-01,  1.3699e-01, -2.2066e-02,  1.1025e-01, -4.1898e-01,\n",
      "         1.2760e-01, -9.5869e-02, -1.7944e-01, -1.7443e-01,  2.7302e-01,\n",
      "        -1.9464e-01,  2.6747e-01, -2.8241e-01,  1.6380e-01, -1.1518e-01,\n",
      "         1.3196e-02, -1.0616e-01, -3.6093e-01,  2.3634e-02,  1.3464e-01,\n",
      "         2.1652e-02, -2.7094e-01, -1.8737e-02,  1.0017e-01,  3.6071e-01,\n",
      "        -9.3951e-02,  4.7634e-01,  1.2874e-01,  1.1868e-03,  1.3770e-01,\n",
      "        -1.4034e-01, -1.8870e-01, -1.6405e-01, -1.5349e-01,  3.2347e-01,\n",
      "        -1.7616e-01,  3.5230e-01, -2.3531e-02, -1.9121e-01, -5.4809e-02,\n",
      "        -9.9521e-02, -3.0056e-01,  3.6632e-01, -2.1509e-01,  7.4123e-02,\n",
      "        -2.0267e-01,  1.2860e-01, -3.8111e-01, -2.5482e-02,  4.5103e-01,\n",
      "         8.8633e-02,  3.6288e-01, -2.3406e-01, -8.6024e-02, -5.0604e-01,\n",
      "         3.4242e-02,  4.3998e-01, -8.3023e-02, -1.1969e-01,  6.8686e-01,\n",
      "        -3.4115e-01,  2.1228e-01,  4.0039e-01,  2.6367e-01, -3.7144e-01,\n",
      "         1.6206e-01, -4.2854e-01,  7.8658e-02, -2.9050e-01,  2.1727e-01,\n",
      "        -2.7484e-01,  3.5887e-01,  2.7055e-01, -1.1326e-01, -1.4848e-01,\n",
      "        -5.0659e-03, -7.6862e-02,  7.8621e-02, -2.4922e-01,  4.2026e-01,\n",
      "        -6.9698e-02,  7.1595e-02,  7.1665e-03,  2.7473e-01, -1.5664e-01,\n",
      "         2.5713e-01, -5.8461e-02, -2.9733e-01, -9.0996e-02,  5.2460e-01,\n",
      "         1.4889e-01, -2.0883e-01, -1.3004e-01, -2.0022e-01,  4.5030e-01,\n",
      "        -3.4654e-01, -2.6007e-01,  3.5247e-01, -3.4757e-01,  3.3738e-02,\n",
      "         1.9907e-01, -3.2912e-01, -8.4689e-02,  6.5319e-01,  2.0954e-01,\n",
      "         7.9274e-02,  1.0860e-01,  2.6466e-03, -1.2843e-01, -2.2811e-01,\n",
      "         5.1501e-02, -2.7429e-01,  1.4505e-01, -1.8430e-01, -3.4825e-01,\n",
      "        -1.1701e-01,  3.4034e-01,  7.5848e-02,  8.2390e-02, -3.9188e-01,\n",
      "        -2.2312e-02, -8.0373e-02,  1.4477e-01,  2.9701e-01, -1.0523e-01,\n",
      "         9.2893e-02,  2.9813e-02, -1.1761e-01,  1.6308e-01,  9.8382e-02,\n",
      "         4.6152e-01, -1.6200e-01, -2.4560e-01,  2.0293e-01, -1.1344e-01,\n",
      "         5.7902e-02, -1.9528e-01, -2.0141e-01, -2.2874e-01, -1.4101e-02,\n",
      "         2.6370e-01, -1.0028e-01, -5.1896e-02,  1.8859e-01, -1.7767e-01,\n",
      "        -1.1556e-01,  1.2100e-01,  1.7303e-01,  1.1773e-01,  3.4837e-02,\n",
      "         2.8485e-01, -3.0447e-01,  6.1024e-02, -2.6442e-01, -8.1135e-02,\n",
      "        -4.4524e-02, -3.6931e-02, -1.5217e-01,  2.9175e-01,  4.4926e-01,\n",
      "        -2.8875e-01,  3.3193e-01, -1.2420e-02, -1.8805e-01, -1.9832e-01,\n",
      "        -1.9736e-01,  2.6893e-01,  1.1106e-01, -6.7383e-01, -1.5180e-01,\n",
      "        -1.6615e-01, -1.6563e-01,  9.3671e-03, -1.5945e-01, -3.3468e-01,\n",
      "         2.2038e-01, -1.6724e-01, -1.5350e-01, -6.1782e-01, -1.7258e-01,\n",
      "         8.8928e-02,  1.9411e-02,  1.8296e-01,  3.2967e-01, -2.4906e-03,\n",
      "        -9.2080e-02,  5.1400e-01,  4.2484e-03, -8.4377e-02, -7.1448e-01,\n",
      "        -2.2148e-01, -4.8350e-02,  4.3761e-02, -2.9376e-01, -2.2287e-01,\n",
      "         1.8001e-01,  7.2197e-02,  4.6499e-01,  5.6466e-02,  4.0844e-01,\n",
      "        -2.3641e-01, -3.8946e-02,  8.7363e-02, -2.1901e-01, -3.2310e-01,\n",
      "        -1.9989e-01, -3.1280e-01, -6.7656e-02, -2.2596e-01,  9.0926e-02,\n",
      "         2.8365e-01,  3.1462e-01,  4.6082e-01, -2.4871e-02, -1.4605e-01,\n",
      "         3.0454e-01,  1.7704e-01, -1.1311e-02,  2.6807e-01, -3.2461e-02,\n",
      "        -1.6644e-01, -1.5313e-01, -2.0426e-01, -3.0820e-01, -2.4590e-01,\n",
      "         8.5848e-02, -1.1767e-01, -6.3056e-02, -1.8133e-01, -1.8629e-01,\n",
      "        -1.7694e-01,  2.9618e-01,  3.5987e-01,  2.0102e-03,  3.8616e-01,\n",
      "         3.6712e-01, -5.5112e-02, -3.4733e-01, -7.2678e-02, -5.1119e-02,\n",
      "        -2.9069e-01,  5.3598e-02,  1.9587e-02,  1.6808e-01, -2.7456e-01,\n",
      "        -9.7179e-02, -5.4541e-02,  1.9229e-01, -4.8128e-01, -2.0304e-01,\n",
      "         1.9368e-01, -3.2546e-01,  1.4421e-01, -1.6900e-01,  2.6501e-01])\n"
     ]
    }
   ],
   "source": [
    "# for key, value in vocab.freqs.items():\n",
    "#     if re.search(' ', key):\n",
    "#         print(key, value)\n",
    "# for i, word in enumerate(vocab.freqs.most_common()):\n",
    "#     print(word)\n",
    "#     if i > 5:\n",
    "#         break\n",
    "the, the_i = vocab.freqs.most_common()[5]\n",
    "word_index = glove_vec.stoi[the]\n",
    "print(word_index)\n",
    "print(glove_vec[the])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words not found: 0\n",
      "words found: 104026\n"
     ]
    }
   ],
   "source": [
    "word_emb_table = build_word_embedding(vocab, glove_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# glove_vec.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not using now\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser','ner',])\n",
    "#\n",
    "# def exact_match(paragraphs_indices, questions_indices, vocab):\n",
    "#     # process one paragraph batch, one question batch\n",
    "#     # print(paragraphs_indices.size())\n",
    "#     # print(questions_indices.size())\n",
    "#     #\n",
    "#     # j = 0\n",
    "#     # for (paragraph_indices, question_indices) in \\\n",
    "#     #         zip(paragraphs_indices, questions_indices):\n",
    "#     #     j += 1\n",
    "#     # print('j:',j)\n",
    "#     exact_match_table = np.zeros((len(paragraphs_indices), len(paragraphs_indices[0]), 3))\n",
    "#     # print(exact_match_table.shape)\n",
    "#\n",
    "#     for i, (paragraph_indices, question_indices) in \\\n",
    "#             enumerate(zip(paragraphs_indices, questions_indices)):\n",
    "#         # print(paragraphs_indices)\n",
    "#         # print(paragraphs_indices.size())\n",
    "#         # paragraph_processed = nlp(paragraph_sentence)\n",
    "#         # question_lemmas = [lem.lemma_ for lem in question_processed]\n",
    "#         for j, paragraph_index in enumerate(paragraph_indices):\n",
    "#             paragraph_word = vocab.itos[paragraph_index]\n",
    "#             if paragraph_word == '<pad>':\n",
    "#                 # print('got pad')\n",
    "#                 continue\n",
    "#             em_tensor = torch.LongTensor([0, 0, 0])\n",
    "#             # original\n",
    "#             if paragraph_index in question_indices:\n",
    "#                 em_tensor[0] = 1\n",
    "#             # lemma\n",
    "#             if vocab.stoi[nlp(paragraph_word)[0].lemma_] in question_indices:\n",
    "#                 em_tensor[1] = 1\n",
    "#             # uncased\n",
    "#             if vocab.stoi[paragraph_word.lower()] and \\\n",
    "#                     vocab.stoi[paragraph_word.lower()] in question_indices:\n",
    "#                 em_tensor[2] = 1\n",
    "#             exact_match_table[i][j] = em_tensor\n",
    "#\n",
    "#     return torch.LongTensor(exact_match_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim, input_dim)\n",
    "        self.linear2 = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, paragraph, question, question_pad_mask):\n",
    "\n",
    "        p = self.relu(self.linear1(paragraph))\n",
    "\n",
    "        # q = self.relu(self.linear2(question))\n",
    "\n",
    "        q = self.relu(self.linear1(question))\n",
    "        q = q.permute(0, 2, 1)\n",
    "\n",
    "        dot_product = torch.bmm(p, q)\n",
    "        # print(dot_product.size())\n",
    "        # print(question_pad_mask.size())\n",
    "        question_mask_expand = question_pad_mask.unsqueeze(1).expand(dot_product.size())\n",
    "        dot_product = dot_product.masked_fill(question_mask_expand == 1, -float('inf'))\n",
    "\n",
    "        attn_score = F.softmax(dot_product.view(-1, question.size(1)), dim=1)\n",
    "        attn_score = attn_score.view(-1, paragraph.shape[1], question.shape[1])\n",
    "\n",
    "        aligned_embedding = torch.bmm(attn_score, question)\n",
    "        return aligned_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerBiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstms.append(nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True))\n",
    "        for i in range(1, nlayers):\n",
    "            self.lstms.append(nn.LSTM(hidden_size * 2, hidden_size,\n",
    "                                      batch_first=True, bidirectional=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        lstm_output, _ = self.lstms[0](x)\n",
    "        hidden_states = [lstm_output]\n",
    "        # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "        for i in range(1, self.nlayers):\n",
    "            # lstm_output = self.dropout(lstm_output)\n",
    "            lstm_output, _ = self.lstms[i](lstm_output)\n",
    "            # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "            hidden_states.append(lstm_output)\n",
    "\n",
    "        output = torch.cat(hidden_states, dim=2)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncoding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm_output_size = hidden_size * 6\n",
    "        self.linear = nn.Linear(self.lstm_output_size, 1)\n",
    "        self.lstm = MultiLayerBiLSTM(input_size, hidden_size, nlayers, dropout)\n",
    "        # biLSTM output size: hidden size * 6\n",
    "    def forward(self, x, question_mask):\n",
    "        try:\n",
    "            x = self.lstm(x)\n",
    "            b = x.contiguous().view(-1, x.size(-1))\n",
    "            b = self.linear(b) # attention score\n",
    "            b = b.view(x.shape[0], -1)\n",
    "            # print(x.size(), question_mask.size())\n",
    "            b = b.masked_fill(question_mask == 1, -float('inf')) # masking\n",
    "            b = F.softmax(b, dim=1)\n",
    "\n",
    "            encoding = b.unsqueeze(1).bmm(x).squeeze(1)\n",
    "            # print(x.size(), x_lstm.size())\n",
    "            return encoding\n",
    "        except:\n",
    "            print('question mask size:', question_mask.size())\n",
    "            print('x size:', x.size())\n",
    "            print('b size:', b.size())\n",
    "            print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionLayer(nn.Module):\n",
    "    def __init__(self, p_size, q_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(q_size, p_size)\n",
    "\n",
    "    def forward(self, paragraph, question, paragraph_mask):\n",
    "        Wq = self.linear(question)\n",
    "        pWq = paragraph.bmm(Wq.unsqueeze(2)).squeeze(2)\n",
    "        pWq = pWq.masked_fill(paragraph_mask == 1, -float('inf'))\n",
    "        return pWq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fixate_embedding(grad):\n",
    "    grad[1000:] = 0\n",
    "    return grad\n",
    "\n",
    "class DocumentReader(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, nlayers, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_emb_table).to(device), freeze=False)\n",
    "        self.word_embedding_layer.weight.register_hook(fixate_embedding)\n",
    "        # print(embedding_size)\n",
    "        self.aligned_embedding_layer = AlignedQuestionEmbedding(embedding_size)\n",
    "        # self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2 + 3, hidden_size, nlayers, dropout)\n",
    "        self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.question_encoder = QuestionEncoding(embedding_size, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.prediction_layer_start = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                          hidden_size * nlayers * 2)\n",
    "        self.prediction_layer_end = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                        hidden_size * nlayers * 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, paragraph, question, paragraph_mask, question_mask):\n",
    "        # em_embedding = exact_match(paragraph, question, vocab)\n",
    "        # print(em_embedding.size())\n",
    "        p_word_embedding = self.word_embedding_layer(paragraph)\n",
    "        q_word_embedding = self.word_embedding_layer(question)\n",
    "        p_word_embedding = self.dropout(p_word_embedding)\n",
    "        q_word_embedding = self.dropout(q_word_embedding)\n",
    "        aligned_embedding = self.aligned_embedding_layer(p_word_embedding, q_word_embedding, question_mask)\n",
    "        # print(p_word_embedding.size())\n",
    "        # print(aligned_embedding.size())\n",
    "        paragraph_embeddings = torch.cat([p_word_embedding, aligned_embedding], dim=2)\n",
    "\n",
    "        # paragraph_embeddings = torch.cat([em_embedding.to(device), p_word_embedding.to(device), aligned_embedding.to(device)], dim=2)\n",
    "        paragraph_encoding = self.paragraph_lstm(paragraph_embeddings)\n",
    "        # print(question.size(), question_mask.size())\n",
    "        question_encoding = self.question_encoder(q_word_embedding, question_mask)\n",
    "\n",
    "        prediction_start = self.prediction_layer_start(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "        prediction_end = self.prediction_layer_end(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "\n",
    "        return prediction_start, prediction_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "EMB_SIZE = 300\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# dataiter_next = dataiter.next()\n",
    "# print(dataiter_next)\n",
    "# (p, q, a, s, p_mask, q_mask) = dataiter.next()\n",
    "# writer.add_graph(model, p, p_mask, q_mask)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters())\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, train_dataset):\n",
    "    '''\n",
    "    Trains the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start training ........\")\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    # put the model in training mode\n",
    "    model.train()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    try:\n",
    "        for i, (paragraphs, questions, span_list, answer_list,\n",
    "                paragraph_mask, question_mask) in enumerate(train_dataset):\n",
    "            # if i < 575:\n",
    "            #     continue\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "            # place the tensors on GPU\n",
    "            paragraphs = paragraphs.to(device)\n",
    "            paragraph_mask = paragraph_mask.to(device)\n",
    "            questions = questions.to(device)\n",
    "            question_mask = question_mask.to(device)\n",
    "            # span_list = span_list.to(device)\n",
    "\n",
    "            # forward pass, get the predictions\n",
    "            preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "            start_pred, end_pred = preds\n",
    "\n",
    "            # print('preds:', start_pred, end_pred)\n",
    "            # separate labels for start and end position\n",
    "            span_start = []\n",
    "            span_end = []\n",
    "            for span in span_list:\n",
    "                span_start.append(span[0][0].item())\n",
    "                span_end.append(span[0][1].item())\n",
    "\n",
    "            # print('span:', span_start, span_end)\n",
    "            span_start = torch.LongTensor(span_start).to(device)\n",
    "            span_end = torch.LongTensor(span_end).to(device)\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(start_pred, span_start) + F.cross_entropy(end_pred, span_end)\n",
    "\n",
    "            # backward pass, calculates the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    "            # zero the gradients to prevent them from accumulating\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "    except Exception as e:\n",
    "        print(f'sizes of pred:{start_pred.size()} / span:{span_start.size()}')\n",
    "        print(f'span_start: {span_start[23]}\\nspan_end: {span_end[23]}')\n",
    "        print(f'i: {i}')\n",
    "        print(f'paragraph: {paragraphs}')\n",
    "        bad_p = paragraphs.numpy()[23]\n",
    "        bad_q = questions.numpy()[23]\n",
    "        bad_p_text = [vocab.itos[pi] for pi in bad_p]\n",
    "        bad_q_text = [vocab.itos[qi] for qi in bad_q]\n",
    "        bad_p_text = ' '.join(bad_p_text)\n",
    "        bad_q_text = ' '.join(bad_q_text)\n",
    "\n",
    "        print(bad_p_text)\n",
    "        print(bad_q_text)\n",
    "        print(f'paragraph size: {paragraphs.size()}, question size: {questions.size()}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "    return train_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %time train_loss = train(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, test_dataset):\n",
    "    '''\n",
    "    Validates the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start validation ........\")\n",
    "\n",
    "    val_loss = 0.\n",
    "    emScore = 0\n",
    "    f1Score = 0\n",
    "    # put the model in eval mode\n",
    "    model.eval()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    for i, (paragraphs, questions, span_list, answer_list,\n",
    "            paragraph_mask, question_mask) in enumerate(test_dataset):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "        # place the tensors on GPU\n",
    "        paragraphs = paragraphs.to(device)\n",
    "        paragraph_mask = paragraph_mask.to(device)\n",
    "        questions = questions.to(device)\n",
    "        question_mask = question_mask.to(device)\n",
    "        # span_list = span_list.to(device)\n",
    "\n",
    "        # forward pass, get the predictions\n",
    "        preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "        start_pred, end_pred = preds\n",
    "        # print('preds:', start_pred, end_pred)\n",
    "        log_softmax = nn.LogSoftmax(dim=1) # batchwise log softmax\n",
    "        pred_table = log_softmax(start_pred).unsqueeze(2) + log_softmax(end_pred).unsqueeze(1)\n",
    "        pred_mask1 = (torch.ones_like(pred_table) * -float('inf')).tril(diagonal=-1)# start index <= end index\n",
    "        pred_mask2 = (torch.ones_like(pred_table) * -float('inf')).triu(diagonal=16)\n",
    "        pred_table += pred_mask1 + pred_mask2\n",
    "\n",
    "        start_pred_argmax = []\n",
    "        end_pred_argmax = []\n",
    "        paragraph_length = pred_table.shape[-1]\n",
    "        for batch in pred_table:\n",
    "            arg_max = batch.argmax()\n",
    "            start_pred_argmax.append(arg_max // paragraph_length)\n",
    "            end_pred_argmax.append(arg_max % paragraph_length)\n",
    "\n",
    "        # separate labels for start and end position\n",
    "        span_start = []\n",
    "        span_end = []\n",
    "        true_answers_list = []\n",
    "        my_answers = []\n",
    "        for paragraph, spans, answers, sp, ep in \\\n",
    "                zip(paragraphs, span_list, answer_list, start_pred_argmax, end_pred_argmax):\n",
    "            span_start.append([span[0].item() for span in spans][:3])\n",
    "            span_end.append([span[1].item() for span in spans][:3])\n",
    "            true_answers_list.append([ans2txt(answer) for answer in answers])\n",
    "            if sp > ep or ep > sp + 15:\n",
    "                print(f'wrong range, sp:{sp}, ep:{ep} ')\n",
    "            my_answers.append(span2txt([sp, ep + 1], paragraph))\n",
    "        with torch.no_grad():\n",
    "            # print('span:', span_start, span_end)\n",
    "            try:\n",
    "                span_start = torch.LongTensor(span_start).to(device)\n",
    "                span_end = torch.LongTensor(span_end).to(device)\n",
    "                # calculate loss\n",
    "                loss = [F.cross_entropy(start_pred, span_start.t()[i]) +\n",
    "                        F.cross_entropy(end_pred, span_end.t()[i]) for i in range(3)]\n",
    "                loss = min(loss)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                emScore += em_batch(my_answers, true_answers_list)\n",
    "                f1Score += f1_batch(my_answers, true_answers_list)\n",
    "            except:\n",
    "                print('start pred:', start_pred)\n",
    "                print('start pred shape:', start_pred.shape)\n",
    "                print('span_list:', span_list)\n",
    "                print('span_list length:', len(span_list))\n",
    "                print('span_start:', span_start)\n",
    "                print('span_start shape:', np.asarray(span_start).shape)\n",
    "                print('span_end:', span_end)\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    return val_loss / len(test_dataset), emScore / len(test_dataset), f1Score / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def normalize_answer(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('','',punctuation))\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def em_batch(my_answers, true_answers_list):\n",
    "    # true_answers_list: batch size * 3\n",
    "    em = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        for true_answer in true_answers:\n",
    "            if my_answer == true_answer:\n",
    "                em += 1\n",
    "                break\n",
    "    return em / BATCH_SIZE\n",
    "\n",
    "def f1_batch(my_answers, true_answers_list):\n",
    "    f1Batch = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        f1_single = 0\n",
    "        for true_answer in true_answers:\n",
    "            my_answer_split = my_answer.split()\n",
    "            true_answer_split = true_answer.split()\n",
    "            common = Counter(my_answer_split) & Counter(true_answer_split)\n",
    "            num_intersection = sum(common.values())\n",
    "            if num_intersection == 0:\n",
    "                continue\n",
    "            precision = num_intersection / len(my_answer_split)\n",
    "            recall = num_intersection / len(true_answer_split)\n",
    "            f1_single = max((2 * precision * recall) / (precision + recall), f1_single)\n",
    "        f1Batch += f1_single\n",
    "        # if f1_single < 0.9:\n",
    "        #     print('my answer split:', my_answer_split)\n",
    "        #     print('true answer split:', true_answer_split)\n",
    "    return f1Batch / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def span2txt(span, paragraph):\n",
    "    # print(span[0].item())\n",
    "    my_answer = paragraph[int(span[0].item()) : int(span[1].item()) + 1]\n",
    "    return ans2txt(my_answer)\n",
    "def ans2txt(answer):\n",
    "    words = []\n",
    "    for a_index in answer:\n",
    "        words.append(vocab.itos[a_index.item()])\n",
    "    return normalize_answer(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_val_loss = 100\n",
    "path = 'best.pt'\n",
    "if os.path.isfile(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "else:\n",
    "    epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring epoch 0\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0050013065338134766\n",
      "Starting batch: 500, time: 81.43470644950867\n",
      "Starting batch: 1000, time: 162.25667095184326\n",
      "Starting batch: 1500, time: 243.18249225616455\n",
      "Starting batch: 2000, time: 324.57894706726074\n",
      "Starting batch: 2500, time: 405.11105012893677\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001967191696166992\n",
      "train_loss: 6.0263854265661, val_loss: 5.161805994262106\n",
      "em_score: 21.428571428571427, f1_score: 43.86407851211354\n",
      "End epoch 0, elapsed time: 444.7756576538086\n",
      "Staring epoch 1\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00799870491027832\n",
      "Starting batch: 500, time: 83.46359395980835\n",
      "Starting batch: 1000, time: 167.72872853279114\n",
      "Starting batch: 1500, time: 251.7063910961151\n",
      "Starting batch: 2000, time: 333.6815586090088\n",
      "Starting batch: 2500, time: 417.82392406463623\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010228157043457031\n",
      "train_loss: 4.808474817655894, val_loss: 4.59541831421576\n",
      "em_score: 24.251930501930502, f1_score: 48.84279954592826\n",
      "End epoch 1, elapsed time: 456.38607907295227\n",
      "Staring epoch 2\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007992744445800781\n",
      "Starting batch: 500, time: 82.07372689247131\n",
      "Starting batch: 1000, time: 163.72314763069153\n",
      "Starting batch: 1500, time: 244.95012712478638\n",
      "Starting batch: 2000, time: 327.2952244281769\n",
      "Starting batch: 2500, time: 406.86201906204224\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001001119613647461\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "train_loss: 4.390972522809424, val_loss: 4.471015941222202\n",
      "em_score: 26.833976833976834, f1_score: 51.13060234451733\n",
      "End epoch 2, elapsed time: 447.4070875644684\n",
      "Staring epoch 3\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004999876022338867\n",
      "Starting batch: 500, time: 81.35409164428711\n",
      "Starting batch: 1000, time: 164.71137356758118\n",
      "Starting batch: 1500, time: 246.25974917411804\n",
      "Starting batch: 2000, time: 328.21548557281494\n",
      "Starting batch: 2500, time: 410.37480545043945\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001997232437133789\n",
      "train_loss: 4.1085603103652035, val_loss: 4.272226685262555\n",
      "em_score: 27.52171814671815, f1_score: 52.58381712039287\n",
      "End epoch 3, elapsed time: 449.20839858055115\n",
      "Staring epoch 4\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004999637603759766\n",
      "Starting batch: 500, time: 81.05834007263184\n",
      "Starting batch: 1000, time: 163.98023629188538\n",
      "Starting batch: 1500, time: 243.9474573135376\n",
      "Starting batch: 2000, time: 328.01073265075684\n",
      "Starting batch: 2500, time: 409.2548234462738\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009663105010986328\n",
      "train_loss: 3.885631332806025, val_loss: 4.164055904366335\n",
      "em_score: 28.40250965250965, f1_score: 53.81079528875341\n",
      "End epoch 4, elapsed time: 447.2133047580719\n",
      "Staring epoch 5\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0050008296966552734\n",
      "Starting batch: 500, time: 82.52630019187927\n",
      "Starting batch: 1000, time: 165.5573387145996\n",
      "Starting batch: 1500, time: 248.86944341659546\n",
      "Starting batch: 2000, time: 331.04696226119995\n",
      "Starting batch: 2500, time: 413.73308753967285\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0020017623901367188\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "train_loss: 3.704577702904321, val_loss: 4.101605261614885\n",
      "em_score: 29.06611969111969, f1_score: 55.10423915939875\n",
      "End epoch 5, elapsed time: 452.77047300338745\n",
      "Staring epoch 6\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004000186920166016\n",
      "Starting batch: 500, time: 83.54726672172546\n",
      "Starting batch: 1000, time: 165.57339453697205\n",
      "Starting batch: 1500, time: 246.2260706424713\n",
      "Starting batch: 2000, time: 327.60466170310974\n",
      "Starting batch: 2500, time: 415.040815114975\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001997709274291992\n",
      "train_loss: 3.545884408569121, val_loss: 4.091742405099758\n",
      "em_score: 28.752413127413128, f1_score: 54.74202271295459\n",
      "End epoch 6, elapsed time: 456.02514481544495\n",
      "Staring epoch 7\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004963397979736328\n",
      "Starting batch: 500, time: 94.3750011920929\n",
      "Starting batch: 1000, time: 181.61150550842285\n",
      "Starting batch: 1500, time: 262.5589442253113\n",
      "Starting batch: 2000, time: 345.2833294868469\n",
      "Starting batch: 2500, time: 429.79023241996765\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019769668579101562\n",
      "train_loss: 3.402970434982317, val_loss: 3.9852190708101487\n",
      "em_score: 30.01930501930502, f1_score: 56.362908471433556\n",
      "End epoch 7, elapsed time: 469.63854026794434\n",
      "Staring epoch 8\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004934549331665039\n",
      "Starting batch: 500, time: 81.37391948699951\n",
      "Starting batch: 1000, time: 163.36267566680908\n",
      "Starting batch: 1500, time: 245.47556471824646\n",
      "Starting batch: 2000, time: 329.50448989868164\n",
      "Starting batch: 2500, time: 411.427672624588\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010075569152832031\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "train_loss: 3.262832792393922, val_loss: 3.941951347133828\n",
      "em_score: 30.091698841698843, f1_score: 56.65394372683017\n",
      "End epoch 8, elapsed time: 450.2847943305969\n",
      "Staring epoch 9\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004000186920166016\n",
      "Starting batch: 500, time: 81.1412456035614\n",
      "Starting batch: 1000, time: 165.5577268600464\n",
      "Starting batch: 1500, time: 248.57583904266357\n",
      "Starting batch: 2000, time: 331.486115694046\n",
      "Starting batch: 2500, time: 413.16082191467285\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010325908660888672\n",
      "train_loss: 3.1535495324315814, val_loss: 4.114791856309162\n",
      "em_score: 29.198841698841697, f1_score: 55.911359956229525\n",
      "End epoch 9, elapsed time: 452.68237829208374\n",
      "Staring epoch 10\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004999876022338867\n",
      "Starting batch: 500, time: 82.67450666427612\n",
      "Starting batch: 1000, time: 164.4729197025299\n",
      "Starting batch: 1500, time: 246.10853791236877\n",
      "Starting batch: 2000, time: 329.18127059936523\n",
      "Starting batch: 2500, time: 412.98428177833557\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009629726409912109\n",
      "train_loss: 3.034202712364369, val_loss: 4.102919616294184\n",
      "em_score: 29.283301158301157, f1_score: 56.09246654628778\n",
      "End epoch 10, elapsed time: 452.30114698410034\n",
      "Staring epoch 11\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.006001472473144531\n",
      "Starting batch: 500, time: 84.7389304637909\n",
      "Starting batch: 1000, time: 167.62414622306824\n",
      "Starting batch: 1500, time: 248.69583249092102\n",
      "Starting batch: 2000, time: 330.3354330062866\n",
      "Starting batch: 2500, time: 413.26520228385925\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002024412155151367\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "train_loss: 2.922466822021754, val_loss: 4.012946913141081\n",
      "em_score: 30.248552123552123, f1_score: 56.8400458590646\n",
      "End epoch 11, elapsed time: 452.6666467189789\n",
      "Staring epoch 12\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004000425338745117\n",
      "Starting batch: 500, time: 81.27030348777771\n",
      "Starting batch: 1000, time: 163.48566031455994\n",
      "Starting batch: 1500, time: 243.85945796966553\n",
      "Starting batch: 2000, time: 327.2328140735626\n",
      "Starting batch: 2500, time: 410.9941191673279\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010035037994384766\n",
      "train_loss: 2.8181832531079993, val_loss: 4.063969462074368\n",
      "em_score: 30.381274131274132, f1_score: 57.02735606196663\n",
      "End epoch 12, elapsed time: 449.8970880508423\n",
      "Staring epoch 13\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.006999492645263672\n",
      "Starting batch: 500, time: 80.70571303367615\n",
      "Starting batch: 1000, time: 164.2076313495636\n",
      "Starting batch: 1500, time: 246.6796305179596\n",
      "Starting batch: 2000, time: 329.4700508117676\n",
      "Starting batch: 2500, time: 412.1093649864197\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009844303131103516\n",
      "train_loss: 2.72174301621431, val_loss: 4.118961807843801\n",
      "em_score: 29.946911196911195, f1_score: 57.10687401597806\n",
      "End epoch 13, elapsed time: 451.87267899513245\n",
      "Staring epoch 14\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.005994081497192383\n",
      "Starting batch: 500, time: 82.47287559509277\n",
      "Starting batch: 1000, time: 165.61961388587952\n",
      "Starting batch: 1500, time: 246.81715440750122\n",
      "Starting batch: 2000, time: 330.22319054603577\n",
      "Starting batch: 2500, time: 412.02100825309753\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019686222076416016\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-07.\n",
      "train_loss: 2.6328747390311986, val_loss: 4.2193451590519615\n",
      "em_score: 29.886583011583014, f1_score: 56.04613117369021\n",
      "End epoch 14, elapsed time: 449.59043765068054\n",
      "Staring epoch 15\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004968404769897461\n",
      "Starting batch: 500, time: 81.57091236114502\n",
      "Starting batch: 1000, time: 165.17949604988098\n",
      "Starting batch: 1500, time: 250.59096121788025\n",
      "Starting batch: 2000, time: 333.11046957969666\n",
      "Starting batch: 2500, time: 415.16435170173645\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019991397857666016\n",
      "train_loss: 2.5414900149406683, val_loss: 4.1538202974326826\n",
      "em_score: 29.57287644787645, f1_score: 56.830386539400216\n",
      "End epoch 15, elapsed time: 454.17509841918945\n",
      "Staring epoch 16\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004000186920166016\n",
      "Starting batch: 500, time: 80.52034997940063\n",
      "Starting batch: 1000, time: 162.93688893318176\n",
      "Starting batch: 1500, time: 245.57811737060547\n",
      "Starting batch: 2000, time: 328.6919276714325\n",
      "Starting batch: 2500, time: 410.7961573600769\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009717941284179688\n",
      "train_loss: 2.4527021726241287, val_loss: 4.233545951401405\n",
      "em_score: 29.8503861003861, f1_score: 56.61153349673948\n",
      "End epoch 16, elapsed time: 449.10238242149353\n",
      "Staring epoch 17\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.005951642990112305\n",
      "Starting batch: 500, time: 80.67257046699524\n",
      "Starting batch: 1000, time: 163.60761713981628\n",
      "Starting batch: 1500, time: 245.71753311157227\n",
      "Starting batch: 2000, time: 329.6368360519409\n",
      "Starting batch: 2500, time: 412.79320001602173\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001986265182495117\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-08.\n",
      "train_loss: 2.370543424189875, val_loss: 4.419718620859978\n",
      "em_score: 29.597007722007724, f1_score: 55.87280423079199\n",
      "End epoch 17, elapsed time: 450.56609654426575\n",
      "Staring epoch 18\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0039827823638916016\n",
      "Starting batch: 500, time: 81.36462116241455\n",
      "Starting batch: 1000, time: 162.04015684127808\n",
      "Starting batch: 1500, time: 245.31105709075928\n",
      "Starting batch: 2000, time: 327.70684719085693\n",
      "Starting batch: 2500, time: 411.6078712940216\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001033782958984375\n",
      "train_loss: 2.2979368592330003, val_loss: 4.353962710004976\n",
      "em_score: 29.584942084942085, f1_score: 56.049494431910674\n",
      "End epoch 18, elapsed time: 449.9433603286743\n",
      "Staring epoch 19\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00500035285949707\n",
      "Starting batch: 500, time: 81.91720581054688\n",
      "Starting batch: 1000, time: 163.86606001853943\n",
      "Starting batch: 1500, time: 244.7857050895691\n",
      "Starting batch: 2000, time: 338.16984486579895\n",
      "Starting batch: 2500, time: 420.2376308441162\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010004043579101562\n",
      "train_loss: 2.2279409185158316, val_loss: 4.408888672309493\n",
      "em_score: 29.51254826254826, f1_score: 56.066877172745386\n",
      "End epoch 19, elapsed time: 459.88912558555603\n",
      "Staring epoch 20\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00800180435180664\n",
      "Starting batch: 500, time: 80.7331268787384\n",
      "Starting batch: 1000, time: 164.5573980808258\n",
      "Starting batch: 1500, time: 245.62028336524963\n",
      "Starting batch: 2000, time: 326.7482690811157\n",
      "Starting batch: 2500, time: 409.29009795188904\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009770393371582031\n",
      "train_loss: 2.1516682467304733, val_loss: 4.522437264560272\n",
      "em_score: 29.80212355212355, f1_score: 56.25808659483362\n",
      "End epoch 20, elapsed time: 448.09387159347534\n",
      "Staring epoch 21\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.006991147994995117\n",
      "Starting batch: 500, time: 83.020174741745\n",
      "Starting batch: 1000, time: 165.79885721206665\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-123-f14a8b3720e7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mtrain_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mval_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memScore\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf1Score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtestloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mscheduler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-117-6071de007764>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_dataset)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m             \u001B[1;31m# backward pass, calculates the gradients\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m             \u001B[1;31m# gradient clipping\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 245\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    143\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 145\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "epoch_start = max(epoch, 0)\n",
    "for epoch in range(epoch_start, epoch_start + 50):\n",
    "    print(f'Staring epoch {epoch}')\n",
    "    start_time = time()\n",
    "\n",
    "    train_loss = train(model, trainloader)\n",
    "    val_loss, emScore, f1Score = validate(model, testloader)\n",
    "    scheduler.step(val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    em_scores.append(emScore * 100)\n",
    "    f1_scores.append(f1Score * 100)\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            }, path)\n",
    "    end_time = time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "    print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')\n",
    "    print(f'End epoch {epoch}, elapsed time: {time_elapsed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(train_losses)\n",
    "    writer.writerow(val_losses)\n",
    "    writer.writerow(em_scores)\n",
    "    writer.writerow(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# val_loss, emScore, f1Score = validate(model, testloader)\n",
    "# print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "# print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(epoch - len(train_losses) + 1, epoch + 1)], train_losses)\n",
    "plt.plot([i for i in range(epoch - len(val_losses) + 1, epoch + 1)], val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('CE losses')\n",
    "plt.title('Training Result')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(epoch - len(em_scores) + 1, epoch + 1)], em_scores)\n",
    "plt.plot([i for i in range(epoch - len(f1_scores) + 1, epoch + 1)], f1_scores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores on SQuAD 1.1')\n",
    "plt.legend(['EM', 'F1'])\n",
    "plt.xticks([i for i in range(1, len(f1_scores) + 1)])\n",
    "plt.yticks(np.arange(15, 70, 5))\n",
    "plt.savefig(f\"best{epoch - len(f1_scores) + 1}-{epoch}.png\", dpi=350)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# for i, t_data in enumerate(testloader):\n",
    "#     idx = i\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (p, q, s, a, p_mask, q_mask), p 길이 점점 증가\n",
    "# p, q: tensor, batch size * length\n",
    "# s: tuple of tensors, batch size\n",
    "# a:\n",
    "# dataiter = iter(trainloader)\n",
    "# dataiter_next = dataiter.next()\n",
    "# dataiter_next[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# for i in range(100):\n",
    "#     dataiter_100 = dataiter.next()\n",
    "# dataiter_100[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start_pred.shape\n",
    "# start_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "# print(start_pred_argmax)\n",
    "# print(span_list)\n",
    "# print(span_list[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for p, s, a in zip(paragraphs, span_list, answer_list):\n",
    "    i += 1\n",
    "    if i < 3:\n",
    "        print(p)\n",
    "        print(s)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# em_score = 0\n",
    "# for i, (p, s, a) in enumerate(list(zip(paragraphs, span_list, answer_list))):\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     if i < 3:\n",
    "#         # print(p)\n",
    "#         # print(s)\n",
    "#         # print(a)\n",
    "#         em_score += em_func(p, a[0], s)\n",
    "# print(em_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainloader length: 2700\n",
    "# testloader length: 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "import os\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:25<00:00, 3463.57lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import SQuAD1\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# data_dir = '.data'\n",
    "# data_names = ['dev-v1.1.json', 'train-v1.1.json']\n",
    "# for data_name in data_names:\n",
    "#     if not os.path.isfile(os.path.join(data_dir, data_name)):\n",
    "#         print('download')\n",
    "#         train, dev = SQuAD1()\n",
    "#         break\n",
    "# trainset, devset = SQuAD1()\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# dataset shape: (paragraph, question, answer, span)\n",
    "trainset, devset = SQuAD1(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = trainset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# trainset_1 = trainset[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "whitespace_string_dev = []\n",
    "whitespace_string_train = []\n",
    "for i, (p, q, a, s) in enumerate(devset.data):\n",
    "    if(len(re.findall('  ', p + q)) > 0):\n",
    "        whitespace_string_dev.append(i)\n",
    "    for answer in a:\n",
    "        if(len(re.findall('  ', answer)) > 0):\n",
    "            whitespace_string_dev.append(i)\n",
    "            break\n",
    "for i, (p, q, a, s) in enumerate(trainset.data):\n",
    "    if(len(re.findall('  ', p + q)) > 0):\n",
    "        whitespace_string_train.append(i)\n",
    "    for answer in a:\n",
    "        if(len(re.findall('  ', answer)) > 0):\n",
    "            whitespace_string_train.append(i)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235, 408, 593, 1094, 1300, 1304, 1305, 1306, 1307, 1308, 1309, 1690, 1766, 1807, 1815, 1868, 1869, 1870, 2170, 2184, 2187, 2245, 2266, 2323, 2380, 2383, 2390, 2433, 2486, 2516, 2582, 2623, 2766, 2865, 2877, 2878, 2879, 2880, 2881, 2955, 3019, 3031, 3076, 3077, 3078, 3079, 3336, 3496, 3503, 3509, 3517, 3521, 3550, 3575, 3595, 3672, 3675, 3754, 4138, 4360, 4518, 4524, 4533, 4630, 4631, 4637, 4645, 4659, 4665, 4834, 4865, 4866, 4880, 4882, 4883, 4884, 4885, 4886, 4987, 5386, 5387, 5388, 5389, 5390, 5565, 5987, 5988, 5989, 5990, 6576, 6794, 7350, 7550, 8050, 8455, 8456, 8457, 8457, 8458, 9026, 9027, 9027, 9028, 9029, 9030, 9051, 9052, 9053, 9054, 9055, 9080, 9460, 9645, 9646, 9647, 9648, 9649, 10084, 10171, 10272, 10275, 10380, 10391, 10471, 10472, 10473, 10474, 10475, 10480, 10481, 10482, 10483, 10493, 10504, 10539, 10540, 10541, 10542, 10546, 10547, 10548, 10549, 10550]\n",
      "143\n",
      "1322\n"
     ]
    }
   ],
   "source": [
    "print(whitespace_string_dev)\n",
    "print(len(whitespace_string_dev))\n",
    "print(len(whitespace_string_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([   14, 20129, 11824,     3,    29,   182,     2,  6206,     7,  7502,\n            16,  1562,  1578,    17,     3,    13,  9130,    22,  6354,     3,\n         20196,   522,  4493,  3893, 20734,     5,  4493,  3893, 19284, 40929,\n          5422,    43,    46,     4,    36,   513,  1620,     3, 11234,    19,\n             0,  6328,     6, 43325,    19,     0,     3,   109,  1605,     9,\n          2009,    11,   136,     6,   996,    11,   609,  2506,   347, 92741,\n            16,  2349,  3632,     3,   312, 43325,    17,     3,     9,  2009,\n            11,   426,   312,     0,     3,     6,     9,  2009,    11,   513,\n         19284,  4399,     4, 98271,     5,  5422,    23,   609, 11546,    27,\n         14499,   179, 11764, 39332,     3,    57,  6239,     9,  2009,    11,\n           136,  7047,  5446,    19,     0,  6328,     6,   860, 92741,     3,\n             6,  1012,  5686,  9918,     0,     3,  3573,     3,    57,  6239,\n          4488,  5446,    19, 55942,  6328,     6,   312, 92741,    44,     0,\n            41, 19633,    19,  1509,  6328,     6,  1022,  1666,     0,    19,\n         65828,  6328,     5,   400,  1290, 11546,   309, 12147,     0,     0,\n            16,  6460, 22973,    19, 52960,  6328,    17,     3, 20327,     0,\n             0,    16,  1669, 22973,    19, 32570,  6328,     6,   264, 92741,\n            17,     3,     6,   172,    11,    82,  5686, 23668,  2502,    16,\n          1669, 22973,    19, 66185,  6328,    17,     5,    14, 20129,     0,\n          1440,  4493,  3893,  1372,   322,  7320,  8437,     3,    57,   182,\n             2,   378,    22,     0, 43325,  6328,     6,   522, 92741,     7,\n          1048,   596,     3,   251,    22,  4493,  3893,     0,  5600, 36499,\n             3,    57, 19633,    19, 12608,  6328,     6,  6239,   759,  5446,\n            19,   275, 15601,  6328,     5,   881,    23,  4054,   356,    41,\n          1440,    63,  4493,  3893, 20734,    68,   676,  5436,     0,     6,\n          6196,     0,  5069,     5]),\n tensor([  121,    54, 22973,    49,     0,   844,  1209,    19,     2,   535,\n           236,    18]),\n [tensor([6460]), tensor([6460]), tensor([6460])],\n [tensor([124, 124]), tensor([151, 151]), tensor([151, 151])])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset[235]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(\"The Panthers offense, which led the NFL in scoring (500 points), was loaded with talent, boasting six Pro Bowl selections. Pro Bowl quarterback Cam Newton had one of his best seasons, throwing for 3,837 yards and rushing for 636, while recording a career-high and league-leading 45 total touchdowns (35 passing, 10 rushing), a career-low 10 interceptions, and a career-best quarterback rating of 99.4. Newton's leading receivers were tight end Greg Olsen, who caught a career-high 77 passes for 1,104 yards and seven touchdowns, and wide receiver Ted Ginn, Jr., who caught 44 passes for 739 yards and 10 touchdowns; Ginn also rushed for 60 yards and returned 27 punts for 277 yards. Other key receivers included veteran Jerricho Cotchery (39 receptions for 485 yards), rookie Devin Funchess (31 receptions for 473 yards and five touchdowns), and second-year receiver Corey Brown (31 receptions for 447 yards). The Panthers backfield featured Pro Bowl running back Jonathan Stewart, who led the team with 989 rushing yards and six touchdowns in 13 games, along with Pro Bowl fullback Mike Tolbert, who rushed for 256 yards and caught 18 passes for another 154 yards. Carolina's offensive line also featured two Pro Bowl selections: center Ryan Kalil and guard Trai Turner.\",\n 'How many receptions did Cotchery  get for the 2015 season?',\n ['39', '39', '39'],\n [588, 739, 739])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset.data[235]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "844"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi[' ']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "whitespace_tokens_dev = []\n",
    "whitespace_tokens_train = []\n",
    "blank_token = vocab.stoi[' ']\n",
    "for i, (p, q, a, _) in enumerate(devset):\n",
    "    if (blank_token in p) or (blank_token in q):\n",
    "        whitespace_tokens_dev.append(i)\n",
    "    for answer in a:\n",
    "        if blank_token in answer:\n",
    "            whitespace_tokens_dev.append(i)\n",
    "            break\n",
    "for i, (p, q, a, _) in enumerate(trainset):\n",
    "    if (blank_token in p) or (blank_token in q):\n",
    "        whitespace_tokens_train.append(i)\n",
    "    for answer in a:\n",
    "        if blank_token in answer:\n",
    "            whitespace_tokens_train.append(i)\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "1530\n"
     ]
    }
   ],
   "source": [
    "print(len(whitespace_tokens_dev))\n",
    "print(len(whitespace_tokens_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# errors = 0\n",
    "# print('length of vocab before filtering:', len(vocab.stoi))\n",
    "# for key, value in list(vocab.stoi.items()):\n",
    "#     if re.search('\\n', key) or re.search(' ', key):\n",
    "#         errors += 1\n",
    "#         print(key)\n",
    "#         vocab.stoi.pop(key)\n",
    "#         vocab.itos.pop(value)\n",
    "#         vocab.freqs.pop(key)\n",
    "#         # vocab.freqs[key] -= 1\n",
    "#         # if vocab.freqs[key] < 1:\n",
    "#         #     vocab.freqs.pop(key)\n",
    "#\n",
    "# print(errors)\n",
    "# print('length of vocab after filtering:', len(vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainset, devset = SQuAD1(vocab=vocab)\n",
    "# model = None\n",
    "# optimizer = None\n",
    "# loss = None\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_large_text(data):\n",
    "    return data[0] <= 400\n",
    "def remove_wrong_whitespace(data):\n",
    "    blank_token = vocab.stoi[' ']\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if (blank_token in paragraph) or (blank_token in question):\n",
    "        return False\n",
    "    for answer in answers:\n",
    "        if blank_token in answer:\n",
    "            return False\n",
    "    return True\n",
    "def check_train_data(data):\n",
    "    # data might be wrong because of spacy tokenizer\n",
    "    p_length, q_length, idx, paragraph, question, answer, span = data\n",
    "    if span[0][0] > p_length or span[0][1] > p_length:\n",
    "        return False\n",
    "    if paragraph[span[0][0]] == answer[0][0] and paragraph[span[0][1]] == answer[0][-1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_dev_data(data):\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if len(spans) != 3 or len(answers) != 3:\n",
    "        return False\n",
    "    else:\n",
    "        for span, answer in zip(spans, answers):\n",
    "            if span[0] > p_length or span[1] > p_length:\n",
    "                return False\n",
    "            if paragraph[span[0]] != answer[0] or paragraph[span[1]] != answer[-1]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85130\n",
      "8262\n"
     ]
    }
   ],
   "source": [
    "train_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(trainset)]\n",
    "dev_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(devset)]\n",
    "\n",
    "# train_data = list(filter(remove_large_text, train_data))\n",
    "# dev_data = list(filter(remove_large_text, dev_data))\n",
    "\n",
    "train_data = list(filter(remove_wrong_whitespace, train_data))\n",
    "dev_data = list(filter(remove_wrong_whitespace, dev_data))\n",
    "\n",
    "train_data = list(filter(check_train_data, train_data))\n",
    "dev_data = list(filter(check_dev_data, dev_data))\n",
    "\n",
    "\n",
    "train_data.sort() # sort by length and pad sequences with similar lengths\n",
    "dev_data.sort()\n",
    "# paragraph, question: tensor of indices of words, use itos to get word\n",
    "print(len(train_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_data[0][3])\n",
    "# for idx in train_data[0][3]:\n",
    "#     print(train.get_vocab().itos[idx], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_data(data):\n",
    "    # Generate the pad id\n",
    "    pad_id = vocab['<pad>']\n",
    "    # Find max length of the mini-batch\n",
    "    # train.get_vocab()['pad'], dev.get_vocab()['pad'] is equal to 22949\n",
    "    max_p_len = max(list(zip(*data))[0])\n",
    "    max_q_len = max(list(zip(*data))[1])\n",
    "    paragraph_list = list(zip(*data))[3]\n",
    "    question_list = list(zip(*data))[4]\n",
    "    answer_list = list(zip(*data))[5]\n",
    "    span_list = list(zip(*data))[6]\n",
    "    padded_paragraphs = torch.stack([torch.cat((paragraph,\n",
    "            torch.LongTensor([pad_id] * (max_p_len - len(paragraph))))) \\\n",
    "            for paragraph in paragraph_list])\n",
    "    padded_questions = torch.stack([torch.cat((question,\n",
    "            torch.tensor([pad_id] * (max_q_len - len(question))).long())) \\\n",
    "            for question in question_list])\n",
    "    paragraph_pad_mask = torch.zeros_like(padded_paragraphs).masked_fill(padded_paragraphs == pad_id, 1)\n",
    "    question_pad_mask = torch.zeros_like(padded_questions).masked_fill(padded_questions == pad_id, 1)\n",
    "\n",
    "    return padded_paragraphs, padded_questions, span_list, answer_list, \\\n",
    "           paragraph_pad_mask, question_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_data, num_workers=0)\n",
    "testloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_data, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i, (p, q, a, s) in enumerate(devset.data):\n",
    "#     print(p)\n",
    "#     print(q)\n",
    "#     print(a,s)\n",
    "#     nps = s[0].numpy()\n",
    "#     tokens = tokenizer(trainset.data[i][0])\n",
    "#     print(tokens[int(nps[0])])\n",
    "#     print(tokens[nps[1]])\n",
    "#     # print(tokens[a[0].numpy().item()])\n",
    "#     if i > 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "           paragraph_pad_mask, question_pad_mask) in enumerate(trainloader):\n",
    "    # print(idx, padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "    #        paragraph_pad_mask, question_pad_mask)\n",
    "    # print(padded_paragraphs.masked_fill(paragraph_pad_mask == 1, -1))\n",
    "    if idx > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(trainset.get_vocab()['pad'], dev.get_vocab()['pad'])\n",
    "# devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_vec = torchtext.vocab.GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(vocab, pre_trained_emb_vec):\n",
    "    # print(pre_trained_emb_vec.dim)\n",
    "    weights_matrix = np.zeros((len(vocab), pre_trained_emb_vec.dim))\n",
    "    words_found = 0\n",
    "    no_word = 0\n",
    "    for i, (word, _) in enumerate(vocab.freqs.most_common()):\n",
    "        try:\n",
    "            word_index = pre_trained_emb_vec.stoi[word]\n",
    "            weights_matrix[i] = pre_trained_emb_vec[word_index]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            no_word += 1 # no such word in pre_trained_embedding: zero vector\n",
    "    print('words not found:', no_word)\n",
    "    print('words found:', words_found)\n",
    "    return torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for key, value in vocab.freqs.items():\n",
    "#     if re.search(' ', key):\n",
    "#         print(key, value)\n",
    "# for i, word in enumerate(vocab.freqs.most_common()):\n",
    "#     print(word)\n",
    "#     if i > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words not found: 17435\n",
      "words found: 86591\n"
     ]
    }
   ],
   "source": [
    "word_emb_table = build_word_embedding(vocab, glove_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# glove_vec.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not using now\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser','ner',])\n",
    "#\n",
    "# def exact_match(paragraphs_indices, questions_indices, vocab):\n",
    "#     # process one paragraph batch, one question batch\n",
    "#     # print(paragraphs_indices.size())\n",
    "#     # print(questions_indices.size())\n",
    "#     #\n",
    "#     # j = 0\n",
    "#     # for (paragraph_indices, question_indices) in \\\n",
    "#     #         zip(paragraphs_indices, questions_indices):\n",
    "#     #     j += 1\n",
    "#     # print('j:',j)\n",
    "#     exact_match_table = np.zeros((len(paragraphs_indices), len(paragraphs_indices[0]), 3))\n",
    "#     # print(exact_match_table.shape)\n",
    "#\n",
    "#     for i, (paragraph_indices, question_indices) in \\\n",
    "#             enumerate(zip(paragraphs_indices, questions_indices)):\n",
    "#         # print(paragraphs_indices)\n",
    "#         # print(paragraphs_indices.size())\n",
    "#         # paragraph_processed = nlp(paragraph_sentence)\n",
    "#         # question_lemmas = [lem.lemma_ for lem in question_processed]\n",
    "#         for j, paragraph_index in enumerate(paragraph_indices):\n",
    "#             paragraph_word = vocab.itos[paragraph_index]\n",
    "#             if paragraph_word == '<pad>':\n",
    "#                 # print('got pad')\n",
    "#                 continue\n",
    "#             em_tensor = torch.LongTensor([0, 0, 0])\n",
    "#             # original\n",
    "#             if paragraph_index in question_indices:\n",
    "#                 em_tensor[0] = 1\n",
    "#             # lemma\n",
    "#             if vocab.stoi[nlp(paragraph_word)[0].lemma_] in question_indices:\n",
    "#                 em_tensor[1] = 1\n",
    "#             # uncased\n",
    "#             if vocab.stoi[paragraph_word.lower()] and \\\n",
    "#                     vocab.stoi[paragraph_word.lower()] in question_indices:\n",
    "#                 em_tensor[2] = 1\n",
    "#             exact_match_table[i][j] = em_tensor\n",
    "#\n",
    "#     return torch.LongTensor(exact_match_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim, input_dim)\n",
    "        self.linear2 = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, paragraph, question, question_pad_mask):\n",
    "\n",
    "        p = self.relu(self.linear1(paragraph))\n",
    "\n",
    "        # q = self.relu(self.linear2(question))\n",
    "\n",
    "        q = self.relu(self.linear1(question))\n",
    "        q = q.permute(0, 2, 1)\n",
    "\n",
    "        dot_product = torch.bmm(p, q)\n",
    "        # print(dot_product.size())\n",
    "        # print(question_pad_mask.size())\n",
    "        question_mask_expand = question_pad_mask.unsqueeze(1).expand(dot_product.size())\n",
    "        dot_product = dot_product.masked_fill(question_mask_expand == 1, -float('inf'))\n",
    "\n",
    "        dot_product_flatten = dot_product.view(-1, question.size(1))\n",
    "\n",
    "        attn_score = F.softmax(dot_product_flatten, dim=1)\n",
    "        attn_score = attn_score.view(-1, paragraph.shape[1], question.shape[1])\n",
    "\n",
    "        aligned_embedding = torch.bmm(attn_score, question)\n",
    "        return aligned_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerBiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstms.append(nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True))\n",
    "        for i in range(1, nlayers):\n",
    "            self.lstms.append(nn.LSTM(hidden_size * 2, hidden_size,\n",
    "                                      batch_first=True, bidirectional=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.dropout(x)\n",
    "        lstm_output, (_, _) = self.lstms[0](x)\n",
    "        hidden_states = [lstm_output]\n",
    "        # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "        for i in range(1, self.nlayers):\n",
    "            # lstm_output = self.dropout(lstm_output)\n",
    "            lstm_output, (_, _) = self.lstms[i](lstm_output)\n",
    "            # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "            hidden_states.append(lstm_output)\n",
    "\n",
    "        output = torch.cat(hidden_states, dim=2)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncoding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm_output_size = hidden_size * 6\n",
    "        self.linear = nn.Linear(self.lstm_output_size, 1)\n",
    "        self.lstm = MultiLayerBiLSTM(input_size, hidden_size, nlayers, dropout)\n",
    "        # biLSTM output size: hidden size * 6\n",
    "    def forward(self, x, question_mask):\n",
    "        try:\n",
    "            x = self.lstm(x)\n",
    "            b = x.view(-1, self.lstm_output_size)\n",
    "            b = self.linear(b) # attention score\n",
    "            b = b.view(question_mask.shape[0], -1)\n",
    "            # print(x.size(), question_mask.size())\n",
    "            b = b.masked_fill(question_mask == 1, -float('inf')) # masking\n",
    "            b = F.softmax(b, dim=1)\n",
    "\n",
    "            b = b.unsqueeze(1)\n",
    "            # print(x.size(), x_lstm.size())\n",
    "            encoding = torch.bmm(b, x)\n",
    "            encoding = encoding.squeeze(1)\n",
    "            return encoding\n",
    "        except:\n",
    "            print('question mask size:', question_mask.size())\n",
    "            print('x size:', x.size())\n",
    "            print('b size:', b.size())\n",
    "            print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionLayer(nn.Module):\n",
    "    def __init__(self, p_size, q_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(q_size, p_size)\n",
    "\n",
    "    def forward(self, paragraph, question, paragraph_mask):\n",
    "        Wq = self.linear(question)\n",
    "        Wq = Wq.unsqueeze(2)\n",
    "        pWq = paragraph.bmm(Wq)\n",
    "        pWq = pWq.squeeze(2)\n",
    "        pWq = pWq.masked_fill(paragraph_mask == 1, -float('inf'))\n",
    "        return pWq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fixate_embedding(grad):\n",
    "    grad[1000:] = 0\n",
    "    return grad\n",
    "\n",
    "class DocumentReader(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, nlayers, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_emb_table).to(device), freeze=False)\n",
    "        self.word_embedding_layer.weight.register_hook(fixate_embedding)\n",
    "        # print(embedding_size)\n",
    "        self.aligned_embedding_layer = AlignedQuestionEmbedding(embedding_size)\n",
    "        # self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2 + 3, hidden_size, nlayers, dropout)\n",
    "        self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.question_encoder = QuestionEncoding(embedding_size, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.prediction_layer_start = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                          hidden_size * nlayers * 2)\n",
    "        self.prediction_layer_end = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                        hidden_size * nlayers * 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, paragraph, question, paragraph_mask, question_mask):\n",
    "        # em_embedding = exact_match(paragraph, question, vocab)\n",
    "        # print(em_embedding.size())\n",
    "        p_word_embedding = self.word_embedding_layer(paragraph)\n",
    "        q_word_embedding = self.word_embedding_layer(question)\n",
    "        p_word_embedding = self.dropout(p_word_embedding)\n",
    "        q_word_embedding = self.dropout(q_word_embedding)\n",
    "        aligned_embedding = self.aligned_embedding_layer(p_word_embedding, q_word_embedding, question_mask)\n",
    "        # print(p_word_embedding.size())\n",
    "        # print(aligned_embedding.size())\n",
    "        paragraph_embeddings = torch.cat([p_word_embedding, aligned_embedding], dim=2)\n",
    "\n",
    "        # paragraph_embeddings = torch.cat([em_embedding.to(device), p_word_embedding.to(device), aligned_embedding.to(device)], dim=2)\n",
    "        paragraph_encoding = self.paragraph_lstm(paragraph_embeddings)\n",
    "        # print(question.size(), question_mask.size())\n",
    "        question_encoding = self.question_encoder(q_word_embedding, question_mask)\n",
    "\n",
    "        prediction_start = self.prediction_layer_start(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "        prediction_end = self.prediction_layer_end(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "\n",
    "        return prediction_start, prediction_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "EMB_SIZE = 300\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# dataiter_next = dataiter.next()\n",
    "# print(dataiter_next)\n",
    "# (p, q, a, s, p_mask, q_mask) = dataiter.next()\n",
    "# writer.add_graph(model, p, p_mask, q_mask)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters(), lr= 1e-2)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min', factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, train_dataset):\n",
    "    '''\n",
    "    Trains the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start training ........\")\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    # put the model in training mode\n",
    "    model.train()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    try:\n",
    "        for i, (paragraphs, questions, span_list, answer_list,\n",
    "                paragraph_mask, question_mask) in enumerate(train_dataset):\n",
    "            # if i < 575:\n",
    "            #     continue\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "            # place the tensors on GPU\n",
    "            paragraphs = paragraphs.to(device)\n",
    "            paragraph_mask = paragraph_mask.to(device)\n",
    "            questions = questions.to(device)\n",
    "            question_mask = question_mask.to(device)\n",
    "            # span_list = span_list.to(device)\n",
    "\n",
    "            # forward pass, get the predictions\n",
    "            preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "            start_pred, end_pred = preds\n",
    "\n",
    "            # print('preds:', start_pred, end_pred)\n",
    "            # separate labels for start and end position\n",
    "            span_start = []\n",
    "            span_end = []\n",
    "            for span in span_list:\n",
    "                span_start.append(span[0][0].item())\n",
    "                span_end.append(span[0][1].item())\n",
    "\n",
    "            # print('span:', span_start, span_end)\n",
    "            span_start = torch.LongTensor(span_start).to(device)\n",
    "            span_end = torch.LongTensor(span_end).to(device)\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(start_pred, span_start) + F.cross_entropy(end_pred, span_end)\n",
    "\n",
    "            # backward pass, calculates the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    "            # zero the gradients to prevent them from accumulating\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "    except Exception as e:\n",
    "        print(f'sizes of pred:{start_pred.size()} / span:{span_start.size()}')\n",
    "        print(f'span_start: {span_start[23]}\\nspan_end: {span_end[23]}')\n",
    "        print(f'i: {i}')\n",
    "        print(f'paragraph: {paragraphs}')\n",
    "        bad_p = paragraphs.numpy()[23]\n",
    "        bad_q = questions.numpy()[23]\n",
    "        bad_p_text = [vocab.itos[pi] for pi in bad_p]\n",
    "        bad_q_text = [vocab.itos[qi] for qi in bad_q]\n",
    "        bad_p_text = ' '.join(bad_p_text)\n",
    "        bad_q_text = ' '.join(bad_q_text)\n",
    "\n",
    "        print(bad_p_text)\n",
    "        print(bad_q_text)\n",
    "        print(f'paragraph size: {paragraphs.size()}, question size: {questions.size()}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "    return train_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %time train_loss = train(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, test_dataset):\n",
    "    '''\n",
    "    Validates the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start validation ........\")\n",
    "\n",
    "    val_loss = 0.\n",
    "    emScore = 0\n",
    "    f1Score = 0\n",
    "    # put the model in eval mode\n",
    "    model.eval()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    for i, (paragraphs, questions, span_list, answer_list,\n",
    "            paragraph_mask, question_mask) in enumerate(test_dataset):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "        # place the tensors on GPU\n",
    "        paragraphs = paragraphs.to(device)\n",
    "        paragraph_mask = paragraph_mask.to(device)\n",
    "        questions = questions.to(device)\n",
    "        question_mask = question_mask.to(device)\n",
    "        # span_list = span_list.to(device)\n",
    "\n",
    "        # forward pass, get the predictions\n",
    "        preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "        start_pred, end_pred = preds\n",
    "        # print('preds:', start_pred, end_pred)\n",
    "        log_softmax = nn.LogSoftmax(dim=1) # batchwise log softmax\n",
    "        pred_table = log_softmax(start_pred).unsqueeze(2) + log_softmax(end_pred).unsqueeze(1)\n",
    "        pred_mask1 = (torch.ones_like(pred_table) * -float('inf')).tril(diagonal=-1)# start index <= end index\n",
    "        pred_mask2 = (torch.ones_like(pred_table) * -float('inf')).triu(diagonal=16)\n",
    "        pred_table += pred_mask1 + pred_mask2\n",
    "\n",
    "        start_pred_argmax = []\n",
    "        end_pred_argmax = []\n",
    "        paragraph_length = pred_table.shape[-1]\n",
    "        for batch in pred_table:\n",
    "            arg_max = batch.argmax()\n",
    "            start_pred_argmax.append(arg_max // paragraph_length)\n",
    "            end_pred_argmax.append(arg_max % paragraph_length)\n",
    "\n",
    "        # separate labels for start and end position\n",
    "        span_start = []\n",
    "        span_end = []\n",
    "        true_answers_list = []\n",
    "        my_answers = []\n",
    "        for paragraph, spans, answers, sp, ep in \\\n",
    "                zip(paragraphs, span_list, answer_list, start_pred_argmax, end_pred_argmax):\n",
    "            span_start.append([span[0].item() for span in spans][:3])\n",
    "            span_end.append([span[1].item() for span in spans][:3])\n",
    "            true_answers_list.append([ans2txt(answer) for answer in answers])\n",
    "            if sp > ep or ep > sp + 15:\n",
    "                print(f'wrong range, sp:{sp}, ep:{ep} ')\n",
    "            my_answers.append(span2txt([sp, ep + 1], paragraph))\n",
    "        with torch.no_grad():\n",
    "            # print('span:', span_start, span_end)\n",
    "            try:\n",
    "                span_start = torch.LongTensor(span_start).to(device)\n",
    "                span_end = torch.LongTensor(span_end).to(device)\n",
    "                # calculate loss\n",
    "                loss = [F.cross_entropy(start_pred, span_start.t()[i]) +\n",
    "                        F.cross_entropy(end_pred, span_end.t()[i]) for i in range(3)]\n",
    "                loss = min(loss)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                emScore += em_batch(my_answers, true_answers_list)\n",
    "                f1Score += f1_batch(my_answers, true_answers_list)\n",
    "            except:\n",
    "                print('start pred:', start_pred)\n",
    "                print('start pred shape:', start_pred.shape)\n",
    "                print('span_list:', span_list)\n",
    "                print('span_list length:', len(span_list))\n",
    "                print('span_start:', span_start)\n",
    "                print('span_start shape:', np.asarray(span_start).shape)\n",
    "                print('span_end:', span_end)\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    return val_loss / len(test_dataset), emScore / len(test_dataset), f1Score / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def normalize_answer(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans('','',punctuation))\n",
    "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def em_batch(my_answers, true_answers_list):\n",
    "    # true_answers_list: batch size * 3\n",
    "    em = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        for true_answer in true_answers:\n",
    "            if my_answer == true_answer:\n",
    "                em += 1\n",
    "                break\n",
    "    return em / BATCH_SIZE\n",
    "\n",
    "def f1_batch(my_answers, true_answers_list):\n",
    "    f1Batch = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        f1_single = 0\n",
    "        for true_answer in true_answers:\n",
    "            my_answer_split = my_answer.split()\n",
    "            true_answer_split = true_answer.split()\n",
    "            common = Counter(my_answer_split) & Counter(true_answer_split)\n",
    "            num_intersection = sum(common.values())\n",
    "            if num_intersection == 0:\n",
    "                continue\n",
    "            precision = num_intersection / len(my_answer_split)\n",
    "            recall = num_intersection / len(true_answer_split)\n",
    "            f1_single = max((2 * precision * recall) / (precision + recall), f1_single)\n",
    "        f1Batch += f1_single\n",
    "        # if f1_single < 0.9:\n",
    "        #     print('my answer split:', my_answer_split)\n",
    "        #     print('true answer split:', true_answer_split)\n",
    "    return f1Batch / BATCH_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def span2txt(span, paragraph):\n",
    "    # print(span[0].item())\n",
    "    my_answer = paragraph[int(span[0].item()) : int(span[1].item()) + 1]\n",
    "    return ans2txt(my_answer)\n",
    "def ans2txt(answer):\n",
    "    words = []\n",
    "    for a_index in answer:\n",
    "        words.append(vocab.itos[a_index.item()])\n",
    "    return normalize_answer(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_val_loss = 100\n",
    "path = 'best.pt'\n",
    "if os.path.isfile(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "else:\n",
    "    epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring epoch 0\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.009966611862182617\n",
      "Starting batch: 500, time: 107.33710861206055\n",
      "Starting batch: 1000, time: 214.9498028755188\n",
      "Starting batch: 1500, time: 321.2359766960144\n",
      "Starting batch: 2000, time: 431.7365171909332\n",
      "Starting batch: 2500, time: 541.1670615673065\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010013580322265625\n",
      "train_loss: 6.466047683276435, val_loss: 5.155352012531178\n",
      "em_score: 21.211389961389962, f1_score: 42.46891243473074\n",
      "End epoch 0, elapsed time: 592.6233892440796\n",
      "Staring epoch 1\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008988142013549805\n",
      "Starting batch: 500, time: 108.65798115730286\n",
      "Starting batch: 1000, time: 217.88436007499695\n",
      "Starting batch: 1500, time: 327.81886529922485\n",
      "Starting batch: 2000, time: 421.823312997818\n",
      "Starting batch: 2500, time: 516.2080411911011\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019757747650146484\n",
      "train_loss: 5.04408136994621, val_loss: 4.544800425128127\n",
      "em_score: 24.96380308880309, f1_score: 48.763768843822774\n",
      "End epoch 1, elapsed time: 559.9642353057861\n",
      "Staring epoch 2\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007001161575317383\n",
      "Starting batch: 500, time: 93.68248867988586\n",
      "Starting batch: 1000, time: 187.52272820472717\n",
      "Starting batch: 1500, time: 282.26792883872986\n",
      "Starting batch: 2000, time: 377.1013684272766\n",
      "Starting batch: 2500, time: 472.0990471839905\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010328292846679688\n",
      "train_loss: 4.632380174721421, val_loss: 4.3889662786800425\n",
      "em_score: 26.158301158301157, f1_score: 50.47522909376945\n",
      "End epoch 2, elapsed time: 516.6965651512146\n",
      "Staring epoch 3\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.006988525390625\n",
      "Starting batch: 500, time: 92.74346661567688\n",
      "Starting batch: 1000, time: 186.2513711452484\n",
      "Starting batch: 1500, time: 280.38685870170593\n",
      "Starting batch: 2000, time: 375.0244998931885\n",
      "Starting batch: 2500, time: 472.083696603775\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002002716064453125\n",
      "train_loss: 4.374086788031267, val_loss: 4.3164134476635905\n",
      "em_score: 26.315154440154444, f1_score: 51.07859803724987\n",
      "End epoch 3, elapsed time: 516.5862889289856\n",
      "Staring epoch 4\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007000923156738281\n",
      "Starting batch: 500, time: 97.21878552436829\n",
      "Starting batch: 1000, time: 195.2363076210022\n",
      "Starting batch: 1500, time: 293.32732248306274\n",
      "Starting batch: 2000, time: 390.3654410839081\n",
      "Starting batch: 2500, time: 488.63021087646484\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019559860229492188\n",
      "train_loss: 4.1721178976408035, val_loss: 4.2444586422452595\n",
      "em_score: 27.340733590733592, f1_score: 51.99985973801775\n",
      "End epoch 4, elapsed time: 533.9960868358612\n",
      "Staring epoch 5\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007960081100463867\n",
      "Starting batch: 500, time: 94.67439293861389\n",
      "Starting batch: 1000, time: 190.2035436630249\n",
      "Starting batch: 1500, time: 287.4497101306915\n",
      "Starting batch: 2000, time: 384.4595527648926\n",
      "Starting batch: 2500, time: 480.8851981163025\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002002239227294922\n",
      "train_loss: 4.010681531967771, val_loss: 4.260594023700847\n",
      "em_score: 27.18388030888031, f1_score: 52.1667300407252\n",
      "End epoch 5, elapsed time: 525.8970251083374\n",
      "Staring epoch 6\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004996061325073242\n",
      "Starting batch: 500, time: 95.30980372428894\n",
      "Starting batch: 1000, time: 191.867014169693\n",
      "Starting batch: 1500, time: 288.05980587005615\n",
      "Starting batch: 2000, time: 384.8318169116974\n",
      "Starting batch: 2500, time: 481.8642520904541\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001953125\n",
      "train_loss: 3.855366252051937, val_loss: 4.248134230094527\n",
      "em_score: 27.316602316602317, f1_score: 51.83697160918168\n",
      "End epoch 6, elapsed time: 527.5633549690247\n",
      "Staring epoch 7\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.009000062942504883\n",
      "Starting batch: 500, time: 94.36481308937073\n",
      "Starting batch: 1000, time: 187.51557207107544\n",
      "Starting batch: 1500, time: 282.92325949668884\n",
      "Starting batch: 2000, time: 378.31288862228394\n",
      "Starting batch: 2500, time: 473.64203333854675\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010232925415039062\n",
      "train_loss: 3.7075704485793977, val_loss: 4.230422119376282\n",
      "em_score: 27.292471042471046, f1_score: 52.42146654150935\n",
      "End epoch 7, elapsed time: 518.1073076725006\n",
      "Staring epoch 8\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004947185516357422\n",
      "Starting batch: 500, time: 94.39776253700256\n",
      "Starting batch: 1000, time: 187.7777018547058\n",
      "Starting batch: 1500, time: 282.7362427711487\n",
      "Starting batch: 2000, time: 377.4143559932709\n",
      "Starting batch: 2500, time: 471.25938510894775\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0009665489196777344\n",
      "train_loss: 3.5911690739481488, val_loss: 4.285061951309558\n",
      "em_score: 27.304536679536678, f1_score: 52.39502828456898\n",
      "End epoch 8, elapsed time: 517.4151027202606\n",
      "Staring epoch 9\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.005997419357299805\n",
      "Starting batch: 500, time: 97.22547721862793\n",
      "Starting batch: 1000, time: 192.57005310058594\n",
      "Starting batch: 1500, time: 291.2110471725464\n",
      "Starting batch: 2000, time: 392.93992853164673\n",
      "Starting batch: 2500, time: 493.7921118736267\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002001047134399414\n",
      "train_loss: 3.4627662412836244, val_loss: 4.299138253259843\n",
      "em_score: 27.376930501930502, f1_score: 52.46624414562228\n",
      "End epoch 9, elapsed time: 542.0355441570282\n",
      "Staring epoch 10\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0049974918365478516\n",
      "Starting batch: 500, time: 97.98119616508484\n",
      "Starting batch: 1000, time: 197.48765087127686\n",
      "Starting batch: 1500, time: 296.5003080368042\n",
      "Starting batch: 2000, time: 400.69279980659485\n",
      "Starting batch: 2500, time: 502.6472930908203\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002001047134399414\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-03.\n",
      "train_loss: 3.3568814475031914, val_loss: 4.3730712461655665\n",
      "em_score: 27.159749034749037, f1_score: 52.39929504730812\n",
      "End epoch 10, elapsed time: 550.7568881511688\n",
      "Staring epoch 11\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004981517791748047\n",
      "Starting batch: 500, time: 96.26629686355591\n",
      "Starting batch: 1000, time: 189.7823452949524\n",
      "Starting batch: 1500, time: 288.10882902145386\n",
      "Starting batch: 2000, time: 386.0550193786621\n",
      "Starting batch: 2500, time: 485.980051279068\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019648075103759766\n",
      "train_loss: 2.88803389622546, val_loss: 4.48465059898995\n",
      "em_score: 27.292471042471046, f1_score: 52.930890519425844\n",
      "End epoch 11, elapsed time: 533.3007662296295\n",
      "Staring epoch 12\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.004000186920166016\n",
      "Starting batch: 500, time: 98.07572031021118\n",
      "Starting batch: 1000, time: 196.92216300964355\n",
      "Starting batch: 1500, time: 295.19154477119446\n",
      "Starting batch: 2000, time: 392.54490208625793\n",
      "Starting batch: 2500, time: 491.3701274394989\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010004043579101562\n",
      "train_loss: 2.743612038332105, val_loss: 4.525273413271518\n",
      "em_score: 27.340733590733592, f1_score: 52.97827209796764\n",
      "End epoch 12, elapsed time: 537.0435929298401\n",
      "Staring epoch 13\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.0059468746185302734\n",
      "Starting batch: 500, time: 97.16135549545288\n",
      "Starting batch: 1000, time: 194.2612268924713\n",
      "Starting batch: 1500, time: 292.2765872478485\n",
      "Starting batch: 2000, time: 387.467894077301\n",
      "Starting batch: 2500, time: 485.0978925228119\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0020248889923095703\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n",
      "train_loss: 2.65800899255997, val_loss: 4.562406875912287\n",
      "em_score: 27.051158301158303, f1_score: 52.595133034791544\n",
      "End epoch 13, elapsed time: 530.698233127594\n",
      "Staring epoch 14\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007033586502075195\n",
      "Starting batch: 500, time: 97.46309065818787\n",
      "Starting batch: 1000, time: 194.05829215049744\n",
      "Starting batch: 1500, time: 293.52232241630554\n",
      "Starting batch: 2000, time: 388.0642366409302\n",
      "Starting batch: 2500, time: 482.1985080242157\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0010342597961425781\n",
      "train_loss: 2.558737800538831, val_loss: 4.602806813008076\n",
      "em_score: 27.195945945945947, f1_score: 52.70963108138454\n",
      "End epoch 14, elapsed time: 527.2832810878754\n",
      "Staring epoch 15\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008000373840332031\n",
      "Starting batch: 500, time: 92.380131483078\n",
      "Starting batch: 1000, time: 187.1907410621643\n",
      "Starting batch: 1500, time: 281.2615611553192\n",
      "Starting batch: 2000, time: 375.84397649765015\n",
      "Starting batch: 2500, time: 469.00521183013916\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.001999378204345703\n",
      "train_loss: 2.5507748725494017, val_loss: 4.615225225802094\n",
      "em_score: 27.051158301158303, f1_score: 52.731854903503326\n",
      "End epoch 15, elapsed time: 515.6934642791748\n",
      "Staring epoch 16\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.005995988845825195\n",
      "Starting batch: 500, time: 95.24084663391113\n",
      "Starting batch: 1000, time: 191.63759303092957\n",
      "Starting batch: 1500, time: 285.352098941803\n",
      "Starting batch: 2000, time: 382.41003131866455\n",
      "Starting batch: 2500, time: 480.859078168869\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0019643306732177734\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "train_loss: 2.5425422816337475, val_loss: 4.622310155146831\n",
      "em_score: 27.00289575289575, f1_score: 52.75011733313655\n",
      "End epoch 16, elapsed time: 527.9520826339722\n",
      "Staring epoch 17\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.003999948501586914\n",
      "Starting batch: 500, time: 103.30752396583557\n",
      "Starting batch: 1000, time: 203.46296000480652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-61-f14a8b3720e7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mtrain_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[0mval_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0memScore\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf1Score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtestloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mscheduler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_loss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-55-6071de007764>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_dataset)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m             \u001B[1;31m# forward pass, get the predictions\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m             \u001B[0mpreds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparagraphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquestions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparagraph_mask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquestion_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m             \u001B[0mstart_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreds\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-33-c199e1024adf>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, paragraph, question, paragraph_mask, question_mask)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m         \u001B[1;31m# paragraph_embeddings = torch.cat([em_embedding.to(device), p_word_embedding.to(device), aligned_embedding.to(device)], dim=2)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m         \u001B[0mparagraph_encoding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparagraph_lstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparagraph_embeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m         \u001B[1;31m# print(question.size(), question_mask.size())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[0mquestion_encoding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mquestion_encoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mq_word_embedding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquestion_mask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-30-bdd3a9576da2>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlayers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m             \u001B[1;31m# lstm_output = self.dropout(lstm_output)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m             \u001B[0mlstm_output\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstms\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlstm_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m             \u001B[1;31m# print(lstm_output.size(), hidden_state.size(), cell_state.size())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlstm_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pch33\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    659\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_forward_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_sizes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    660\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mbatch_sizes\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 661\u001B[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001B[0m\u001B[0;32m    662\u001B[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001B[0;32m    663\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "epoch_start = max(epoch, 0)\n",
    "for epoch in range(epoch_start, epoch_start + 50):\n",
    "    print(f'Staring epoch {epoch}')\n",
    "    start_time = time()\n",
    "\n",
    "    train_loss = train(model, trainloader)\n",
    "    val_loss, emScore, f1Score = validate(model, testloader)\n",
    "    scheduler.step(val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    em_scores.append(emScore * 100)\n",
    "    f1_scores.append(f1Score * 100)\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            }, path)\n",
    "    end_time = time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "    print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')\n",
    "    print(f'End epoch {epoch}, elapsed time: {time_elapsed}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(train_losses)\n",
    "    writer.writerow(val_losses)\n",
    "    writer.writerow(em_scores)\n",
    "    writer.writerow(f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# val_loss, emScore, f1Score = validate(model, testloader)\n",
    "# print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "# print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(epoch - len(train_losses) + 1, epoch + 1)], train_losses)\n",
    "plt.plot([i for i in range(epoch - len(val_losses) + 1, epoch + 1)], val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('CE losses')\n",
    "plt.title('Training Result')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvlUlEQVR4nO3deZxcVZn/8c/T1Us6+0aahAQSEkAwSKDDZgATYFARERgHYVDBYYw6ijgCI+BvFIfBwfmpDPpzZkRBGEUjBhBkEEGgEUSWJIQQEkJC0pDOSva1t+rn98c5nVR3qtOdqrrdndT3/Xrd192fe6q6+qlbp06dY+6OiIgUj5KeLoCIiHQvJX4RkSKjxC8iUmSU+EVEiowSv4hIkVHiFxEpMkr8IiJFRolfRKTIKPFLQZjZaWb2vJltNrMNZvZnMzuxp8uVNDMbbGZ3mdlqM9tqZm+a2fUZ+83MrjOzxWa208zeMbNvm1n5Pl7HzGypmS3Isq/GzOrj9beY2Wwzu97MKvYSb5qZPR3/XrWdXLvczGaaWa2ZuZlN3ZeyS++jxC95M7OBwCPAD4GhwCHAt4CGAl8nVch4BXIb0B84GhgEnA8sydj/A2A68GlgAPBh4Gxgxj5e5wxgBHB4B2+oX3L3AcBI4BrgEuBRM7MO4m0H7gKu6+L1nwM+Cazep1JL7+TumjTlNQGTgU2dHPNZYCGwFVgAnBC3Hw3UAJuA14HzM865G/gv4FFCojobGAXcD7wLLAO+nHH8ScAsYAuwBvh+J+VZAmwAHgZGZexz4PPA4liuHwHWQZz5wAUd7DsCSAMntds+hvCm+IG4XgP8fcb+K4Dn2p1zF3Av8ADw/9rta3N+3HYosAM4r5O/y9lA7T78reuAqT39mtOU36Q7fimEN4G0md1jZh82syGZO83sb4CbCHe9Awl3xevNrAz4HfA44W72KuBeMzsq4/S/BW4h3C0/H49/lfCp4izgK2b2wXjs7cDt7j4QGA/cl62wZnYm8G/AxYQ75LfZ8w78POBE4H3xuA+S3QvALWb2GTM7ot2+s4A6d38pc6O7L4/nndNBzPbl7Qt8nJD47wUu6ayqyN3fIbwJnt6Va0hxUeKXvLn7FuA0wp3yT4B3zexhM6uKh/w98O/u/rIHS9z9beAUQjXJre7e6O5PEaqMLs0I/5C7/9ndW4BjgYPc/V/i8Uvj9S6JxzYBE8xsuLtvc/cXOijyZcBd7j7H3RuAG4BTzWxsxjG3uvummECfBiZ1EOsqQjL+ErDAzJaY2YfjvuHAqg7OWwUc1MG+9i4ifEJ4HPhfoAz4SBfOW0moehNpQ4lfCsLdF7r7Fe4+GphIqJL5j7h7DPBWltNGActjUm/1NuFuvtXyjOXDgFFmtql1Am4EWt9grgSOBN4ws5fN7LwOijsqXqe17NuA9e2um1mXvYPwBrUHd9/p7t9292pgGOFTxm/MbCiwjvCJIpuRcX9XXA7c5+7N7l5PqOq6vAvnHUKoyhJpQ4lfCs7d3yDUz0+Mm5YTql7aWwmMMbPM1+GhwIrMcBnLy4Fl7j44Yxrg7ufG6y5290sJ1UbfAWaaWb8OrntY60o8Zli76+6z+Mnn20A/YBzwVHx8J2UeZ2ZjCJ92auKm7UDfjEMOzjh2NHAm8MnYcmg1odrnXDMb3lFZ4jWqgWfzeUxyYFLil7yZ2XvM7JqYpFqTzqWEemyAnwLXmll1bJY4wcwOA14k3E3/k5mVxWaCH6XjFi8vAVvN7GtmVmlmKTOb2NrKxcw+aWYHxU8Qm+I5LVni/Ar4jJlNik0evw286O61OTz2fzazE2OTxz7A1fHai9z9TeC/Cd9bnBLL+17CHfvzwB9jmLnARWbW18wmED65tPoU4TuUowjVTZMIn2rqaFsl1lqevmb2AeCh+Hw92kG5S2J5y8Kq9dnb9wZmVhGPByiPx3fUYkh6u57+dlnT/j8RqhTuI9wxb4/zHwMDM475PLAI2EZoCXN83P5e4BlgM6G1z4UZ59wN/Gu7a40iJO7VwEbCm8vZcd8vgLXxGq/TQWubjPK8RagKeQQYnbHPgQl7K0fGvv8TH8+WGKsGeH/G/hLga4QWRA0x9m+AQRnHDCfU328F/kz4Ivy5uO8N4Kos1/0nYFZcrgHq4/lbgVeArwN99vL4p8ayZE41GftfBy7LWK/NcvzYnn7tacptsvhHFZFuYGbfAi4EznD3TT1cHClSiSZ+MxtM+Jg/kXCH8HeEZnGfJbTDBrjR3bN+HBU5EJnZl4Al7v5YT5dFilPSif8e4Fl3/2msP+wLfAXY5u7fTezCIiLSodKkApvZIMLPzK8AcPdGoFHfB4mI9KzEEj+hOdu7wM/M7DhgNqHFA8CXzOzThF8WXuPuG9ufbGbTCX2cUFlZWT1mzJicCtHS0kJJSWEaLymWYimWYnV3vHxivfnmm+vcfc8fCib1rTGh/5Zm4OS4fjtwM+HHNilCa4dbCL+g3Gus6upqz9XTTz+d87mKpViKpVg9HS+fWMSWX+2nJNvx1xH6KXkxrs8kdMy1xt3THtpa/4TQsZaIiHSTxBK/u68Glmd0uHUWoS+TzJ+wX0hoAy0iIt0kyTp+2N3bYjmwFPgM8AMzm0Ro3lkLfC7hMoiISIZEE7+7zyXU9Wf6VJLXFBHpqqamJurq6hg0aBALFy4sWNxCxutKrD59+jB69GjKysq6FDPpO34RkV6rrq6OAQMGMGzYMAYOHFiwuFu3bmXAgAHdEsvdWb9+PXV1dYwbN65LMdVJm4gUrfr6eoYNG8b+/PsiM2PYsGHU19d3+RwlfhEpavtz0m+1r49BiV9EpMgo8YuI9KBUKsWkSZN2TbfeeisAU6dO5dBDD239QSwAF1xwAf37Zx0Mbp/oy10RkR5UWVnJ3Llzs+4bPHgwL7zwAueccw6bNm1i1aqOhnDeN7rjFxHppS655BJmzpwJwAMPPMBFF11UkLi64xcRAb71u9dZsHJLQWKl02lSqRTHjBrINz/63r0eu3PnTiZNmrRr/YYbbuATn/gEAGeddRZXXnkl6XSaGTNmcMcdd3DzzTfnXT4lfhGRHrS3qp5UKsUpp5zCjBkz2LlzJ2PHji3INZX4RUSg0zvzfVHIH3B9/OMf57LLLuOmm24qSDxQHb+ISK/2/ve/nxtuuIFLL720YDF1xy8i0oPa1/F/6EMf2tWkE8KPs6699tqCXlOJX0SkB6XT6azba2pqgFBtlGnbtm15XzPRqh4zG2xmM83sDTNbaGanmtlQM3vCzBbH+ZAkyyAiIm0lXcd/O/CYu78HOA5YCFwPPOnuRwBPxnUREekmiSV+MxsEnAHcCeDuje6+CfgYcE887B7ggqTKICIie7LMfiAKGjiMsnUHsIBwtz8buBpY4e6D4zEGbGxdb3f+dGA6QFVVVfWMGTNyKse2bdsK0reFYimWYh14sQYNGsSECRN2/eCqUAoZr6uxlixZwubNm9tsmzZt2mx3bz8YFnuMvl6oiTDyVjNwcly/HbgZ2NTuuI2dxaqurs55lPneMtq9YimWYvW+WAsWLHB39y1btuQdK1Mh43U1VutjyQTM8iw5Nck6/jqgzt1fjOszgROANa0Drsf52gTLICIi7SSW+N19NbDczI6Km84iVPs8DFwet10OPJRUGUREerv23TLX1tayfv16pk2bRv/+/bnmmmsKfs2k2/FfBdxrZuXAUuAzhDeb+8zsSuBt4OKEyyAi0mtl66tn+/bt3HzzzcyfP585c+YU/JqJJn53n0uo62/vrCSvKyKyP+vXrx+nnXYaS5YsSSS+frkrIgLw++th9WsFCVWZboZUKRx8LHz41r0em9llw7hx43jwwQcLUoa9UeIXEelBe+uWOSlK/CIi0Omd+b7YWcBumZOgbplFRIqM7vhFRHqhsWPHsmXLFhobG3n00Ud5/PHHOeaYYwoSW4lfRKQHddTNcm1tLVDY0bxaqapHRKTIKPGLiBQZJX4RKWqeUA/F3WlfH4MSv4gUrT59+rB+/fr9Ovm7O+vXr6dPnz5dPkdf7opI0Ro9ejR1dXVs2rRpnxJnZ+rr6wsWryux+vTpw+jRo7scU4lfRIpWWVkZ48aNo6amhuOPP75gcQsZr9BlA1X1iIgUnUQTv5nVmtlrZjbXzGbFbTeZ2Yq4ba6ZnZtkGUREpK3uqOqZ5u7r2m27zd2/2w3XFhGRdlTVIyJSZCzJZkxmtgzYCDjwY3e/w8xuAq4AtgCzgGvcfWOWc6cD0wGqqqqqZ8yYkVMZtm3bRv/+/XM6V7EUS7EUq6fj5RNr2rRps919z8Gwso3AXqgJOCTORwCvAmcAVUCK8GnjFuCuzuJUV1d3aZT5bJ5++umcz1UsxVIsxerpePnEAmZ5lpyaaFWPu6+I87XAg8BJ7r7G3dPu3gL8BDgpyTKIiEhbiSV+M+tnZgNal4FzgPlmNjLjsAuB+UmVQURE9pRkq54q4EEza73OL939MTP7uZlNItT71wKfS7AMIiLSTmKJ392XAsdl2f6ppK4pIiKdU3NOEZEio756RCR/7tCSBk/HeUvb5Tgvb9gAzY1QWt7TJS5qSvwixc4ddm6ETe/A5uWwaXmch/VT178DL5VkJPSWPZM8Xfs90PsB/gL0GQT9DoJ+I6DfcOg/Iq4Pj9sOClP/g6BiIITvCnsH9zAR562PP2M51bwTGra2PW7XnPg8Ztu357wk3VDwh6DEL3Kga2mBbWvaJPPdyT3OG9uN+1rWDwaPgUFjWM8IRo0+DCwFVgIl7eaWisupkKBbl9vsD/M3F73BkaOHw/a1sP1d2L4O3l0Etc/Bzg3Zy5+qyHhTOCi+SQxnzKpN8KdZkG6CdEP4JJFubLfcCM0NnS6f1rATni/ZMyFnSepdcTrAczn/xdoYfOw3gQ8WJlikxC8HtvotsLE2Y1rGe2tfh9U/iXeRFpNTnHe4Ttb9R6xYAVt/Cy1N4e63pTljiuvpprbrHUyn7NwBc/tBSWnGVNJuvTQk1Pbrlmqz/p6VK+Dt74XEvmVFSHCZKofAoDEwbDwcPnVXkmfwGBh8WNgf77LfrKlh1NSpBflzrNxWw5Ef6CBWugl2rIdtrW8KGdO21uW1sHYBbFvL+JYmWBrPLSmD0gpIlYeptDy8YbRZLoO+/XYvZxy/etVaRo85NP5d270uOl1mj+1vLV3K+PETMo7LmO96HcVPMdmOyZhvX1tZkOc+kxK/7F26CZp2QNPOOK/PWI7z5vqsx0xY/jbwIvQdGhJJ32FxeWhYLu+bf/la0rBlZZvE3ibR71jf9vjKIVSWDISN23dXW7S5s2u/3v7Or+3+EY2NsLlyd9JNdZSgy8J6acWe+1NlUFLKxjVrGDlixJ5vHp5uu97UuOebS7v54MYGKDscRh0Px5wfk/qhu5N7xYD8n/tCS5XBgIPD1Bl3nn3yMU6femZI3nlWBS2pqWF0gd7cAJY31zB+SmHiNdTUFCROJiX+YrftXVg5B1bMhhWzObnuNXjZdydxT+97TCuBsr4cnE7Dikc6Pq60z+43gb5D4nJcb7fcf+tSWLhtz8S+6Z22d7OWColtyFg4+vwwz5wqBzOrpoapBfon/3MBYy2qqWFkgWK9UMBy9UpmpEsrwxup7DMl/mLSsA1WvborybNyTkicEJL1iGPYMvAoKseMh7LK3VNp63Lftttb10v7tN0X78Ceq6lh6ulTwheHOzaEOtwd69stb4zLG2DN62F558Z4R73bZIDZcaXPIBgyDqomwnvO253Uh46DgaPDXbeIdEj/IQeqdBOsXbg7ya+YA+8u3J1QBx8Kh1TDSdPDfORxUN6PhTU1VBXyTjFVFr6M6z+i6+e0tED9pjZvGPNfnc3EKR+Od+1DClc+kSKkxH8gcIcNS0NyXxGrbVa9Cs07w/7KISG5H31emI86ITST661KSmI1z9Dw5SOwbmVFqK8Wkbwp8e9PdmwIddwb4hSXp6x8DZ7ZGo4p7QMjJ8Hkv4NDTgjTkHG9qx20iPQoJf7epKUFtq3OSOpL2yR46je1Pb7/wTD0cNYNP5mRk+Pd/IijQ/WKiEgHEk38ZlYLbAXSQLO7TzazocCvgbGE3jkv9iwjcB3QGrYyZMMr8NLi0DJlV4Kv3V09AxktVMbBxL8OX14OGQdDDw913bE55KKaGkZOntoDD0RE9kc9Mdj69cCT7n6rmV0f17/WDeXoWe5QNwvm3APzH+C4pu0wj1A1M2RcSOrjzwzz1gQ/+FDdvYtIwfVEVc/HgKlx+R6ghgM58W9fD/N+DXP+J7SqKesHEy/i1fQEjjv74lBdU6JOUkWk+ySd+B143Mx2DbYOVLn7qrh/NWHAlgNLSwsseyYk+zceCT8wOmQyfPQHMPEiqBjAxpoaGDiqp0sqIkXIvLW3uCSCmx3i7ivMbATwBHAV8LC7D844ZqO779Ew28ymA9MBqqqqqmfMmJFTGbpztPvyhvUcvPpJRq76I5X1a2gq7c+aqmmsGnk22/uP7bFyKZZiKVb3xSp0vHxiTZs2bba7T95jR7YR2JOYgJuAa4FFwMi4bSSwqLNzq6urcx5lPvHR7psb3Rc+4n7vxe43DXb/5kD3u89zn/cb98adPVcuxVIsxeqRWIWOl08sYJZnyamJVfXEAdZL3H1rxmDr/wI8DFwO3BrnDyVVhkStfwte+TnM/WXo8rb/wXDaP8LxnwytbkREeqmeGGz9ZeA+M7sSeBu4OMEyFFRJuhHm/Sa0zKl9NjS3PPKDcMKnYcJfqY8YEdkv9MRg6+uBs5K6bmJem8mpf7kamreFNvRnfQOO+1sYOLKnSyYisk90i9oV69+Ch69iZ+UhlF34PRh7uppgish+S9mrM+lmePBzkCpn/sQb4PAPKOmLyH5NGawzz90GdS/Ded+nsWJYT5dGRCRvSvx7s2IOPHMrHPs3oa8cEZEDgBJ/Rxp3hCqefiPg3P/b06URESkYfbnbkT/eBOvehE/9ViM+icgBRXf82Sx5El76MZz8BRg/radLIyJSUEr87e3YAA99EYYfBWd/s6dLIyJScKrqae/Ra2H7u3DpDCir7OnSiIgUnO74M702E+bfD1NvgFGTero0IiKJUOJvtbkO/verMOZkmPKVni6NiEhilPghDJzy238Iv9K98L/V2ZqIHNCU4SC04Fn2DHz0dnWpLCIHvMTv+M0sZWavmNkjcf1uM1tmZnPjNCnpMuzV2jfgiW/CkR+CEy7v0aKIiHSH7rjjvxpYCAzM2Hadu8/shmvvXXMjPPBZqOgP5/8QwtgBIiIHtETv+M1sNPAR4KdJXidnz9wKq+eFQdD7j+jp0oiIdIukB1ufCfwbMAC41t3PM7O7gVOBBuBJ4Hp3b8hybqKDrQ/cvJDjX7mR1QefyaL3XJVXrEKWS7EUS7H271iFjrdfDbYOnAf8Z1yeCjziuwdYN6ACuAf4RmexCj7Yev1W9/94n/ttx7rXb8kvViHLpViKpVj7faxCx0tisPUkq3qmAOebWS0wAzjTzH7h7qtimRqAnwEnJViG7P5wI2x8Gy78MVQM6PbLi4j0pMQSv7vf4O6j3X0scAnwlLt/0sxGAlgYhf0CYH5SZchq0e/DYOmnfQUOO7VbLy0i0hv0RDv+e83sIEJ1z1zg89125W3vwsNXQdWxMPXGbrusiEhv0i2J391rgJq4fGZ3XDNLIeB3V0P9Zvj0w1Ba3iPFEBHpacXzy91XfgGL/hfOuQWqjunp0oiI9Jji6KtnwzJ47HoYezqc8g89XRoRkR7VpcRvZuPNrCIuTzWzL5vZ4ERLViieht9+AawELvgvKCmO9zoRkY50NQveD6TNbAJwBzAG+GVipSqgMct/C+/8Bc79Lgwe09PFERHpcV1N/C3u3gxcCPzQ3a8j/BCrd1s1j3HLfgnHXADvu7inSyMi0it0NfE3mdmlwOXAI3FbWTJFKqAX/5umsgFw3m3qgE1EJOpqq57PENrb3+Luy8xsHPDz5IpVIB/9AXPLp3By36E9XRIRkV6jS4nf3ReY2deAQ+P6MuA7SRasIFKl7Ox7SE+XQkSkV+lqq56PEn5l+1hcn2RmDydYLhERSUhX6/hvInSmtgnA3ecCGqNQRGQ/1OUvd919c7ttLYUujIiIJK+rX+6+bmZ/C6TM7Ajgy8DzyRVLRESS0tU7/quA9xJGzfolsBn4SkJlEhGRBHV6x29mKeB/3X0a8PV9vUA8fxawwsPQi+MIA7MMA2YDn3L3xn2NKyIiuen0jt/d00CLmQ3K8RpXAwsz1r8D3ObuE4CNwJU5xhURkRx0tapnG/Camd1pZj9onTo7ycxGAx8BfhrXDTgTmBkPuYcwCpeIiHQTC+PxdnKQ2eXZtrv7PZ2cNxP4N2AAcC1wBfBCvNvHzMYAv3f3iVnOnQ5MB6iqqqqeMWNGp+XMpreMdq9YiqVYxRGr0PHyiTVt2rTZ7j55jx3ZRmDPNgHlwMQ4lXXh+POA/4zLUwl9/AwHlmQcMwaY31ms6urqnEeZ7y2j3SuWYilWccQqdLx8YgGzPEtO7VJzTjObSqiWqSWMlTvGzC539z/t5bQpwPlmdi7QBxgI3A4MNrNSD719jgZWdKUMIiJSGF2t4/8ecI67f8DdzwA+CNy2txPc/QZ3H+3uY4FLgKfc/TLgaeDj8bDLgYdyKrmIiOSkq4m/zN0Xta64+5vk3i3z14CvmtkSQpPOO3OMIyIiOejqL3dnmdlPgV/E9csIbfO7xN1rgJq4vJTQ74+IiPSArib+LwBfJHTVAPAs8J+JlEhERBLV1cRfCtzu7t+HXb/GrUisVCIikpiu1vE/CVRmrFcCfyx8cUREJGldTfx93H1b60pc7ptMkUREJEldTfzbzeyE1hUzmwzsTKZIIiKSpK7W8X8F+I2ZrYzrI4FPJFIiERFJ1F7v+M3sRDM72N1fBt4D/BpoIoy9u6wbyiciIgXWWVXPj4HWvvJPBW4EfkToTvmOBMslIiIJ6ayqJ+XuG+LyJ4A73P1+4H4zm5toyUREJBGd3fGnzKz1zeEs4KmMfV39fkBERHqRzpL3r4BnzGwdoRXPswBmNoEw7q6IiOxn9pr43f0WM3uS0Irn8di/M4RPClclXTgRESm8Tqtr3P2FLNveTKY4IiKStK7+gGufmVkfM3vJzF41s9fN7Ftx+91mtszM5sZpUlJlEBGRPSX5BW0DcKa7bzOzMuA5M/t93Hedu8/cy7kiIpKQxBJ//D6gtX+fsjh1PrK7iIgkynZ/X5tA8NB982xgAvAjd/+amd1N+DFYA6HXz+vdvSHLudOB6QBVVVXVM2bMyKkMvWW0e8VSLMUqjliFjpdPrGnTps1298l77Mg2AnuhJ2AwYazdiYQWQkboz/8e4BudnV9dXZ3zKPO9ZbR7xVIsxSqOWIWOl08sYJZnyamJfbnb7s1lU0z8H3L3VbFMDcDP0DCMIiLdKslWPQeZ2eC4XAn8FfCGmY2M2wy4AJifVBlERGRPSbbqGQncE+v5S4D73P0RM3vKzA4iVPfMBT6fYBlERKSdJFv1zAOOz7L9zKSuKSIineuWOn4REek9lPhFRIqMEr+ISJFR4hcRKTJK/CIiRUaJX0SkyCjxi4gUGSV+EZEio8QvIlJklPhFRIqMEr+ISJFR4hcRKTI9Mdj6ODN70cyWmNmvzaw8qTKIiMiekrzjbx1s/ThgEvAhMzsF+A5wm7tPADYCVyZYBhERaSexxB9H2co22PqZwMy4/R7CYCwiItJNEq3jN7OUmc0F1gJPAG8Bm9y9OR5SBxySZBlERKQtC+PxJnyRMATjg8A/A3fHah7MbAzwe3efmOWc6cB0gKqqquoZM2bkdO3eMtq9YimWYhVHrELHyyfWtGnTZrv75D12ZBuBPYkJ+AZwHbAOKI3bTgX+0Nm51dXVOY8y31tGu1csxVKs4ohV6Hj5xAJmeZac2t2DrS8EngY+Hg+7HHgoqTKIiMieemKw9QXADDP7V+AV4M4EyyAiIu30xGDrS4GTkrquiIjsnX65KyJSZJT4RUSKjBK/iEiRUeIXESkySvwiIkUmyeacsp9oaE4zf8VmXq7dyPPzG3hq83z6lKXiVEKf0ozlNvNU3Ld7vbIsRUVpCSUltit+S4vT0NxCY3MLDc1pGppb4hSXm1poTLfQ0LR7X+axjc0tLF7ayJzGRWBGiYER5wZmFuYZ20osXN92HQ8lJYYBi99pYvlfaoHQeZQ7rT8y3L0ey75re9zgeJv9by1tZH7LYprSTrrFaW5x0i0tNLc4zem26+ld21oyjnWa0mF906ad3PnWi/SvKKVfRSn9ylNhnrHcv6KUvhWl9K+I+8rj/ooU5akSzHY/7+25h2u2eX6bsj/fmX+b+e808fbztaRbnBb3OGfXcpe3tzirVjfw3LYFDKosY1DfMgb2KWNQZRkDK8O8dSov1T1pkpT4i9DmnU3MeXsjL9duYFbtRubWbaKxuQWAgeXw6vqV1McknKvy0hJKvIX0E4/SlM6/WxADWLpkVwLO24LXCxQIePNNAFIlRqrEKM2Yl6ZK9rqeitvKUiWUlsDW+mZWb65ne0Mz2xqa2d6YJt3StQddWmK73hzSTfWUvfTUHom9i6H21MnzZQYpM0pKwhtt63KqxNpsb2hIM2vtO+xoTO81XmVZqs0bQfs3hkGVpSyva2LVS+/seq12NG/YY72F+vim1zpvbE5T/uRjVMQbnWzzitISKuKNTZ+9zMtTJby5spmtr64kFR93iYXnoiQ+H6kS2/WcZd2e8bw1NBe+Wx0l/iKwYtNOZtVu2JXoF63ZintIFBMPGcTlpx7G5LFDqT5sCPNn/YWpU6cC4Q6tMR3+YXY2palvCsv1rcvNaeob02G+a18LO5vSNDSlWfb2O4wfdxgVpSWUl5ZQURr+OVr/gcpTJbv/oTL3ZfyjlZeWUJ4q4bln/7SrXO7hDnLXvPUuPC5n7iPLtj8//2emvH8KrTfHRvzUEJ+v1k8PrRvMdh+z+/hwzJ+e/RNnTv3Arn/SfNTU1DB16pQ229zDHfr2hmZ2NKbDm0F8U8hcb79v+crVjB45dNdz2ub5LyuJz32qzXNfXto2ubWuz3rxBU4/bUqbBFViRkkJGcmqa489PMapNDa3sKW+ic07d09bWpd3tN2+eWcTdRt3sGBlWN6e+aYx/7U28ctT7RN0eHyt8/79Sne9vnYl9rIUK+uWM2r0mPDmkOWNYVtDM+u37V5v82kp3cEN0rxX9unv35GvVlfwwYJE2k2J/wDT0uIsWrM1JvqNzKrdwMrN9QD0ryjlhMOG8JFjRzJ57FAmjRlMZXmqw1glJUafklCFMziHstTUrGHq1Pfk9kD2wsxIGezKzPtocEUJBw2oKEhZKlJGWSq5agkz21WNNmwfzgsJdlJByrCkTwnD+hfm+WpVXlrC8P4VDM8hblO6ha31zfzxmec4Y8r7d99pl5aQyvHNN7xWj87p3HSL09juk8ZfXniRySeeSIvTpsor7U5LrPrqyvYWd1pWL8qpXHujxL+fcW+9Cw8fYeubWli0Ic3rTy9hVu0GZr29ka31odfrqoEVTB47lOmHDWHy2KEcPXJgzv8YIr1FWaqEof3KGdG3hIMH9enp4pAqMSrLU21uomr7l3BE1YCCxK+pWVyQOJmU+LvZlvom/vLWeh5b0siL9W/sqh5paApVJjsbM6pRdiX3NPXNu6tZstfTLuKIEf05732jOHHsEE4cO5TRQyq7/BFcRIqHEn/CmtMtzFuxmWffXMezi9/lleWbdn1ZV7ZsaaxnbNtiprIsRf+KUob1a9eSpjTcVWR+kdSnLEXdW29w+UfOYEg/DV8sIp1T4k/A8g07eHZxSPR/XrKOLfXNmMH7DhnEFz4wntOPGM6W2nn81ZnTCnK9mq1LlPRFpMsSS/xxdK3/AaoIzZ7vcPfbzewm4LPAu/HQG9390aTK0R22xuqb55as49nF61i2bjsAowb14cMTR3L6kcOZMn54m+Rc846qYESkZyR5x98MXOPuc8xsADDbzJ6I+25z9+8meO1EpVuceXWbdt3Vz3knVN/0LU9xyuHD+PSph3H6EQcx/qB+qmMXkV4nyf74VwGr4vJWM1vIfjyw+uadTdQsb+K+e2fz5yXr2byzCTM49pBBfP4Dh3P6EQdxwqFD9ItDEen1umuw9bHAn4CJwFeBK4AtwCzCp4KNWc7pNYOtr97ewm2z61mzwxnax3jvsBQTh6c4ZliKAeW53dH3lsGYFUuxFEuDrScxyHp/YDZwUVyvAlqHY7wFuKuzGD052PoLb63z4771Bz/+Xx73/5z5R29packrXqHKpViKpVi9M1ah4+1Xg60DmFkZcD9wr7s/EN9o1rh72t1bgJ/Qi4dhfGBOHZ+880WG9Svnt/8whaOHpVRnLyL7vcQSv4UMeSew0N2/n7F9ZMZhFwLzkypDrtyd2554k6/e9yqTDxvKA1+YwqHD+vZ0sURECiLJVj1TgE8Br5nZ3LjtRuBSM5tEaOJZC3wuwTLss4bmNNff/xoPvrKCj1eP5tsXHqsvbEXkgJJkq57nyN6LVq9ts79xeyOf+/lsXqrdwHUfPIp/mDpeVTsicsDRL3ejZeu283d3v8yKTTv54aXH89HjRvV0kUREEqHED7y0bAPTfz6LEjN+9dmTqT5saE8XSUQkMUWf+B98pY6vzXyN0UMr+dkVJ3LYsH49XSQRkUQVbeJ3d25/cjH/8cfFnHL4UH78yckM6lvW08USEUlcUSb+zJY7f33CaP7tIrXcEZHiUXSJf+P2Rj73i9m8tGwD155zJF+cNkEtd0SkqBRV4q9dt53PxJY7t18yiY9N2m/7jBMRyVnRJP6Xazcw/X9mAfDLvz+ZyWPVckdEilNRJP6H5q7gut/MY/SQSu664kTGDlfLHREpXgd04nd3HlrSyINL5nLyuKH8+FPVDO6rIQpFpLgd0In/W79bwINLmrjohEO49aL3qeWOiAgHeOI/99iRbHl3Bd/7m+PUckdEJDqgE/9J44ayY3y5kr6ISIYk++MfY2ZPm9kCM3vdzK6O24ea2RNmtjjOhyRVBhER2VOSld7NhPF0jwFOAb5oZscA1wNPuvsRwJNxXUREukliid/dV7n7nLi8FVgIHAJ8DLgnHnYPcEFSZRARkT1ZGI834YuYjQX+BEwE3nH3wXG7ARtb19udMx2YDlBVVVU9Y8aMnK7dW0a7VyzFUqziiFXoePnEmjZt2mx3n7zHjmwjsBdyAvoDs4GL4vqmdvs3dhajuro651Hme8to94qlWIpVHLEKHS+fWMAsz5JTE23YbmZlwP3Ave7+QNy8pnXA9Thfm2QZRESkrSRb9RhwJ7DQ3b+fseth4PK4fDnwUFJlEBGRPSXZjn8K8CngNTObG7fdCNwK3GdmVwJvAxcnWAYREWknscTv7s8BHf1y6qykrisiInunzmtERIqMEr+ISJFR4hcRKTJK/CIiRUaJX0SkyCjxi4gUGSV+EZEio8QvIlJklPhFRIqMEr+ISJFR4hcRKTJK/CIiRUaJX0SkyCTZH/9dZrbWzOZnbLvJzFaY2dw4nZvU9UVEJLsk7/jvBj6UZftt7j4pTo8meH0REckiscTv7n8CNiQVX0REcpPkCFwd+ZKZfRqYBVzj7huzHWRm04HpcXWbmS3K8XrDgXU5nqtYiqVYitXT8fKJdVjWrdlGYC/UBIwF5mesVwEpwieNW4C7krx+vGbWUeYVS7EUS7GSiNXby+bu3duqx93XuHva3VuAnwAndef1RUSkm5tzmtnIjNULgfkdHSsiIslIrI7fzH4FTAWGm1kd8E1gqplNAhyoBT6X1PUz3KFYiqVYitWNsQodr9Blw2IdkoiIFAn9cldEpMgo8YuIFJkDNvFn6zIij1hjzOxpM1tgZq+b2dV5xOpjZi+Z2asx1rcKUL6Umb1iZo/kGafWzF6L3WnMyjPWYDObaWZvmNlCMzs1xzhHZXTxMdfMtpjZV/Io1z/G532+mf3KzPrkEevqGOf1fS1TB12aDDWzJ8xscZwPySPW38RytZjZ5DzL9X/j33GemT1oZoPziHVzjDPXzB43s1G5xsrYd42ZuZkNz6NcOXUn01G5zOyq+Jy9bmb/nke5fp1Rplozm9uVWJ0qdPvQ3jIBZwAnkPE7gjxijQROiMsDgDeBY3KMZUD/uFwGvAickmf5vgr8Engkzzi1wPACPf/3AH8fl8uBwQWImQJWA4fleP4hwDKgMq7fB1yRY6yJhFZpfQmNJP4ITNiH8/d4fQL/Dlwfl68HvpNHrKOBo4AaYHKe5ToHKI3L38mzXAMzlr8M/HeuseL2McAfgLe7+trtoFw3Adfm8DrIFmtafD1UxPUR+TzGjP3fA76Ry+u1/XTA3vF7AbuMcPdV7j4nLm8FFhKSSC6x3N23xdWyOOX8DbuZjQY+Avw01xiFZmaDCC/iOwHcvdHdNxUg9FnAW+7+dh4xSoFKMyslJO2VOcY5GnjR3Xe4ezPwDHBRV0/u4PX5McIbJnF+Qa6x3H2hu+/zr907iPV4fIwALwCj84i1JWO1H1187e/l//k24J+6GqeTWPusg1hfAG5194Z4zNp8y2VmBlwM/Cr30u52wCb+pJjZWOB4wp16rjFS8SPbWuAJd885FvAfhBd+Sx4xWjnwuJnNjl1m5Goc8C7ws1gF9VMz61eA8l1CHi98d18BfBd4B1gFbHb3x3MMNx843cyGmVlf4FzC3Wc+qtx9VVxeTfile2/zd8Dv8wlgZreY2XLgMuAbecT5GLDC3V/NpzwZvhSroe7qajVbB44kvDZeNLNnzOzEApTtdGCNuy8uQCwl/n1hZv2B+4GvtLtz2Scefr08iXDndJKZTcyxPOcBa919dq5laec0dz8B+DDwRTM7I8c4pYSPrP/l7scD2wlVFzkzs3LgfOA3ecQYQrirHgeMAvqZ2SdzieXuCwnVHo8DjwFzgXSuZcsS38njk2ASzOzrQDNwbz5x3P3r7j4mxvlSjmXpC9xIHm8c7fwXMB6YRLgp+F4esUqBocApwHXAffGOPR+XUqC7fVDi7zIzKyMk/Xvd/YFCxIzVH0+TvfvqrpgCnG9mtcAM4Ewz+0Ue5VkR52uBB8m9S406oC7jk8xMwhtBPj4MzHH3NXnEOBtY5u7vunsT8ADw/lyDufud7l7t7mcAGwnf/eRjjcVft8d5l6oIuoOZXQGcB1wW35QK4V7gr3M8dzzhDfzV+PofDcwxs4NzCeaF7U6mDnggVuu+RPg03qUvnrOJ1ZIXAb/Oo0xtKPF3QXy3vhNY6O7fzzPWQa2tIsysEvgr4I1cYrn7De4+2t3HEqpBnnL3nO5gzayfmQ1oXSZ8oZdTiyh3Xw0sN7Oj4qazgAW5xMpQiDued4BTzKxv/JueRfi+JidmNiLODyX8Y/4yz/I9DFwely8HHsozXkGY2YcI1Ynnu/uOPGMdkbH6MXJ/7b/m7iPcfWx8/dcRGmCszrFchexO5reEL3gxsyMJjRvy6anzbOANd6/LI0ZbhfiGuDdOhCSxCmgivCiuzCPWaYSP3fMIH+nnAufmGOt9wCsx1nwK9C09oXuMnFv1AIcDr8bpdeDreZZnEqHr7XmEf4QhecTqB6wHBhXgefoWIdnMB35ObHmRY6xnCW9orwJn7eO5e7w+gWHAk8BiQquQoXnEujAuNwBrgD/kEWsJsDzjtd/VljjZYt0fn/t5wO+AQ3KN1W5/LV1v1ZOtXD8HXovlehgYmUescuAX8XHOAc7M5zESBrX6fL6v/cxJXTaIiBQZVfWIiBQZJX4RkSKjxC8iUmSU+EVEiowSv4hIkVHil6JmZmlr2/tnXr8wbhd7bLbeJEV6WmJDL4rsJ3Z66D5DpGjojl8ki9j3+b9bGJ/gJTObELePNbOnYmdeT8Zf7WJmVbGv+lfj1NoVRMrMfhL7ZX88/lobM/uyhfEd5pnZjB56mFKklPil2FW2q+r5RMa+ze5+LPD/CL2gAvwQuMfd30foa+YHcfsPgGfc/ThCv0Svx+1HAD9y9/cCm9jdN831wPExzueTeWgi2emXu1LUzGybu/fPsr2W8FP7pbGDvtXuPszM1hF+zt8Ut69y9+Fm9i4w2mMf7DHGWEK320fE9a8BZe7+r2b2GLCN0J3Fb333GA0iidMdv0jHvIPlfdGQsZxm9/dqHwF+RPh08HLsgVGkWyjxi3TsExnzv8Tl5wk9oUIYSOTZuPwkYeSl1oF2BnUU1MxKgDHu/jTwNWAQsMenDpGk6C5Dil1luwGsH3P31iadQ8xsHuGu/dK47SrCyGLXEUYZ+0zcfjVwh5ldSbiz/wKhp8VsUsAv4puDAT/wwgxNKdIlquMXySLW8U9293z6URfplVTVIyJSZHTHLyJSZHTHLyJSZJT4RUSKjBK/iEiRUeIXESkySvwiIkXm/wNkyw1iUBu4bAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(epoch - len(em_scores) + 1, epoch + 1)], em_scores)\n",
    "plt.plot([i for i in range(epoch - len(f1_scores) + 1, epoch + 1)], f1_scores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores on SQuAD 1.1')\n",
    "plt.legend(['EM', 'F1'])\n",
    "plt.xticks([i for i in range(1, len(f1_scores) + 1)])\n",
    "plt.yticks(np.arange(15, 70, 5))\n",
    "plt.savefig(f\"best{epoch - len(f1_scores) + 1}-{epoch}.png\", dpi=350)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# for i, t_data in enumerate(testloader):\n",
    "#     idx = i\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 348])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (p, q, s, a, p_mask, q_mask), p 길이 점점 증가\n",
    "# p, q: tensor, batch size * length\n",
    "# s: tuple of tensors, batch size\n",
    "# a:\n",
    "dataiter = iter(trainloader)\n",
    "dataiter_next = dataiter.next()\n",
    "dataiter_next[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 23])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "for i in range(100):\n",
    "    dataiter_100 = dataiter.next()\n",
    "dataiter_100[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start_pred.shape\n",
    "# start_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "# print(start_pred_argmax)\n",
    "# print(span_list)\n",
    "# print(span_list[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paragraphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-70-c8301ee379e5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparagraphs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspan_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0manswer_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0mi\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'paragraphs' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p, s, a in zip(paragraphs, span_list, answer_list):\n",
    "    i += 1\n",
    "    if i < 3:\n",
    "        print(p)\n",
    "        print(s)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# em_score = 0\n",
    "# for i, (p, s, a) in enumerate(list(zip(paragraphs, span_list, answer_list))):\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     if i < 3:\n",
    "#         # print(p)\n",
    "#         # print(s)\n",
    "#         # print(a)\n",
    "#         em_score += em_func(p, a[0], s)\n",
    "# print(em_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
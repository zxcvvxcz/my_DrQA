{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainloader length: 2700\n",
    "# testloader length: 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:21<00:00, 3985.38lines/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import SQuAD1\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "# data_dir = '.data'\n",
    "# data_names = ['dev-v1.1.json', 'train-v1.1.json']\n",
    "# for data_name in data_names:\n",
    "#     if not os.path.isfile(os.path.join(data_dir, data_name)):\n",
    "#         print('download')\n",
    "#         train, dev = SQuAD1()\n",
    "#         break\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# dataset shape: (paragraph, question, answer, span)\n",
    "trainset, devset = SQuAD1(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = trainset.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# errors = 0\n",
    "# print('length of vocab before filtering:', len(vocab.stoi))\n",
    "# for key, value in list(vocab.stoi.items()):\n",
    "#     if re.search('\\n', key) or re.search(' ', key):\n",
    "#         errors += 1\n",
    "#         print(key)\n",
    "#         vocab.stoi.pop(key)\n",
    "#         vocab.itos.pop(value)\n",
    "#         vocab.freqs.pop(key)\n",
    "#         # vocab.freqs[key] -= 1\n",
    "#         # if vocab.freqs[key] < 1:\n",
    "#         #     vocab.freqs.pop(key)\n",
    "#\n",
    "# print(errors)\n",
    "# print('length of vocab after filtering:', len(vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trainset, devset = SQuAD1(vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_large_text(data):\n",
    "    return data[0] <= 400\n",
    "\n",
    "def check_train_data(data):\n",
    "    # data might be wrong because of spacy tokenizer\n",
    "    p_length, q_length, idx, paragraph, question, answer, span = data\n",
    "    if span[0][0] > p_length or span[0][1] > p_length:\n",
    "        return False\n",
    "    if paragraph[span[0][0]] == answer[0][0] and paragraph[span[0][1]] == answer[0][-1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_dev_data(data):\n",
    "    p_length, q_length, idx, paragraph, question, answers, spans = data\n",
    "    if len(spans) != 3 or len(answers) != 3:\n",
    "        return False\n",
    "    else:\n",
    "        for span, answer in zip(spans, answers):\n",
    "            if span[0] > p_length or span[1] > p_length:\n",
    "                return False\n",
    "            if paragraph[span[0]] != answer[0] or paragraph[span[1]] != answer[-1]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86412\n",
      "8295\n"
     ]
    }
   ],
   "source": [
    "train_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(trainset)]\n",
    "dev_data = [(len(paragraph), len(question), idx, paragraph, question, answer, span)\n",
    "            for idx, (paragraph, question, answer, span) in enumerate(devset)]\n",
    "\n",
    "train_data = list(filter(remove_large_text, train_data))\n",
    "dev_data = list(filter(remove_large_text, dev_data))\n",
    "\n",
    "train_data = list(filter(check_train_data, train_data))\n",
    "dev_data = list(filter(check_dev_data, dev_data))\n",
    "\n",
    "\n",
    "train_data.sort() # sort by length and pad sequences with similar lengths\n",
    "dev_data.sort()\n",
    "# paragraph, question: tensor of indices of words, use itos to get word\n",
    "print(len(train_data))\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(train_data[0][3])\n",
    "# for idx in train_data[0][3]:\n",
    "#     print(train.get_vocab().itos[idx], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pad_data(data):\n",
    "    # Generate the pad id\n",
    "    pad_id = vocab['<pad>']\n",
    "    # Find max length of the mini-batch\n",
    "    # train.get_vocab()['pad'], dev.get_vocab()['pad'] is equal to 22949\n",
    "    max_p_len = max(list(zip(*data))[0])\n",
    "    max_q_len = max(list(zip(*data))[1])\n",
    "    paragraph_list = list(zip(*data))[3]\n",
    "    question_list = list(zip(*data))[4]\n",
    "    answer_list = list(zip(*data))[5]\n",
    "    span_list = list(zip(*data))[6]\n",
    "    padded_paragraphs = torch.stack([torch.cat((paragraph,\n",
    "            torch.LongTensor([pad_id] * (max_p_len - len(paragraph))))) \\\n",
    "            for paragraph in paragraph_list])\n",
    "    padded_questions = torch.stack([torch.cat((question,\n",
    "            torch.tensor([pad_id] * (max_q_len - len(question))).long())) \\\n",
    "            for question in question_list])\n",
    "    paragraph_pad_mask = torch.zeros_like(padded_paragraphs).masked_fill(padded_paragraphs == pad_id, 1)\n",
    "    question_pad_mask = torch.zeros_like(padded_questions).masked_fill(padded_questions == pad_id, 1)\n",
    "\n",
    "    return padded_paragraphs, padded_questions, span_list, answer_list, \\\n",
    "           paragraph_pad_mask, question_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_data)\n",
    "testloader = DataLoader(dev_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([12163, 56789]), tensor([12163, 56789]), tensor([12163, 56789])] [tensor([33, 34]), tensor([33, 34]), tensor([33, 34])]\n",
      "facing\n",
      "it\n",
      "[tensor([  881, 20129]), tensor([  881, 20129]), tensor([  881, 20129])] [tensor([44, 45]), tensor([44, 45]), tensor([44, 45])]\n",
      "upraised\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "for i, (p, q, a, s) in enumerate(devset):\n",
    "    print(a,s)\n",
    "    nps = s[0].numpy()\n",
    "    tokens = tokenizer(trainset.data[i][0])\n",
    "    print(tokens[int(nps[0])])\n",
    "    print(tokens[nps[1]])\n",
    "    # print(tokens[a[0].numpy().item()])\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, (padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "           paragraph_pad_mask, question_pad_mask) in enumerate(trainloader):\n",
    "    # print(idx, padded_paragraphs, padded_questions, span_list, answer_list,\n",
    "    #        paragraph_pad_mask, question_pad_mask)\n",
    "    # print(padded_paragraphs.masked_fill(paragraph_pad_mask == 1, -1))\n",
    "    if idx > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(trainset.get_vocab()['pad'], dev.get_vocab()['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_vec = torchtext.vocab.GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_embedding(vocab, pre_trained_emb_vec):\n",
    "    # print(pre_trained_emb_vec.dim)\n",
    "    weights_matrix = np.zeros((len(vocab), pre_trained_emb_vec.dim))\n",
    "    words_found = 0\n",
    "    no_word = 0\n",
    "    for i, (word, _) in enumerate(vocab.freqs.most_common()):\n",
    "        try:\n",
    "            word_index = pre_trained_emb_vec.stoi[word]\n",
    "            weights_matrix[i] = pre_trained_emb_vec[word_index]\n",
    "            words_found += 1\n",
    "        except:\n",
    "            no_word += 1 # no such word in pre_trained_embedding: zero vector\n",
    "    print('words not found:', no_word)\n",
    "    print('words found:', words_found)\n",
    "    return torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for key, value in vocab.freqs.items():\n",
    "#     if re.search(' ', key):\n",
    "#         print(key, value)\n",
    "# for i, word in enumerate(vocab.freqs.most_common()):\n",
    "#     print(word)\n",
    "#     if i > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words not found: 17435\n",
      "words found: 86591\n"
     ]
    }
   ],
   "source": [
    "word_emb_table = build_word_embedding(vocab, glove_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# glove_vec.vectors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not using now\n",
    "# import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser','ner',])\n",
    "#\n",
    "# def exact_match(paragraphs_indices, questions_indices, vocab):\n",
    "#     # process one paragraph batch, one question batch\n",
    "#     # print(paragraphs_indices.size())\n",
    "#     # print(questions_indices.size())\n",
    "#     #\n",
    "#     # j = 0\n",
    "#     # for (paragraph_indices, question_indices) in \\\n",
    "#     #         zip(paragraphs_indices, questions_indices):\n",
    "#     #     j += 1\n",
    "#     # print('j:',j)\n",
    "#     exact_match_table = np.zeros((len(paragraphs_indices), len(paragraphs_indices[0]), 3))\n",
    "#     # print(exact_match_table.shape)\n",
    "#\n",
    "#     for i, (paragraph_indices, question_indices) in \\\n",
    "#             enumerate(zip(paragraphs_indices, questions_indices)):\n",
    "#         # print(paragraphs_indices)\n",
    "#         # print(paragraphs_indices.size())\n",
    "#         # paragraph_processed = nlp(paragraph_sentence)\n",
    "#         # question_lemmas = [lem.lemma_ for lem in question_processed]\n",
    "#         for j, paragraph_index in enumerate(paragraph_indices):\n",
    "#             paragraph_word = vocab.itos[paragraph_index]\n",
    "#             if paragraph_word == '<pad>':\n",
    "#                 # print('got pad')\n",
    "#                 continue\n",
    "#             em_tensor = torch.LongTensor([0, 0, 0])\n",
    "#             # original\n",
    "#             if paragraph_index in question_indices:\n",
    "#                 em_tensor[0] = 1\n",
    "#             # lemma\n",
    "#             if vocab.stoi[nlp(paragraph_word)[0].lemma_] in question_indices:\n",
    "#                 em_tensor[1] = 1\n",
    "#             # uncased\n",
    "#             if vocab.stoi[paragraph_word.lower()] and \\\n",
    "#                     vocab.stoi[paragraph_word.lower()] in question_indices:\n",
    "#                 em_tensor[2] = 1\n",
    "#             exact_match_table[i][j] = em_tensor\n",
    "#\n",
    "#     return torch.LongTensor(exact_match_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AlignedQuestionEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_dim, input_dim)\n",
    "        self.linear2 = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, paragraph, question, question_pad_mask):\n",
    "\n",
    "        p = self.relu(self.linear1(paragraph))\n",
    "\n",
    "        q = self.relu(self.linear2(question))\n",
    "        q = q.permute(0, 2, 1)\n",
    "\n",
    "        dot_product = torch.bmm(p, q)\n",
    "        # print(dot_product.size())\n",
    "        # print(question_pad_mask.size())\n",
    "        question_mask_expand = question_pad_mask.unsqueeze(1).expand(dot_product.size())\n",
    "        dot_product = dot_product.masked_fill(question_mask_expand == 1, -float('inf'))\n",
    "\n",
    "        dot_product_flatten = dot_product.view(-1, question.size(1))\n",
    "\n",
    "        attn_score = F.softmax(dot_product_flatten, dim=1)\n",
    "        attn_score = attn_score.view(-1, paragraph.shape[1], question.shape[1])\n",
    "\n",
    "        aligned_embedding = torch.bmm(attn_score, question)\n",
    "        return aligned_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLayerBiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstms.append(nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True))\n",
    "        for i in range(1, nlayers):\n",
    "            self.lstms.append(nn.LSTM(hidden_size * 2, hidden_size,\n",
    "                                      batch_first=True, bidirectional=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.dropout(x)\n",
    "        lstm_output, (_, _) = self.lstms[0](x)\n",
    "        hidden_states = [lstm_output]\n",
    "        # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "        for i in range(1, self.nlayers):\n",
    "            # lstm_output = self.dropout(lstm_output)\n",
    "            lstm_output, (_, _) = self.lstms[i](lstm_output)\n",
    "            # print(lstm_output.size(), hidden_state.size(), cell_state.size())\n",
    "            hidden_states.append(lstm_output)\n",
    "\n",
    "        output = torch.cat(hidden_states, dim=2)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionEncoding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm_output_size = hidden_size * 6\n",
    "        self.linear = nn.Linear(self.lstm_output_size, 1)\n",
    "        self.lstm = MultiLayerBiLSTM(input_size, hidden_size, nlayers, dropout)\n",
    "        # biLSTM output size: hidden size * 6\n",
    "    def forward(self, x, question_mask):\n",
    "        try:\n",
    "            x = self.lstm(x)\n",
    "            b = x.view(-1, self.lstm_output_size)\n",
    "            b = self.linear(b) # attention score\n",
    "            b = b.view(question_mask.shape[0], -1)\n",
    "            # print(x.size(), question_mask.size())\n",
    "            b = b.masked_fill(question_mask == 1, -float('inf')) # masking\n",
    "            b = F.softmax(b, dim=1)\n",
    "\n",
    "            b = b.unsqueeze(1)\n",
    "            # print(x.size(), x_lstm.size())\n",
    "            encoding = torch.bmm(b, x)\n",
    "            encoding = encoding.squeeze(1)\n",
    "            return encoding\n",
    "        except:\n",
    "            print('question mask size:', question_mask.size())\n",
    "            print('x size:', x.size())\n",
    "            print('b size:', b.size())\n",
    "            print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionLayer(nn.Module):\n",
    "    def __init__(self, p_size, q_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(q_size, p_size)\n",
    "\n",
    "    def forward(self, paragraph, question, paragraph_mask):\n",
    "        Wq = self.linear(question)\n",
    "        Wq = Wq.unsqueeze(2)\n",
    "        pWq = paragraph.bmm(Wq)\n",
    "        pWq = pWq.squeeze(2)\n",
    "        pWq = pWq.masked_fill(paragraph_mask == 1, -float('inf'))\n",
    "        return pWq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fixate_embedding(grad):\n",
    "    grad[1000:] = 0\n",
    "    return grad\n",
    "\n",
    "class DocumentReader(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, nlayers, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.word_embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(word_emb_table).to(device), freeze=False)\n",
    "        self.word_embedding_layer.weight.register_hook(fixate_embedding)\n",
    "        # print(embedding_size)\n",
    "        self.aligned_embedding_layer = AlignedQuestionEmbedding(embedding_size)\n",
    "        # self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2 + 3, hidden_size, nlayers, dropout)\n",
    "        self.paragraph_lstm = MultiLayerBiLSTM(embedding_size * 2, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.question_encoder = QuestionEncoding(embedding_size, hidden_size, nlayers, dropout)\n",
    "\n",
    "        self.prediction_layer_start = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                          hidden_size * nlayers * 2)\n",
    "        self.prediction_layer_end = PredictionLayer(hidden_size * nlayers * 2,\n",
    "                                                        hidden_size * nlayers * 2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, paragraph, question, paragraph_mask, question_mask):\n",
    "        # em_embedding = exact_match(paragraph, question, vocab)\n",
    "        # print(em_embedding.size())\n",
    "        p_word_embedding = self.word_embedding_layer(paragraph)\n",
    "        q_word_embedding = self.word_embedding_layer(question)\n",
    "        p_word_embedding = self.dropout(p_word_embedding)\n",
    "        q_word_embedding = self.dropout(q_word_embedding)\n",
    "        aligned_embedding = self.aligned_embedding_layer(p_word_embedding, q_word_embedding, question_mask)\n",
    "        # print(p_word_embedding.size())\n",
    "        # print(aligned_embedding.size())\n",
    "        paragraph_embeddings = torch.cat([p_word_embedding, aligned_embedding], dim=2)\n",
    "\n",
    "        # paragraph_embeddings = torch.cat([em_embedding.to(device), p_word_embedding.to(device), aligned_embedding.to(device)], dim=2)\n",
    "        paragraph_encoding = self.paragraph_lstm(paragraph_embeddings)\n",
    "        # print(question.size(), question_mask.size())\n",
    "        question_encoding = self.question_encoder(q_word_embedding, question_mask)\n",
    "\n",
    "        prediction_start = self.prediction_layer_start(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "        prediction_end = self.prediction_layer_end(paragraph_encoding, question_encoding, paragraph_mask)\n",
    "\n",
    "        return prediction_start, prediction_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "EMB_SIZE = 300\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "#\n",
    "# writer = SummaryWriter('runs/myDrQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# dataiter_next = dataiter.next()\n",
    "# print(dataiter_next)\n",
    "# (p, q, a, s, p_mask, q_mask) = dataiter.next()\n",
    "# writer.add_graph(model, p, p_mask, q_mask)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, train_dataset):\n",
    "    '''\n",
    "    Trains the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start training ........\")\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    # put the model in training mode\n",
    "    model.train()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    try:\n",
    "        for i, (paragraphs, questions, span_list, answer_list,\n",
    "                paragraph_mask, question_mask) in enumerate(train_dataset):\n",
    "            # if i < 575:\n",
    "            #     continue\n",
    "            if i % 500 == 0:\n",
    "                print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "            # place the tensors on GPU\n",
    "            paragraphs = paragraphs.to(device)\n",
    "            paragraph_mask = paragraph_mask.to(device)\n",
    "            questions = questions.to(device)\n",
    "            question_mask = question_mask.to(device)\n",
    "            # span_list = span_list.to(device)\n",
    "\n",
    "            # forward pass, get the predictions\n",
    "            preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "            start_pred, end_pred = preds\n",
    "\n",
    "            # print('preds:', start_pred, end_pred)\n",
    "            # separate labels for start and end position\n",
    "            span_start = []\n",
    "            span_end = []\n",
    "            for span in span_list:\n",
    "                span_start.append(span[0][0].item())\n",
    "                span_end.append(span[0][1].item())\n",
    "\n",
    "            # print('span:', span_start, span_end)\n",
    "            span_start = torch.LongTensor(span_start).to(device)\n",
    "            span_end = torch.LongTensor(span_end).to(device)\n",
    "            # calculate loss\n",
    "            loss = F.cross_entropy(start_pred, span_start) + F.cross_entropy(end_pred, span_end)\n",
    "\n",
    "            # backward pass, calculates the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "            # update the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the gradients to prevent them from accumulating\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ...학습 중 손실(running loss)을 기록하고\n",
    "            # writer.add_scalar('training loss',\n",
    "            #                 train_loss / 500,\n",
    "            #                 epoch * len(trainloader) + i)\n",
    "            train_loss += loss.item()\n",
    "    except Exception as e:\n",
    "        print(f'sizes of pred:{start_pred.size()} / span:{span_start.size()}')\n",
    "        print(f'span_start: {span_start[23]}\\nspan_end: {span_end[23]}')\n",
    "        print(f'i: {i}')\n",
    "        print(f'paragraph: {paragraphs}')\n",
    "        bad_p = paragraphs.numpy()[23]\n",
    "        bad_q = questions.numpy()[23]\n",
    "        bad_p_text = [vocab.itos[pi] for pi in bad_p]\n",
    "        bad_q_text = [vocab.itos[qi] for qi in bad_q]\n",
    "        bad_p_text = ' '.join(bad_p_text)\n",
    "        bad_q_text = ' '.join(bad_q_text)\n",
    "\n",
    "        print(bad_p_text)\n",
    "        print(bad_q_text)\n",
    "        print(f'paragraph size: {paragraphs.size()}, question size: {questions.size()}')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "    return train_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %time train_loss = train(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def validate(model, test_dataset):\n",
    "    '''\n",
    "    Validates the model.\n",
    "    '''\n",
    "\n",
    "    print(\"Start validation ........\")\n",
    "\n",
    "    val_loss = 0.\n",
    "    emScore = 0\n",
    "    f1Score = 0\n",
    "    # put the model in eval mode\n",
    "    model.eval()\n",
    "    start_time = time()\n",
    "    # iterate through training data\n",
    "    for i, (paragraphs, questions, span_list, answer_list,\n",
    "            paragraph_mask, question_mask) in enumerate(test_dataset):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Starting batch: {i}, time: {time() - start_time}\")\n",
    "\n",
    "\n",
    "        # place the tensors on GPU\n",
    "        paragraphs = paragraphs.to(device)\n",
    "        paragraph_mask = paragraph_mask.to(device)\n",
    "        questions = questions.to(device)\n",
    "        question_mask = question_mask.to(device)\n",
    "        # span_list = span_list.to(device)\n",
    "\n",
    "        # forward pass, get the predictions\n",
    "        preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "        start_pred, end_pred = preds\n",
    "        # print('preds:', start_pred, end_pred)\n",
    "        start_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "        end_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "\n",
    "        # separate labels for start and end position\n",
    "        span_start = []\n",
    "        span_end = []\n",
    "        true_answers_list = []\n",
    "        my_answers = []\n",
    "        for paragraph, spans, answers, sp, ep in \\\n",
    "                zip(paragraphs, span_list, answer_list, start_pred_argmax, end_pred_argmax):\n",
    "            span_start.append([span[0].item() for span in spans][:3])\n",
    "            span_end.append([span[1].item() for span in spans][:3])\n",
    "            true_answers_list.append([ans2txt(answer) for answer in answers])\n",
    "            my_answers.append(span2txt([sp, ep + 1], paragraph))\n",
    "        with torch.no_grad():\n",
    "            # print('span:', span_start, span_end)\n",
    "            try:\n",
    "                span_start = torch.LongTensor(span_start).to(device)\n",
    "                span_end = torch.LongTensor(span_end).to(device)\n",
    "                # calculate loss\n",
    "                loss = F.cross_entropy(start_pred, span_start.t()[0]) + F.cross_entropy(end_pred, span_end.t()[0])\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                emScore += em_batch(my_answers, true_answers_list)\n",
    "                f1Score += f1_batch(my_answers, true_answers_list)\n",
    "            except:\n",
    "                print('start pred:', start_pred)\n",
    "                print('start pred shape:', start_pred.shape)\n",
    "                print('span_list:', span_list)\n",
    "                print('span_list length:', len(span_list))\n",
    "                print('span_start:', span_start)\n",
    "                print('span_start shape:', np.asarray(span_start).shape)\n",
    "                print('span_end:', span_end)\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    return val_loss / len(test_dataset), emScore / len(test_dataset), f1Score / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "def normalize_answer(s):\n",
    "    # # lower\n",
    "    # s = s.lower()\n",
    "    # # remove punctuation\n",
    "    # s = s.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "    # s = ' '.join(s.split())\n",
    "\n",
    "    # # remove a, an, the from the text\n",
    "    # s = re.sub(r'\\b(a|an|the)\\b', ' ', s)\n",
    "    return re.sub(r'\\b(a|an|the)\\b', ' ',\n",
    "                  ' '.join(s.lower().translate(str.maketrans('', '', punctuation)).split()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def em_batch(my_answers, true_answers_list):\n",
    "    # true_answers_list: batch size * 3\n",
    "    em = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        for true_answer in true_answers:\n",
    "            if my_answer == true_answer:\n",
    "                em += 1\n",
    "                break\n",
    "    return em / BATCH_SIZE\n",
    "\n",
    "def f1_batch(my_answers, true_answers_list):\n",
    "    f1Batch = 0\n",
    "    for my_answer, true_answers in zip(my_answers, true_answers_list):\n",
    "        f1_single = 0\n",
    "        for true_answer in true_answers:\n",
    "            my_answer_split = my_answer.split()\n",
    "            true_answer_split = true_answer.split()\n",
    "            common = Counter(my_answer_split) & Counter(true_answer_split)\n",
    "            num_intersection = sum(common.values())\n",
    "            if num_intersection == 0:\n",
    "                continue\n",
    "            precision = num_intersection / len(my_answer_split)\n",
    "            recall = num_intersection / len(true_answer_split)\n",
    "            f1_single = max((2 * precision * recall) / (precision + recall), f1_single)\n",
    "        f1Batch += f1_single\n",
    "        # if f1_single < 0.9:\n",
    "        #     print('my answer split:', my_answer_split)\n",
    "        #     print('true answer split:', true_answer_split)\n",
    "    return f1Batch / BATCH_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def span2txt(span, paragraph):\n",
    "    # print(span[0])\n",
    "    my_answer = paragraph[span[0].item() : span[1].item() + 1]\n",
    "    return ans2txt(my_answer)\n",
    "def ans2txt(answer):\n",
    "    words = []\n",
    "    for a_index in answer:\n",
    "        words.append(vocab.itos[a_index.item()])\n",
    "    return normalize_answer(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "best_val_loss = 100\n",
    "path = 'best.pt'\n",
    "if os.path.isfile(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring epoch 0\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007521867752075195\n",
      "Starting batch: 500, time: 120.96693825721741\n",
      "Starting batch: 1000, time: 247.9487226009369\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0029985904693603516\n",
      "train_loss: 6.704261917436149, val_loss: 6.518800078905546\n",
      "em_score: 12.151442307692308, f1_score: 25.05014796356147\n",
      "End epoch 0, elapsed time: 349.32715368270874\n",
      "Staring epoch 1\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00699925422668457\n",
      "Starting batch: 500, time: 132.42858958244324\n",
      "Starting batch: 1000, time: 264.180362701416\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0029973983764648438\n",
      "train_loss: 6.285401098998188, val_loss: 6.179189337216891\n",
      "em_score: 14.278846153846153, f1_score: 28.701748532041627\n",
      "End epoch 1, elapsed time: 369.53988766670227\n",
      "Staring epoch 2\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.010951757431030273\n",
      "Starting batch: 500, time: 135.03480339050293\n",
      "Starting batch: 1000, time: 268.2892520427704\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.003002166748046875\n",
      "train_loss: 5.860226878230436, val_loss: 5.689092925878671\n",
      "em_score: 16.814903846153847, f1_score: 34.144957807164204\n",
      "End epoch 2, elapsed time: 373.0033965110779\n",
      "Staring epoch 3\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.012001276016235352\n",
      "Starting batch: 500, time: 132.63365244865417\n",
      "Starting batch: 1000, time: 268.12913060188293\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0030329227447509766\n",
      "train_loss: 5.3235981312616945, val_loss: 5.201399392348069\n",
      "em_score: 19.375, f1_score: 38.73009586200207\n",
      "End epoch 3, elapsed time: 372.6942846775055\n",
      "Staring epoch 4\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.007035732269287109\n",
      "Starting batch: 500, time: 134.0149531364441\n",
      "Starting batch: 1000, time: 266.3191592693329\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0029997825622558594\n",
      "train_loss: 4.864201784486863, val_loss: 4.881459021568299\n",
      "em_score: 21.09375, f1_score: 42.18798729006012\n",
      "End epoch 4, elapsed time: 376.5253882408142\n",
      "Staring epoch 5\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.01696634292602539\n",
      "Starting batch: 500, time: 144.27384901046753\n",
      "Starting batch: 1000, time: 279.9433536529541\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.003001689910888672\n",
      "train_loss: 4.547605070513677, val_loss: 4.711612926996671\n",
      "em_score: 21.25, f1_score: 42.667785974583516\n",
      "End epoch 5, elapsed time: 386.7259020805359\n",
      "Staring epoch 6\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.008998394012451172\n",
      "Starting batch: 500, time: 138.32785892486572\n",
      "Starting batch: 1000, time: 275.9149935245514\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.002998828887939453\n",
      "train_loss: 4.337426438673967, val_loss: 4.559453679965093\n",
      "em_score: 21.983173076923077, f1_score: 43.982245354373916\n",
      "End epoch 6, elapsed time: 389.56853008270264\n",
      "Staring epoch 7\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.009000778198242188\n",
      "Starting batch: 500, time: 153.09490704536438\n",
      "Starting batch: 1000, time: 293.40539383888245\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.004000663757324219\n",
      "train_loss: 4.163924195164667, val_loss: 4.528607386809129\n",
      "em_score: 22.367788461538463, f1_score: 44.621979203845754\n",
      "End epoch 7, elapsed time: 403.2509026527405\n",
      "Staring epoch 8\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.011001825332641602\n",
      "Starting batch: 500, time: 140.4388165473938\n",
      "Starting batch: 1000, time: 282.5065178871155\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.004034757614135742\n",
      "train_loss: 4.004781249714815, val_loss: 4.476220917701721\n",
      "em_score: 22.247596153846153, f1_score: 44.935978487238806\n",
      "End epoch 8, elapsed time: 396.1784436702728\n",
      "Staring epoch 9\n",
      "Start training ........\n",
      "Starting batch: 0, time: 0.00999760627746582\n",
      "Starting batch: 500, time: 140.6036570072174\n",
      "Starting batch: 1000, time: 285.9254629611969\n",
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0039517879486083984\n",
      "train_loss: 3.8536952078386557, val_loss: 4.499206133989188\n",
      "em_score: 21.382211538461537, f1_score: 44.12747753892462\n",
      "End epoch 9, elapsed time: 395.61138129234314\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "for epoch in range(10):\n",
    "    print(f'Staring epoch {epoch}')\n",
    "    start_time = time()\n",
    "\n",
    "    train_loss = train(model, trainloader)\n",
    "    val_loss, emScore, f1Score = validate(model, testloader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    em_scores.append(emScore * 100)\n",
    "    f1_scores.append(f1Score * 100)\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            }, path)\n",
    "    end_time = time()\n",
    "\n",
    "    time_elapsed = end_time - start_time\n",
    "    print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "    print(f'em_score: {emScore}, f1_score: {f1Score}')\n",
    "    print(f'End epoch {epoch}, elapsed time: {time_elapsed}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation ........\n",
      "Starting batch: 0, time: 0.0030329227447509766\n",
      "train_loss: 3.8536952078386557, val_loss: 4.499206133989188\n",
      "em_score: 21.382211538461537, f1_score: 44.12747753892462\n"
     ]
    }
   ],
   "source": [
    "# val_loss, emScore, f1Score = validate(model, testloader)\n",
    "# print(f'train_loss: {train_loss}, val_loss: {val_loss}')\n",
    "# print(f'em_score: {emScore * 100}, f1_score: {f1Score * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# plt.plot([i for i in range(1, 11)], train_losses)\n",
    "# plt.plot([i for i in range(1, 11)], val_losses)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('CE losses')\n",
    "# plt.title('Training Result')\n",
    "# plt.legend(['Train', 'Test'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1, 11)], em_scores)\n",
    "plt.plot([i for i in range(1, 11)], f1_scores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores on SQuAD 1.1')\n",
    "plt.legend(['EM', 'F1'])\n",
    "plt.xticks([i for i in range(1, 11)])\n",
    "plt.yticks(np.arange(15, 60, 5))\n",
    "plt.savefig(\"lineexamples.png\", dpi=350)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# for i, t_data in enumerate(testloader):\n",
    "#     idx = i\n",
    "# print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 357])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (p, q, s, a, p_mask, q_mask), p 길이 점점 증가\n",
    "# p, q: tensor, batch size * length\n",
    "# s: tuple of tensors, batch size\n",
    "# a:\n",
    "dataiter = iter(trainloader)\n",
    "dataiter_next = dataiter.next()\n",
    "dataiter_next[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 22])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "for i in range(100):\n",
    "    dataiter_100 = dataiter.next()\n",
    "dataiter_100[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paragraphs, questions, span_list, answer_list, paragraph_mask, question_mask = dataiter_next\n",
    "model_ex = DocumentReader(HIDDEN_SIZE,\n",
    "                       EMB_SIZE,\n",
    "                       NLAYERS,\n",
    "                       DROPOUT,\n",
    "                       device).to(device)\n",
    "model_ex.train()\n",
    "paragraphs = paragraphs.to(device)\n",
    "paragraph_mask = paragraph_mask.to(device)\n",
    "questions = questions.to(device)\n",
    "question_mask = question_mask.to(device)\n",
    "# span_list = span_list.to(device)\n",
    "\n",
    "# forward pass, get the predictions\n",
    "preds = model(paragraphs, questions, paragraph_mask, question_mask)\n",
    "\n",
    "start_pred, end_pred = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start_pred.shape\n",
    "# start_pred_argmax = torch.argmax(start_pred, dim=1)\n",
    "# print(start_pred_argmax)\n",
    "# print(span_list)\n",
    "# print(span_list[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1822,     6,   515,  1465,  3705,    38,     3,    19,     2,    53,\n",
      "          110,     3,    52,   671,     8,  1545,    55,    19,    40,  2576,\n",
      "           67,    53,  5952,  2226,   398,   272,     5, 18722,     7,     2,\n",
      "          159,     4,   376,  7717,     3,    55,  3170,  2419,  9945,     3,\n",
      "           30,   294, 34010,   192,     3,     2,   164,     6,   515,  1465,\n",
      "           38,  3933,    32,  2054,     7,  6359,  2576,    75, 10612,     5,\n",
      "         6013,     3,     2, 11092,    38,  3083,  2316,    11,  2430,  1069,\n",
      "           57,  2854,     8,  5240,    40,  2001,   681,     5, 37413,     2,\n",
      "         1063,    12,    21,    74, 10612,   138,    39,  1938,     7,     9,\n",
      "         3350,   382,     8,    53,  2919,     3,    30,    78, 20733,     5,\n",
      "           85,  2684,    54,  1178,     6,  2430,  2576,     8, 62503, 10612,\n",
      "            7,  2313,     4,    55,  3336,  3705,     5,  1974,   298,     3,\n",
      "        18195,  1411,    26,  6545,  1309,    64,    20,    40,  7331,     6,\n",
      "         4198,    81,   689,     8,  3833,    40,  2576,     6,  4461,     2,\n",
      "          513,     4,     2,  1768, 10888,  9961,     5,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1], device='cuda:0')\n",
      "[tensor([66, 76])]\n",
      "[tensor([2316,   11, 2430, 1069,   57, 2854,    8, 5240,   40, 2001,  681])]\n",
      "tensor([ 8698,    37,   939,     2,   272,     4,  4368,    58,  5497,     5,\n",
      "           28,    46,  3021,     3,     2,    45,  1606,     4,  4368,     3,\n",
      "           88,    15, 53024,  4368,     3,     9,  3298,  4777,    20,  4346,\n",
      "        15634,     9, 29269,     3,    13,   113,  3131,     6,  1539,    15,\n",
      "            9,   625,    47,   963,   373,   494,   532,    70,  3759,     6,\n",
      "         3558,     7,   218,     5,    86,   172,  1606,     3, 33353,  4368,\n",
      "            3,   577,  4937,   161,   178,  4038,     3,    84,     2, 45920,\n",
      "          532,  1243,  1861,     5,   186,   494,  3213,  7279,  6046,  1087,\n",
      "          275,  3021,     3,  5369,   119,  5497,     4,  4368,     7,    36,\n",
      "          586,     3,    14,  7909, 44621,     5,   325,     8,  6046,   103,\n",
      "           13,    10,  1658,  4368,    10,     3,    16,    25,  6172,     8,\n",
      "         4718,    17,    84,     2,   532,    13,  1194,   247,     7,     2,\n",
      "         5929,     4,  7012,     6, 11405,    44,     2,   172,  1606,   120,\n",
      "           96,    10,  1337,  4368,    10,     3,    16,    25,  4393,     8,\n",
      "         2751,    17,    76,    29,    69,  4346, 15634,  1495,    15,    32,\n",
      "          229, 26519,    16,    73,  3079,    17,    44,     6,  1469,  6046,\n",
      "          648,     8,    10,  3190,  4368,    10,    16,    25,  2751,     8,\n",
      "         4744,    17,    15,     2,   297,  1606,     4,  4368,    15,     9,\n",
      "         3131,  7550,    11,  7527,   532,     5,  7279,  6046,    23, 12357,\n",
      "           91,     4,   100,   460,     8,  4080,     2,   192,     4, 11405,\n",
      "            3,  7012,     3, 15634,    16,    25,  3079,    17,     6, 12876,\n",
      "           16,     8,     9,  4200,  1837,    17,  9307,    32, 15337,   998,\n",
      "        13196,     5,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1], device='cuda:0')\n",
      "[tensor([138, 140])]\n",
      "[tensor([4393,    8, 2751])]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p, s, a in zip(paragraphs, span_list, answer_list):\n",
    "    i += 1\n",
    "    if i < 3:\n",
    "        print(p)\n",
    "        print(s)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# em_score = 0\n",
    "# for i, (p, s, a) in enumerate(list(zip(paragraphs, span_list, answer_list))):\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     if i < 3:\n",
    "#         # print(p)\n",
    "#         # print(s)\n",
    "#         # print(a)\n",
    "#         em_score += em_func(p, a[0], s)\n",
    "# print(em_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}